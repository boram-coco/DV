[
  {
    "objectID": "posts/DV_3(0919).html",
    "href": "posts/DV_3(0919).html",
    "title": "DV 3주차(1)",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "posts/DV_3(0919).html#line-plot",
    "href": "posts/DV_3(0919).html#line-plot",
    "title": "DV 3주차(1)",
    "section": "Line plot",
    "text": "Line plot\n\n기본플랏\n- 예시\n\nx=[1,2,3,4]\ny=[1,2,4,3]\n\n\nplt.plot(x,y)\n\n\n\n\n\n\n모양변경\n- 예시1\n\nplt.plot(x,y,'--') #점선\n\n\n\n\n- 예시2\n\nplt.plot(x,y,':')\n\n\n\n\n- 예시3\n\nplt.plot(x,y,'-.')\n\n\n\n\n\n\n색상변경\n- 예시1\n\nplt.plot(x,y,'r')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'k') #블랙\n\n\n\n\n\n\n모양 + 색상변경\n- 예시1\n\nplt.plot(x,y,'--r')  # r을 앞에 쓰든 뒤에 쓰든 나온다\n\n\n\n\n\n\n원리?\n- r-- 등의 옵션은 Markers + Line Styles + Colors의 조합으로 표현 가능\nref : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n\n--r: 점선(dashed)스타일 + 빨간색\nr--: 빨간색 + 점선(dashed)스타일\n:k: 점선(dotted)스타일 + 검은색\nk:: 검은색 + 점선(dotted)스타일\n\n- 우선 Marker를 무시하면 Line Styles + Color로 표현가능한 조합은 4*8 = 32개\n(Line Styles) 모두 4개\n\n\n\ncharacter\ndescription\n\n\n\n\n‘-’\nsolid line style\n\n\n‘–’\ndashed line style\n\n\n‘-.’\ndash-dot line style\n\n\n‘:’\ndotted line style\n\n\n\n(Color) 모두 8개\n\n\n\ncharacter\ncolor\n\n\n\n\n‘b’\nblue\n\n\n‘g’\ngreen\n\n\n‘r’\nred\n\n\n‘c’\ncyan\n\n\n‘m’\nmagenta\n\n\n‘y’\nyellow\n\n\n‘k’\nblack\n\n\n‘w’\nwhite\n\n\n\n- 예시1\n\nplt.plot(x,y,'--m')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'-.c')\n\n\n\n\n- 예시3: line style + color 조합으로 사용하든 color + line style 조합으로 사용하든 상관없음\n\nplt.plot(x,y,'c-.')\n\n\n\n\n- 예시4: line style을 중복으로 사용하거나 color를 중복으로 쓸 수 는 없다.\n\nplt.plot(x,y,'--:')\n\nValueError: Illegal format string \"--:\"; two linestyle symbols\n\n\n\n\n\n\nplt.plot(x,y,'rb')\n\nValueError: Illegal format string \"rb\"; two color symbols\n\n\n\n\n\n- 예시5: 색이 사실 8개만 있는 것은 아니다.\nref: https://matplotlib.org/2.0.2/examples/color/named_colors.html\n\nplt.plot(x,y,'--',color='aqua') # 8가지 색 외의 다른 것은 color= 옵션으로 줘야함\n\n\n\n\n- 예시6: 색을 바꾸려면 Hex코드를 밖아 넣는 방법이 젤 깔끔함\nref: https://htmlcolorcodes.com/\n\nplt.plot(x,y,color='#277E41')   \n\n\n\n\n- 예시7: 라인스타일도 4개만 있지 않다\nref: https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html\n\nplt.plot(x,y,linestyle='dashed')\n\n\n\n\n\nplt.plot(x,y,linestyle=(0, (20, 5)))\n\n\n\n\n\nplt.plot(x,y,linestyle=(0, (20, 1)))"
  },
  {
    "objectID": "posts/DV_3(0919).html#scatter-plot",
    "href": "posts/DV_3(0919).html#scatter-plot",
    "title": "DV 3주차(1)",
    "section": "Scatter plot",
    "text": "Scatter plot\n\n원리\n- 그냥 마커를 설정하면 끝\nref: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n\n\n\ncharacter\ndescription\n\n\n\n\n‘.’\npoint marker\n\n\n‘,’\npixel marker\n\n\n‘o’\ncircle marker\n\n\n‘v’\ntriangle_down marker\n\n\n‘^’\ntriangle_up marker\n\n\n‘<’\ntriangle_left marker\n\n\n‘>’\ntriangle_right marker\n\n\n‘1’\ntri_down marker\n\n\n‘2’\ntri_up marker\n\n\n‘3’\ntri_left marker\n\n\n‘4’\ntri_right marker\n\n\n‘8’\noctagon marker\n\n\n‘s’\nsquare marker\n\n\n‘p’\npentagon marker\n\n\n‘P’\nplus (filled) marker\n\n\n’*’\nstar marker\n\n\n‘h’\nhexagon1 marker\n\n\n‘H’\nhexagon2 marker\n\n\n‘+’\nplus marker\n\n\n‘x’\nx marker\n\n\n‘X’\nx (filled) marker\n\n\n‘D’\ndiamond marker\n\n\n‘d’\nthin_diamond marker\n\n\n‘|’\nvline marker\n\n\n’_’\nhline marker\n\n\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n기본플랏\n\nplt.plot(x,y,'.')\n\n\n\n\n\nplt.plot(x,y,'x')\n\n\n\n\n\n\n색깔변경\n\nplt.plot(x,y,'or')\n\n\n\n\n\nplt.plot(x,y,'db')\n\n\n\n\n\nplt.plot(x,y,'bx')"
  },
  {
    "objectID": "posts/DV_3(0919).html#dot-connected-plot",
    "href": "posts/DV_3(0919).html#dot-connected-plot",
    "title": "DV 3주차(1)",
    "section": "dot-connected plot",
    "text": "dot-connected plot\n- 예시1: 마커와 라인스타일을 동시에 사용하면 dot-connected plot이 된다.\n\nplt.plot(x,y,'o-')\n\n\n\n\n- 예시2: 당연히 색도 적용가능\n\nplt.plot(x,y,'o--r')\n\n\n\n\n- 예시3: 서로 순서를 바꿔도 상관없다.\n\nplt.plot(x,y,'r--o')\n\n\n\n\n\nplt.plot(x,y,'ro--')"
  },
  {
    "objectID": "posts/DV_3(0919).html#여러-그림-그리기",
    "href": "posts/DV_3(0919).html#여러-그림-그리기",
    "title": "DV 3주차(1)",
    "section": "여러 그림 그리기",
    "text": "여러 그림 그리기\n\n겹쳐그리기\n- 예시1\n\nx = np.arange(-5,5,0.1)\nϵ = np.random.randn(100)\ny = 2*x + ϵ\n\n\nplt.plot(x,y,'.b')\nplt.plot(x,2*x,'r')\n\n\n\n\n\n\n따로그리기(subplot) // 외우기\n- 예시1\n\nfig, axs = plt.subplots(2)\naxs[0].plot(x,y,'.b')\naxs[1].plot(x,2*x,'r')\n\n\n\n\n- 예시2\n\nfig, axs = plt.subplots(2,2)\naxs[0,0].plot(x,2*x,'--b')\naxs[0,1].plot(x,ϵ,'.r')\naxs[1,0].plot(x,y,'.r')\naxs[1,1].plot(x,y,'.r')\naxs[1,1].plot(x,2*x,'-b')"
  },
  {
    "objectID": "posts/DV_3(0919).html#fig와-axes의-이해-matplotlib으로-어렵게-그림을-기리는-방법",
    "href": "posts/DV_3(0919).html#fig와-axes의-이해-matplotlib으로-어렵게-그림을-기리는-방법",
    "title": "DV 3주차(1)",
    "section": "fig와 axes의 이해: matplotlib으로 어렵게 그림을 기리는 방법",
    "text": "fig와 axes의 이해: matplotlib으로 어렵게 그림을 기리는 방법\n\n예제1\n- 목표: plt.plot()을 이용하지 않고 아래의 그림을 그려보자.\n\nplt.plot([1,2,3,4],[1,2,4,3],'or--')\n\n\n\n\n- 구조: axis \\(\\subset\\) axes \\(\\subset\\) figure\nref: https://matplotlib.org/stable/gallery/showcase/anatomy.html#sphx-glr-gallery-showcase-anatomy-py\n\n- 전략: Fig을 만들고 (도화지를 준비) \\(\\to\\) axes를 만들고 (네모틀) \\(\\to\\) axes에 그림을 그린다.\n- 그림객체를 생성한다.\n\nfig = plt.figure()\n\n<Figure size 432x288 with 0 Axes>\n\n\n\nfig # 지금은 아무것도 없다\n\n<Figure size 432x288 with 0 Axes>\n\n\n- 그림객체에는 여러 인스턴스+함수가 있는데 그중에서 axes도 있다. (그런데 그 와중에 plot method는 없다.)\n\nfig.axes   # 비어있는 리스트\n\n[]\n\n\n- axes추가\n\nfig.add_axes([0,0,1,1])  # (0,0) 위치에 (1,1)인 액시즈(=네모틀)을 만들어라.\n\n<Axes:>\n\n\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig  # 아까는 아무것도 없었는데 지금 도화지안에 네모틀이 들어가 있다.\n\n\n\n\n- 첫번째 액시즈를 ax1으로 받음 (원래 axes1이어야하는데 그냥 편의상)\n\nax1 = fig.axes[0]\n\n\nid(fig.axes[0]), id(ax1)\n\n(140307253185296, 140307253185296)\n\n\n- 잠깐만! (fig오브젝트와 ax1 오브젝트는 포함관계에 있다.)\n\nid(fig.axes[0]), id(ax1)\n\n(140307253185296, 140307253185296)\n\n\n- 또 잠깐만! (fig오브젝트에는 plot이 없지만 ax1에서는 plot가 있다.)\n\nset(dir(fig)) & {'plot'}\n\nset()\n\n\n\nset(dir(ax1)) & {'plot'}\n\n{'plot'}\n\n\n- ax1.plot()을 사용하여 그림을 그려보자.\n\nax1.plot([1,2,3,4],[1,2,4,3],'--or') # 안되누?\n\n\nfig\n\n\n\n\n\n\n예제2: 예제1의 응용\n- 위에서 축을 하나 더 추가\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig.add_axes([1,1,1,1,])  # (1,1) 위치에 (1,1)크기의 액자틀 추가\n\n<Axes:>\n\n\n\nfig.axes  #추가해서 두개\n\n[<Axes:>, <Axes:>]\n\n\n\nfig\n\n\n\n\n\nax1, ax2 = fig.axes\n\n- ax2에 파란선으로 그림을 그리자\n\nax2.plot([1,2,3,4],[1,2,4,3],'--ob')\n\n\nfig\n\n\n\n\n\n\n예제3: 응용(미니맵)\n- 위의 상황에서 액시지를 하나 더 추가\n\nfig.add_axes([0.65,0.1,0.3,0.3])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n\nfig.axes[-1].plot([1,2,3,4],[1,2,4,3],'xr')\n\n\nfig\n\n\n\n\n\n\n예제4: 재해석1\n(ver1)\n\nplt.plot([1,2,3,4],[1,2,4,3])\n\n\n\n\n(ver2)\nver1은 사실 아래가 연속적으로 실행된 축약구문임\nfig = plt.figure() \nfig.add_axes([?,?,?,?])\nax1 = fig.axes[0]\nax1.plot([1,2,3,4],[1,2,4,3])\nfig\n\n\n예제5: 재해석2\n\nfig, axs = plt.subplots(2,2)\n\n\n\n\n\nfig, axs = plt.subplots(2,2)\naxs[0,0].plot([1,2,3,4],[1,2,4,3],'.')\naxs[0,1].plot([1,2,3,4],[1,2,4,3],'--r')\naxs[1,0].plot([1,2,3,4],[1,2,4,3],'o--')\naxs[1,1].plot([1,2,3,4],[1,2,4,3],'o--',color='lime')\n\n\n\n\n- fig, axs = plt.subplots(2,2)의 축약버전을 이해하면된다.\n(ver1)\n\nfig, axs = plt.subplots(2,2)\n\n\n\n\n(ver2)\nver1은 사실 아래가 연속적으로 실행된 축약구문임\nfig = plt.figure()\nfig.add_axes([?,?,?,?]) \nfig.add_axes([?,?,?,?])\nfig.add_axes([?,?,?,?])\nfig.add_axes([?,?,?,?])\nax1,ax2,ax3,ax4 = fig.axes\naxs = np.array(((ax1,ax2),(ax3,ax4)))\n(ver3)\nver1은 아래와 같이 표현할 수도 있다.\n\nfig = plt.figure()\naxs = fig.subplots(2,2)"
  },
  {
    "objectID": "posts/DV_3(0919).html#숙제",
    "href": "posts/DV_3(0919).html#숙제",
    "title": "DV 3주차(1)",
    "section": "숙제",
    "text": "숙제\n\n숙제1\n\nfig, axs = plt.subplots(2,3)\naxs[0,0].plot([1,2,3,4],[1,2,4,3],'or')\naxs[0,1].plot([1,2,3,4],[1,2,4,3],'og')\naxs[0,2].plot([1,2,3,4],[1,2,4,3],'ob')\naxs[1,0].plot([1,2,3,4],[1,2,4,3],'or--')\naxs[1,1].plot([1,2,3,4],[1,2,4,3],'og--')\naxs[1,2].plot([1,2,3,4],[1,2,4,3],'ob--')\n\n\n\n\n\n\n숙제2\n\nx,y = [1,2,3,4], [1,2,1,1]\n\n\nfig = plt.figure()\n\n<Figure size 432x288 with 0 Axes>\n\n\n\nfig\n\n<Figure size 432x288 with 0 Axes>\n\n\n\nfig.axes\n\n[]\n\n\n\nfig.add_axes([0,0,1,1]) \n\n<Axes:>\n\n\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig\n\n\n\n\n\nax1 = fig.axes[0]\n\n\nax1.plot(x,y,'or')\n\n\nfig\n\n\n\n\n\nfig.add_axes([0.5,0.5,1,1,])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n\nfig.add_axes([1,1,1,1,])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n\nax1, ax2, ax3 = fig.axes\n\n\nax2.plot(x,y,'og')\nax3.plot(x,y,'ob')\n\n\nfig\n\n\n\n\n\n\n숙제3\n\nx = np.arange(-5,5,0.1)\ny1 = np.sin(x)\ny2 = np.sin(2*x) + 2\ny3 = np.sin(4*x) + 4 \ny4 = np.sin(8*x) + 6\n\n\nplt.plot(x, y1, '--r')\nplt.plot(x, y2, '--b')\nplt.plot(x, y3, '--g')\nplt.plot(x, y4, '--m')"
  },
  {
    "objectID": "posts/DV_5(1006).html",
    "href": "posts/DV_5(1006).html",
    "title": "DV 5주차(2)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotnine import *"
  },
  {
    "objectID": "posts/DV_5(1006).html#애드워드-터프티",
    "href": "posts/DV_5(1006).html#애드워드-터프티",
    "title": "DV 5주차(2)",
    "section": "애드워드 터프티",
    "text": "애드워드 터프티\n- 데이터 시각화계의 거장\n- 터프티의 이론중 백미: 엄격한 미니멀리즘\n\n최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다.\n작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다.\n\n- 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량\n- 차트정크 (나이젤홈즈의 그래프)\n\n\n“Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (…) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (…) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.”\n\n\n차트정크 = 대중을 멸시 + 데이터에 대한 모독\n차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다..\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 제 생각: 글쎄…"
  },
  {
    "objectID": "posts/DV_5(1006).html#찰스미나드의-도표",
    "href": "posts/DV_5(1006).html#찰스미나드의-도표",
    "title": "DV 5주차(2)",
    "section": "찰스미나드의 도표",
    "text": "찰스미나드의 도표\n\n인류역사상 가장 훌륭한 시각화\n\n\n- 터프티의 평\n\n지금까지 그려진 최고의 통계 그래픽일지도 모른다.\n여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 \\(\\to\\) 6차원의 변수\n백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. \\(\\to\\) 미니멀리즘..\n\n- 왜 우수한 그래프일까?\n\n자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존\n이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임\n미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함."
  },
  {
    "objectID": "posts/DV_5(1006).html#미나드처럼-그리는게-왜-어려운가",
    "href": "posts/DV_5(1006).html#미나드처럼-그리는게-왜-어려운가",
    "title": "DV 5주차(2)",
    "section": "미나드처럼 그리는게 왜 어려운가?",
    "text": "미나드처럼 그리는게 왜 어려운가?\n- 몸무게, 키, 성별, 국적\n\ndf1=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male1.csv')\ndf2=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male2.csv')  \ndf3=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/female.csv') \ndf4=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/foreign.csv')\n\n- 미나드의 접근방법\n\n_df = pd.concat([pd.concat([df1,df2],axis=1).assign(g='m'),df3.assign(g='f')]) # df1과 df2는 옆으로 붙여야 하므로 axis=0, df3와 구분을 주기위한 g추가\ndf = pd.concat([_df.assign(g2='korea'),df4.assign(g2='foreign')]).reset_index(drop=True) # 인덱스를 0~부터 다시 정리해논거\ndf\n\n\n\n\n\n  \n    \n      \n      w\n      h\n      g\n      g2\n    \n  \n  \n    \n      0\n      72.788217\n      183.486773\n      m\n      korea\n    \n    \n      1\n      66.606430\n      173.599877\n      m\n      korea\n    \n    \n      2\n      69.806324\n      173.237903\n      m\n      korea\n    \n    \n      3\n      67.449439\n      173.223805\n      m\n      korea\n    \n    \n      4\n      70.463183\n      174.931946\n      m\n      korea\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1525\n      78.154632\n      188.324350\n      m\n      foreign\n    \n    \n      1526\n      74.754308\n      183.017979\n      f\n      foreign\n    \n    \n      1527\n      91.196208\n      190.100456\n      m\n      foreign\n    \n    \n      1528\n      87.770394\n      187.987255\n      m\n      foreign\n    \n    \n      1529\n      88.021995\n      193.456798\n      m\n      foreign\n    \n  \n\n1530 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df,x='w',y='h',hue='g',style='g2')\n\n# 4차원 그림, style을 통해 외국인 구분하기\n\n<AxesSubplot:xlabel='w', ylabel='h'>\n\n\n\n\n\n- 어려운점: (1) 센스가 없어서 hue/style을 이용하여 그룹을 구분할 생각을 못함 (2) long df (=tidy data) 형태로 데이터를 정리할 생각을 못함 (3) long df 형태로 데이터를 변형하는 코드를 모름\n\n\n기획력부족 -> 훌륭한 시각화를 많이 볼 것\n\n\n데이터프레임에 대한 이해부족 -> tidydata에 대한 개념\n\n\n프로그래밍 능력 -> 코딩공부열심히 (pandas를 엄청 잘해야함)"
  },
  {
    "objectID": "posts/DV_5(1006).html#방법1-rpy2-코랩-아닌경우-실습금지",
    "href": "posts/DV_5(1006).html#방법1-rpy2-코랩-아닌경우-실습금지",
    "title": "DV 5주차(2)",
    "section": "방법1: rpy2 (코랩 아닌경우 실습금지)",
    "text": "방법1: rpy2 (코랩 아닌경우 실습금지)\n\nimport rpy2\n%load_ext rpy2.ipython\n\n\n%%R \n### 여기는 R처럼 쓸 수 있다. \na <- c(1,2,3) \na+1\n\n[1] 2 3 4\n\n\n\na\n\nNameError: name 'a' is not defined\n\n\n\nR과 파이썬은 독립적이므로 R을 나가서 a를 입력하면 아무것도 안나옴\n\n\n%%R \nlibrary(tidyverse)\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# … with 224 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nmpg\n\nNameError: name 'mpg' is not defined\n\n\n\n%R -o mpg # R에 있는 자료가 파이썬으로 넘어옴\n\n\nmpg\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      5\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      234\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/DV_5(1006).html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "href": "posts/DV_5(1006).html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "title": "DV 5주차(2)",
    "section": "방법2: 저장된 csv파일을 통하여 데이터를 확보",
    "text": "방법2: 저장된 csv파일을 통하여 데이터를 확보\n\nmpg.to_csv(\"mpg.csv\",index=False)\n\n\npd.read_csv(\"mpg.csv\")\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/DV_5(1006).html#방법3-github등에-공개된-csv를-읽어오기",
    "href": "posts/DV_5(1006).html#방법3-github등에-공개된-csv를-읽어오기",
    "title": "DV 5주차(2)",
    "section": "방법3: github등에 공개된 csv를 읽어오기",
    "text": "방법3: github등에 공개된 csv를 읽어오기\n\npd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/mpg.csv')\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns\n\n\n\n- 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다."
  },
  {
    "objectID": "posts/DV_5(1006).html#data-설명",
    "href": "posts/DV_5(1006).html#data-설명",
    "title": "DV 5주차(2)",
    "section": "data 설명",
    "text": "data 설명\n- displ: 자동차의 엔진크기\n- hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐?\n- 자세한 설명은 R에서 ?mpg를 이용해 스스로 찾아볼 것"
  },
  {
    "objectID": "posts/DV_5(1006).html#python에서-plotnine을-이용한-산점도",
    "href": "posts/DV_5(1006).html#python에서-plotnine을-이용한-산점도",
    "title": "DV 5주차(2)",
    "section": "python에서: plotnine을 이용한 산점도",
    "text": "python에서: plotnine을 이용한 산점도\n\nggplot(data=mpg) + geom_point(aes(x='displ', y='hyw')) \n\n\nggplot(data=mpg) + geom_point(mapping=aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726736046009)>\n\n\n\n산점도 해석: 엔진크기가 클수록 효율이 낮음.\n\n- 빠르게 그리기: data=와 mapping=은 생략가능함\n\nggplot(mpg) + geom_point(aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726735544581)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#r에서-ggplot2를-이용한-산점도",
    "href": "posts/DV_5(1006).html#r에서-ggplot2를-이용한-산점도",
    "title": "DV 5주차(2)",
    "section": "R에서: ggplot2를 이용한 산점도",
    "text": "R에서: ggplot2를 이용한 산점도\n- R에서도 거의 똑같은 문법으로 그릴 수 있음 (데이터프레임 혹은 티블에 저장된 column 이름을 사용할때 따옴표만 제거하면 된다!)\n\nw 800은 그림의 폭 조정\n\n\n%%R -w 800\nggplot(mpg) + geom_point(aes(x=displ,y=hwy)) ## plotnine"
  },
  {
    "objectID": "posts/DV_5(1006).html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "href": "posts/DV_5(1006).html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "title": "DV 5주차(2)",
    "section": "python에서: 객체지향적인 느낌으로 산점도 그리기",
    "text": "python에서: 객체지향적인 느낌으로 산점도 그리기\nstep1: 도화지를 준비한다.\n\nfig = ggplot(data=mpg)\nfig\n\n\n\n\n<ggplot: (8726735085529)>\n\n\nstep2 변수와 에스테틱사이의 맵핑을 설정한다.\n\na1= aes(x='displ',y='hwy')\na1\n\n{'x': 'displ', 'y': 'hwy'}\n\n\nstep3 점들의 집합을 만든다. 즉 포인트 지옴을 만든다.\n\npoint1=geom_point(mapping=a1)\n\n\ngeom_point(): 점들을 그려! 어떻게?\na1에서 설정된 표를 보고\n\nstep4 도화지와 지옴을 합친다.\n\nfig+point1\n\n\n\n\n<ggplot: (8726775447877)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-점크기변경",
    "href": "posts/DV_5(1006).html#산점도-점크기변경",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경",
    "text": "산점도 + 점크기변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734563561)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-투명도변경",
    "href": "posts/DV_5(1006).html#산점도-투명도변경",
    "title": "DV 5주차(2)",
    "section": "산점도 + 투명도변경",
    "text": "산점도 + 투명도변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734989121)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-투명도점크기를-동시에-적용",
    "href": "posts/DV_5(1006).html#산점도-투명도점크기를-동시에-적용",
    "title": "DV 5주차(2)",
    "section": "산점도 + 투명도/점크기를 동시에 적용",
    "text": "산점도 + 투명도/점크기를 동시에 적용\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734522405)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-형태",
    "href": "posts/DV_5(1006).html#산점도-형태",
    "title": "DV 5주차(2)",
    "section": "산점도 + 형태",
    "text": "산점도 + 형태\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',shape='class'))\n\n\n\n\n<ggplot: (8726734265229)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-색깔",
    "href": "posts/DV_5(1006).html#산점도-색깔",
    "title": "DV 5주차(2)",
    "section": "산점도 + 색깔",
    "text": "산점도 + 색깔\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',color='class'))\n\n\n\n\n<ggplot: (8726734017473)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#객체지향적-느낌으로",
    "href": "posts/DV_5(1006).html#객체지향적-느낌으로",
    "title": "DV 5주차(2)",
    "section": "객체지향적 느낌으로?",
    "text": "객체지향적 느낌으로?\n\na2 = aes(x='displ', y='hwy', color='class') \n\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\npoint2=geom_point(a2)\n\n\nfig+point2\n\n\n\n\n<ggplot: (8726733712885)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-색깔-적합선",
    "href": "posts/DV_5(1006).html#산점도-색깔-적합선",
    "title": "DV 5주차(2)",
    "section": "산점도 + 색깔 + 적합선",
    "text": "산점도 + 색깔 + 적합선\n- 일단 색깔이 없는 포인트 지옴부터 연습\n\nfig+point1\n\n\n\n\n<ggplot: (8726733452617)>\n\n\n\nline1 = geom_smooth(a1)\n\n\nfig+point1+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732994973)>\n\n\n- point1(색깔없는 포인트 지옴)을 point2(색깔있는 포인트 지옴)으로 언제든지 바꿔치기 가능!\n\nfig+point2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732661565)>\n\n\n- 명령어로 한번에 그리기\n\n줄 넘어 가는 연산자 표현 : \\\n\n\nggplot(data=mpg) + \\\ngeom_point(mapping=aes(x='displ',y='hwy',color='class')) + \\\ngeom_smooth(mapping=aes(x='displ',y='hwy'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732727485)>\n\n\n- 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함)\n\nggplot(data=mpg,mapping=aes(x='displ',y='hwy')) + \\\ngeom_point(mapping=aes(color='class')) + \\\ngeom_smooth()\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733489953)>\n\n\n- R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다.\n\n%%R -w 800\nggplot(data=mpg,mapping=aes(x=displ,y=hwy)) + geom_point(mapping=aes(color=class)) + geom_smooth()\n\nR[write to console]: `geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-점크기변경-색깔",
    "href": "posts/DV_5(1006).html#산점도-점크기변경-색깔",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔",
    "text": "산점도 + 점크기변경 + 색깔\n- drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다.\n\nggplot(data=mpg, mapping=aes(x='displ',y='hwy')) + geom_point(mapping=aes(size='class',color='drv'),alpha=0.3)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731152845)>\n\n\n\n모든 \\(x\\)에 대하여 붉은색 점들이 대부분 초록색과 보라색 점들에 비하여 아래쪽에 있음 \\(\\to\\) 4륜구동방식이 연비가 좋지 않음"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-점크기변경-색깔-객체지향버전",
    "href": "posts/DV_5(1006).html#산점도-점크기변경-색깔-객체지향버전",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔 (객체지향버전)",
    "text": "산점도 + 점크기변경 + 색깔 (객체지향버전)\n- 맵핑규칙\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\na3 = a2.copy() \n\n\na3['color'] = 'drv'\na3['size'] = 'class'\na3\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'}\n\n\n\n아래와 같이 선언해도 괜찮음\n\na3= aes(x='displ',y='hwy',color='drv',size='class')\n\npoint3=geom_point(a3)\n\n\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731065581)>\n\n\n\n그림의 전체적인 투명도를 조절하면 좋겠음\n\n\npoint3=geom_point(a3,alpha=0.2)\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726730819657)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-점크기변경-색깔-선추가",
    "href": "posts/DV_5(1006).html#산점도-점크기변경-색깔-선추가",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔 + 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + 선추가\n\nfig+point3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726730575253)>"
  },
  {
    "objectID": "posts/DV_5(1006).html#산점도-점크기변경-색깔-drv별로-선추가",
    "href": "posts/DV_5(1006).html#산점도-점크기변경-색깔-drv별로-선추가",
    "title": "DV 5주차(2)",
    "section": "산점도 + 점크기변경 + 색깔 + drv별로 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + drv별로 선추가\n- 맵핑규칙\n\na1,a2,a3\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'})\n\n\n\na4 = a2.copy() \na4['color']='drv'\na4\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv'}\n\n\n\nline2 = geom_smooth(a4)\n\n\nfig + point3 +line2\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726729919385)>\n\n\n- 선의 색깔을 동일하게 하고 선의 타입을 변경하여 drv를 표시하고 싶다면?\n\na1,a2,a3,a4\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv'})\n\n\n\na5=a1.copy()\na5['linetype']='drv' \na5\n\n{'x': 'displ', 'y': 'hwy', 'linetype': 'drv'}\n\n\n\nline3 = geom_smooth(a5,size=0.5,color='gray')\n\n\nfig+point3+line3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732637457)>\n\n\n- 전체적인 추세선도 추가하고 싶다면?\n\nfig+point3+line3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732939513)>\n\n\n- 그려보니까 역시 drv별로 그려지는 추세선은 색깔별로 구분하는게 좋겠음.\n\nline2 = geom_smooth(a4,size=0.5,linetype='dashed')\nfig+point3+line2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733678229)>\n\n\n- 고차원을 변수를 표현할 수 있는 무기는 다양하다.\n\n산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도\n라인플랏(스무스지옴,라인지옴): 선의형태, 선의색깔, 선의굵기"
  },
  {
    "objectID": "posts/DV_09(1102).html",
    "href": "posts/DV_09(1102).html",
    "title": "DV 9주차",
    "section": "",
    "text": "Cairo, A. Functional Art, The: An Introduction to Information Graphics and Visualization, New Riders, 2012. San Francisco, US."
  },
  {
    "objectID": "posts/DV_09(1102).html#presentation",
    "href": "posts/DV_09(1102).html#presentation",
    "title": "DV 9주차",
    "section": "Presentation",
    "text": "Presentation\n\n- 프리젠테이션방식의 시각화는 화자가 다듬은 이야기를 전달하기에 좋은 시각화이다. 즉 잘 정리된 메시지를 전달하기에 좋다."
  },
  {
    "objectID": "posts/DV_09(1102).html#exploration",
    "href": "posts/DV_09(1102).html#exploration",
    "title": "DV 9주차",
    "section": "Exploration",
    "text": "Exploration\n\n\n문학적유기체라는 작품이다.(https://www.stefanieposavec.com/).\n어떤 소설책을 시각화.\n수형도 + 칼라\n수형도의 의미: 단원, 문단, 문장, 단어 (수형도 계층적 구조를 시각화 하기에 뛰어남. ex: 리그레션트리!)\n색깔: 여행, 음악, 파티 등 소설에서 자주 등장하는 소재 (색은 범주형 변수를 표현하기에 뛰어남)\n\n- 익스플로래이션 방식은 독자가 스스로 그림에서 메시지를 찾아낸다.\n- 소설을 읽어보지 않은 사람: 이 그래픽으로 소설책의 전체 주제를 미리 파악가능\n- 소설을 이미 읽어본 사람: 분석 & 탐구를 할 수 있음. ex: 파티와 음악이 동시에 등장하는 경우가 많다."
  },
  {
    "objectID": "posts/DV_09(1102).html#절충",
    "href": "posts/DV_09(1102).html#절충",
    "title": "DV 9주차",
    "section": "절충",
    "text": "절충\n- 카이로: 사실 프리젠테이션과 익스플로레이션은 절충가능함\n\n\naes(x=‘GDP’,y=‘불평등’,text=‘년도’,color=‘정부’)\n초록색정부: 소득이 증가 & 불평등이 훨씬 더 증가\n갈색정부: 매우 빠른 경제 성장\n포인트간의 간격이 조밀하다 = 변화가 더디다 // 포인트간의 간격이 넓다 = 변화가 빠르다.\n\n- 언뜻보기에는 우리에게 익숙한 라인플랏인듯 보이지만 의외로 정보를 해석할만한 요소가 있다.\n\n익스플로레이션형의 그래프는 그릴줄도 알아야 하지만 남이 그린 그래프를 해석할 수도 있어야함."
  },
  {
    "objectID": "posts/DV_09(1102).html#인구문제에-대한-편견",
    "href": "posts/DV_09(1102).html#인구문제에-대한-편견",
    "title": "DV 9주차",
    "section": "인구문제에 대한 편견",
    "text": "인구문제에 대한 편견\n- 주장1 (맬서스주의자): 가난한 나라들의 출산율이 너무 높음 \\(\\to\\) 세계인구가 90억까지 증가할 것이다. (현재 70억)\n- 주장2: 잘사는 나라에서는 애를 적게 낳음 \\(\\to\\) 고령화 문제"
  },
  {
    "objectID": "posts/DV_09(1102).html#에서-제기된-리들리의-메시지",
    "href": "posts/DV_09(1102).html#에서-제기된-리들리의-메시지",
    "title": "DV 9주차",
    "section": "<이성적 낙관주의자>에서 제기된 리들리의 메시지",
    "text": "<이성적 낙관주의자>에서 제기된 리들리의 메시지\n- 둘다 틀렸다.\n- 주장1의 반박: 가난한 나라의 출산율은 점점 감소하고 있음. (특히 가난하다가 막 부유해진 나라는 이러한 감소폭이 드라마틱함, ex: 브라질)\n- 주장2의 반박: 평균적으로 잘사는 국가들의 출산률이 매우 낮은것은 사실이나 최근들어 약간 증가하는 경향을 보임. (ex: 스웨덴, 영국, 노르웨이, 스페인)\n- 리들리의 주장: 결국 세계의 인구는 안정화 될 것 (증가하지도 감소하지도 않는다)\n- 리들리의 주장을 뒷받침하기 위해 그린 그림\n\n\n이 그림은 간단명료해 보이지만 리들리의 주장을 뒷받침하기에는 부족하다.\n그림에서 얻을 수 있는 정보: 인구변화를 연도별로 나열했더니 성장속도가 둔화된다는 사실\n리들리가 주장한 다양한 패턴은 이 그림에 보이지 않는다. (출산률이 회복되고 있다는 선진국이라든가, 브라질/인도와 같은 나라의 인구안정화에 대한 주장)\n\n\n카이로\n- 리들러의 메시지는 아래의 그림들이 더 잘 전달한다.\n\n\n스웨덴, 노르웨이 -> 출산률 증가\n브라질, 인도 -> 출산률 대폭감소\n\n\n\n소감\n- 어떠한 통계량 혹은 현상을 살펴볼때 그것의 부분집합들이 역시 그러한지 살펴보는것은 기본임 (그룹별로 파악하면 정반대의 결과가 나올 수 있음)\n- 중요한 선을 제외한 나머지는 회색처리(일러스트레이터 사용) 한 것이 시각적으로 우수하며, 인상적이었음\n- 과학적인 논문작업에 들어갈 그림이라면 임의로 회색처리한 것이 다소 비판을 받을 수 있음."
  },
  {
    "objectID": "posts/DV_09(1102).html#사례1-남미국가의-국방력",
    "href": "posts/DV_09(1102).html#사례1-남미국가의-국방력",
    "title": "DV 9주차",
    "section": "사례1: 남미국가의 국방력",
    "text": "사례1: 남미국가의 국방력\n- 아래는 남미국가들의 국방력을 시각화한 그림\n\n\n쓸모없는 그래픽\n뭐 기억나는 것이 있나요?\n\n- 아래가 더 우수한 그림이다. 더 정확한 비교를 할 수 있어요.\n\n- 그리고 위의 그림보다 아래의 그림이 더 우수한 시각화이다.\n\n\n브라질이 국방력도 우수하고 예산도 많이 투자하는 것 같지만 인구가 흑막인것 같다.\n\n- 흑막을 제거\n\n- 최종적으로 제안하는 그래프\n\n\n좌측하단: aes(x=‘인구’, y=‘군인수’, size=‘예산’)\n우측하단: 관심있는 그래프가 아님\n\n사실 저는 좌측하단의 그래프가 좋은 시각화라고 생각안해요\n- 1사분면의 의미: 인구도 높고 군인수도 많은 나라 (똑같은 정보임 의미가 없다. 마치 x축이 토익점수, y축이 텝스점수 같은느낌임)\n\n모든 점들이 직선에 몰려있다면? \\(\\to\\) 왜 2차원으로 표현함?\n\n- 저같으면 aes(x=‘예산(인구효과제거)’, y=‘군인수(인구효과제거)’,size=‘인구’)로 할것 같아요.\n\n1사분면의 의미: 예산도 많이 쓰고 군인수도 많은나라 = 콜롬비아.\n4사분면의 의미: 예산은 많이 쓰는데 군인수가 적은나라 = 브라질\n\n- 산점도에서 데이터를 한눈에 파악하고 특징을 요약하기 위해서는 X,Y를 너무 비슷한 성질의 변수로 설정하지마라.\n아래중 어떤것이 더 바람직한 그래프인가?\n\naes(x=‘토익’, y=‘텝스’, color=‘합/불’, shape=‘회사의종류’)\naes(x=‘토익’, y=‘GPA’, color=‘합/불’, shape=‘회사의종류’)"
  },
  {
    "objectID": "posts/DV_09(1102).html#사례2-스페인의-실업률",
    "href": "posts/DV_09(1102).html#사례2-스페인의-실업률",
    "title": "DV 9주차",
    "section": "사례2: 스페인의 실업률",
    "text": "사례2: 스페인의 실업률\n\n\n명암으로 왜 크기비교를 하는것인가?\n\n- 비교를 위해서는 바플랏이 더 우수하다."
  },
  {
    "objectID": "posts/DV_09(1102).html#사례3-버블의-남용",
    "href": "posts/DV_09(1102).html#사례3-버블의-남용",
    "title": "DV 9주차",
    "section": "사례3: 버블의 남용",
    "text": "사례3: 버블의 남용\n- 카이로교수님의 강의자료에 등장하는 그림\n- 회색이 befor, 검은색이 after\n\n\n크기비교는 바플랏으로 하는것이 아니다.\n\n- 우리눈은 작은원이 큰원의 절반정도 차지한다고 느껴진다.\n\n- 그렇지만 실제로는 아래와 같음\n\n- 버블차트는 크기를 왜곡시킨다.\n\n- 하지만 아래의 버블차트는 우수하다.\n\n- 선거지도는 수치비교에 별로 관심이 없다.\n- 대신에 민주당표와 공화당표가 어떤 지역에 몰렸는지 파악하는 것이중요\n- 따라서 aes중 가장 중요한 x,y를 모두 지역에 투자함"
  },
  {
    "objectID": "posts/DV_07(1019).html",
    "href": "posts/DV_07(1019).html",
    "title": "DV 7주차(2)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom plotnine import *"
  },
  {
    "objectID": "posts/DV_07(1019).html#자료생성",
    "href": "posts/DV_07(1019).html#자료생성",
    "title": "DV 7주차(2)",
    "section": "자료생성",
    "text": "자료생성\n기상자료개방포털: https://data.kma.go.kr/cmmn/main.do\n\n_df=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/temp.csv')\n_df\n\n\n\n\n\n  \n    \n      \n      지점번호\n      지점명\n      일시\n      평균기온(℃)\n      최고기온(℃)\n      최고기온시각\n      최저기온(℃)\n    \n  \n  \n    \n      0\n      146\n      전주\n      2020-01-01\n      -0.5\n      4.3\n      15:09\n      -6.4\n    \n    \n      1\n      146\n      전주\n      2020-01-02\n      1.4\n      6.5\n      14:12\n      -3.0\n    \n    \n      2\n      146\n      전주\n      2020-01-03\n      2.6\n      7.6\n      13:32\n      -0.5\n    \n    \n      3\n      146\n      전주\n      2020-01-04\n      2.0\n      7.7\n      13:51\n      -2.6\n    \n    \n      4\n      146\n      전주\n      2020-01-05\n      2.5\n      8.6\n      14:05\n      -3.2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      146\n      전주\n      2021-10-13\n      19.9\n      25.5\n      14:29\n      15.6\n    \n    \n      652\n      146\n      전주\n      2021-10-14\n      20.4\n      25.5\n      13:36\n      17.0\n    \n    \n      653\n      146\n      전주\n      2021-10-15\n      18.3\n      22.0\n      13:47\n      15.7\n    \n    \n      654\n      146\n      전주\n      2021-10-16\n      12.8\n      17.4\n      0:01\n      6.5\n    \n    \n      655\n      146\n      전주\n      2021-10-17\n      6.7\n      12.4\n      15:18\n      2.2\n    \n  \n\n656 rows × 7 columns\n\n\n\n- 평균기온만 선택\n\npd.Series(_df.columns)\n\n0       지점번호\n1        지점명\n2         일시\n3    평균기온(℃)\n4    최고기온(℃)\n5     최고기온시각\n6    최저기온(℃)\ndtype: object\n\n\n\ntemp=np.array(_df.iloc[:,3])"
  },
  {
    "objectID": "posts/DV_07(1019).html#숨은-진짜-상황1-온도-to-아이스크림-판매량",
    "href": "posts/DV_07(1019).html#숨은-진짜-상황1-온도-to-아이스크림-판매량",
    "title": "DV 7주차(2)",
    "section": "숨은 진짜 상황1: 온도 \\(\\to\\) 아이스크림 판매량",
    "text": "숨은 진짜 상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자\n아이스크림 판매량 = 20 + 2 x 온도 + ϵ\n\nnp.random.seed(1)\neps = np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2*temp + eps\n\n\nplt.plot(temp, icecream, 'o', alpha=0.2)\nplt.xlabel(\"temp\", size=15)\nplt.ylabel(\"icecream\", size=15)\n\nText(0, 0.5, 'icecream')"
  },
  {
    "objectID": "posts/DV_07(1019).html#숨은-진짜-상황2-온도-to-소아마비-반응수치",
    "href": "posts/DV_07(1019).html#숨은-진짜-상황2-온도-to-소아마비-반응수치",
    "title": "DV 7주차(2)",
    "section": "숨은 진짜 상황2: 온도 \\(\\to\\) 소아마비 반응수치",
    "text": "숨은 진짜 상황2: 온도 \\(\\to\\) 소아마비 반응수치\n- 아래와 같은 관계가 있다고 하자\n소아마비 반응수치 = 30 + 0.5 x 온도 + ϵ\n\nnp.random.seed(2) \neps=np.random.normal(size=len(temp),scale=1)\ndisease= 30 + 0.5 * temp + eps\n\n\nplt.plot(temp, disease, 'o', alpha=0.2)\nplt.xlabel(\"temp\", size=15)\nplt.ylabel(\"disease\", size=15)\n\nText(0, 0.5, 'disease')"
  },
  {
    "objectID": "posts/DV_07(1019).html#우리가-관측한-상황-온도는-은닉되어-있음",
    "href": "posts/DV_07(1019).html#우리가-관측한-상황-온도는-은닉되어-있음",
    "title": "DV 7주차(2)",
    "section": "우리가 관측한 상황 (온도는 은닉되어 있음)",
    "text": "우리가 관측한 상황 (온도는 은닉되어 있음)\n\nplt.plot(icecream,disease,'o',alpha=0.3)\nplt.xlabel(\"icecream\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\ncorr이 높아서 얼핏 생각하면 인과성이 있어보인다.\n\nnp.corrcoef(icecream, disease)\n\narray([[1.        , 0.86298975],\n       [0.86298975, 1.        ]])\n\n\ncorr = 0.86"
  },
  {
    "objectID": "posts/DV_07(1019).html#직관-여름만-뽑아서-plot해보자",
    "href": "posts/DV_07(1019).html#직관-여름만-뽑아서-plot해보자",
    "title": "DV 7주차(2)",
    "section": "직관: 여름만 뽑아서 plot해보자",
    "text": "직관: 여름만 뽑아서 plot해보자\n- temp>25 (여름으로 간주) 인 관측치만 plot\n\nplt.plot(icecream[temp>25], disease[temp>25], 'o', alpha=0.2)\n\n\n\n\n상관관계가 없어보인다?\n\nnp.corrcoef(icecream[temp>25], disease[temp>25])\n\narray([[1.        , 0.26612659],\n       [0.26612659, 1.        ]])\n\n\n- 전체적인 산점도\n\nfig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2,figsize=(8,6)) \nax1.plot(temp,icecream,'o',alpha=0.2); ax1.set_xlabel('temp'); ax1.set_ylabel('icecream'); ax1.set_title(\"hidden1\")\nax2.plot(temp,disease,'o',alpha=0.2); ax2.set_xlabel('temp'); ax2.set_ylabel('disease'); ax2.set_title(\"hidden2\")\nax3.plot(icecream,disease,'o',alpha=0.2); ax3.set_xlabel('icecream'); ax3.set_ylabel('disease'); ax3.set_title(\"observed\")\nax4.plot(icecream,disease,'o',alpha=0.2); ax4.set_xlabel('icecream'); ax4.set_ylabel('disease'); ax4.set_title(\"observed\")\nax4.plot(icecream[temp>25],disease[temp>25],'o',label='temp>25')\nax4.legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/DV_07(1019).html#ggplot-온도구간을-세분화-하여-시각화",
    "href": "posts/DV_07(1019).html#ggplot-온도구간을-세분화-하여-시각화",
    "title": "DV 7주차(2)",
    "section": "ggplot: 온도구간을 세분화 하여 시각화",
    "text": "ggplot: 온도구간을 세분화 하여 시각화\n- 목표: 모든 온도구간에 대하여 각각 색을 다르게 하여 그려보자.\n\n사실 지금 변수는 온도, 아이스크림판매량, 소아마비\n온도가 유사한 지역을 색으로 묶으면 3차원 플랏이 가능함"
  },
  {
    "objectID": "posts/DV_07(1019).html#df로-자료정리",
    "href": "posts/DV_07(1019).html#df로-자료정리",
    "title": "DV 7주차(2)",
    "section": "df로 자료정리",
    "text": "df로 자료정리\n\ndf=pd.DataFrame({'temp':temp, 'icecream':icecream, 'disease' : disease})\ndf\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n    \n  \n\n656 rows × 3 columns\n\n\n\n\n구간세분화\n온도를 봄 여름 가을 경루.. 확인하기 위해 구간을 확인하자\n\nplt.hist(df.temp)\n\n(array([  3.,   9.,  29.,  60.,  92.,  86.,  65.,  93., 139.,  80.]),\n array([-12.4 ,  -8.16,  -3.92,   0.32,   4.56,   8.8 ,  13.04,  17.28,\n         21.52,  25.76,  30.  ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\ndf.temp.hist() # 위에도 되고 이거도 되고\n\n<AxesSubplot:>\n\n\n\n\n\n- 구간을 5정도로 하면 적당\n\ndef cut(x): #\n    if x<0: \n        y='Temp: <0'\n    elif x<5: \n        y='Temp: 0~5'\n    elif x<10: \n        y='Temp: 5~10'\n    elif x<15: \n        y='Temp: 10~15'\n    elif x<20:\n        y='Temp: 15~20'\n    elif x<25: \n        y='Temp: 20~25'\n    else: \n        y='Temp: >30'\n    return y \n\n\ndf.temp\n\n0      -0.5\n1       1.4\n2       2.6\n3       2.0\n4       2.5\n       ... \n651    19.9\n652    20.4\n653    18.3\n654    12.8\n655     6.7\nName: temp, Length: 656, dtype: float64\n\n\n\ncut(-0.5)\n\n'Temp: <0'\n\n\n\ncut(4)\n\n'Temp: 0~5'\n\n\n\ndf.assign(temp2=list(map(cut,df.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\n\nggplot\n\nfig = ggplot(data=df.assign(temp2=list(map(cut,df.temp))))\np1 = geom_point(aes(x='icecream', y='disease', color='temp2'))\nl1 = geom_smooth(aes(x='icecream', y='disease', color='temp2')) # color별 추체선\nfig+p1+l1\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8764688308729)>\n\n\n\n각 온도별로 추세선 기울기가 거의 0이다. \\(\\to\\) 온도가 비슷한 구간별로 묶어서 보니까 상관관계가 없다는 것!\n아이스크림 판매량과 소아마비의 corr은 유의미해 보였지만, 온도를 통제하였을 경우 아이스크림의 판매량과 소아마비 반응수치의 corr은 유의미해보이지 않다.\n\n\n\n해석\n- 해피앤딩: 온도를 통제하니까 아이스크림과 질병은 관련이 없어보인다. \\(\\to\\) 아이스크림을 먹으면 소아마비를 유발한다는 이상한 결론이 나올뻔 했지만 우리는 온도라는 흑막을 잘 찾았고 결과적으로 “온도->아이스크림판매량,소아마비” 이라는 합리적인 진리를 얻을 수 있었다.\n\n온도와 같은 변수를 은닉변수라고 한다.\n\n- 또 다른 흑막? 고려할 흑막이 온도뿐이라는 보장이 어디있지? 사실 흑막2, 흑막3이 있어서 그런 흑막들을 고려하다보니까 아이스크림과 소아마비사이의 상관관계가 다시 보이면 어떡하지?\n\n이러한 이유 때문에 상관계수로 인과성을 유추하는건 사실상 불가능.\n그런데 이론적으로는 “세상의 모든 은닉변수를 통제하였을 경우에도 corr(X,Y)의 값이 1에 가깝다면 그때는 인과성이 있다고 봐도 무방함, (물론 이 경우에도 무엇이 원인인지는 통계적으로 따지는것이 불가)” 이라고 주장할 수 있다. 즉 모든 흑막을 제거한다면 “상관성=인과성”이다.\n\n- 실험계획법, 인과추론: 세상의 모든 흑막을 제거하는건 상식적으로 불가능\n\n피셔의주장(실험계획법): 그런데 실험계획을 잘하면 흑막을 제거한 효과가 있음 (무작위로 사람뽑아서 담배를 피우게 한다든가)\n인과추론: 실험계획이 사실상 불가능한 경우가 있음 \\(\\to\\) 모인 데이터에서 최대한 흑막2,3,4,.. 등이 비슷한 그룹끼리 “매칭”을 시킨다!\n\n실험계획법 - 내가 데이터를 모아야함/ 잘 생각해서 계획적으로\n인과추론 - 모인데이터를 활용 / 데이터의 양이 많아야하는 다넘이 있지만 실험은 하지 않아도 된다는 장점"
  },
  {
    "objectID": "posts/DV_07(1019).html#만약-아이스크림과-소아마비가-관련있는-경우라면",
    "href": "posts/DV_07(1019).html#만약-아이스크림과-소아마비가-관련있는-경우라면",
    "title": "DV 7주차(2)",
    "section": "만약 아이스크림과 소아마비가 관련있는 경우라면?",
    "text": "만약 아이스크림과 소아마비가 관련있는 경우라면?\n- 온도는 아이스크림 판매에 여전히 영향을 주지만\n아이스크림 판매량 = 20 + 2 x 온도 + ϵ\n\nnp.random.seed(1)\neps=np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2 * temp + eps \n\n- 수영장이 원인이 아니라 진짜 아이스크림을 먹고 소아마비에 걸린상황이라면?\n소아마비 반응수치 = 30 + 0 x 온도 + 0.15 x 아이스크림판매랑 + ϵ\n\nnp.random.seed(2) \neps = np.random.normal(size=len(temp),scale=2)\ndisease= 30+ 0*temp + 0.15*icecream + eps\n\n\ndf2=pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf2.assign(temp2=list(map(cut,df2.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      34.453002\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      32.389832\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      28.715350\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      35.271089\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      31.461240\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.693811\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.924088\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      41.765212\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.842022\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      37.715537\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\nggplot(data=df2.assign(temp2=list(map(cut,df2.temp))))+\\\ngeom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.2)+\\\ngeom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8764688192609)>\n\n\n\ndf.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.975609\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.862990\n    \n    \n      disease\n      0.975609\n      0.862990\n      1.000000\n    \n  \n\n\n\n\n\ndf2.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.725505\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.830539\n    \n    \n      disease\n      0.725505\n      0.830539\n      1.000000\n    \n  \n\n\n\n\n단순 corr을 봐서는 “온도->아이스크림,소아마비” 인지, “온도->아이스크림->소아마비” 인지 알기 어렵다."
  },
  {
    "objectID": "posts/DV_4(0926).html",
    "href": "posts/DV_4(0926).html",
    "title": "DV 4주차(1)",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/DV_4(0926).html#예시자료",
    "href": "posts/DV_4(0926).html#예시자료",
    "title": "DV 4주차(1)",
    "section": "예시자료",
    "text": "예시자료\n- 예시1\n\nx1 = np.random.uniform(low=0, high=1, size=10000)  # 0~1사이의 10000개\ny1 = np.random.uniform(low=0, high=1, size=10000) \n\n\nplt.plot(x1,y1,',')\nplt.plot(x1[0], y1[0],'or')\n\n\n\n\n- 예시2 (원)\n\n_r2 = x1**2 + y1**2 # 반지름\n_r2\n\narray([0.32841936, 0.65211343, 0.8620744 , ..., 0.99310561, 0.35628571,\n       0.32995271])\n\n\n\nlen(_r2)\n\n10000\n\n\n\nx2=x1[_r2<1]\ny2=y1[_r2<1]\n\n\nplt.plot(x2,y2,',')\n\n\n\n\n- 예시3 (이변량정규분포)\n\nx3 = np.random.randn(10000)\ny3 = np.random.randn(10000)\n\n\nplt.plot(x3,y3,',')"
  },
  {
    "objectID": "posts/DV_4(0926).html#상관계수",
    "href": "posts/DV_4(0926).html#상관계수",
    "title": "DV 4주차(1)",
    "section": "상관계수",
    "text": "상관계수\n예시1, 예시2, 예시3의 산점도를 보고 상관계수가 얼마인지 예상해보라. 실제 계산결과와 확인하라.\n\nnp.corrcoef([x1,y1])\n\narray([[1.        , 0.01268214],\n       [0.01268214, 1.        ]])\n\n\n\nnp.corrcoef([x2,y2])\n\narray([[ 1.        , -0.28666195],\n       [-0.28666195,  1.        ]])\n\n\n\nnp.corrcoef([x3,y3])\n\narray([[1.        , 0.00827362],\n       [0.00827362, 1.        ]])\n\n\n독립을 따져보자.\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(x1,y1,',')\nax[1].plot(x2,y2,',')\n\n\n\n\n\ndef g(intval, data, ax, col = 'r'):\n    a,b = intval\n    x,y = data\n    idx = (a<x) & (x<b)\n    ax.plot(x[idx], y[idx],',',color=col)\n\n\nfig\n\n\n\n\n\ng([-0.1,0.1],[x1,y1],ax[0])\ng([-0.1,0.1],[x2,y2],ax[1])\nfig\n\n\n\n\n\ng([0.79,0.99],[x1,y1],ax[0],col='m')\ng([0.79,0.99],[x2,y2],ax[1],col='m')\nfig\n\n\n\n\n- 예시3\n\nplt.plot(x3,y3,',')\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(x3,y3,',',color='gray')     # g함수 사용하기 위해 이렇게 해보자\n\n\n\n\n\ng([-2.5,-1.5],[x3,y3],ax,col='r')\nfig\n\n\n\n\n\ng([-2.5,-1.5],[x3,y3],ax,col='r')\ng([-0.5,+0.5],[x3,y3],ax,col='b')\ng([+1.5,+2.5],[x3,y3],ax,col='g')\nfig\n\n\n\n\n\nidx = (-0.5<x3) & (x3<0.5)\nplt.hist(y3[idx])  # 위의 파란색을 뽑아보자\n\n(array([   5.,   32.,  188.,  512.,  938., 1054.,  722.,  303.,   79.,\n          16.]),\n array([-3.81904376, -3.09056613, -2.36208849, -1.63361085, -0.90513321,\n        -0.17665557,  0.55182207,  1.28029971,  2.00877735,  2.73725499,\n         3.46573263]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nidx = (-0.5<x3) & (x3<0.5)\nplt.hist(y3[idx]);  # 맨 뒤 세미콜론 붙이면 위의 글씨 안나옴\n\n\n\n\n\ndef h(intval, data, ax, col):\n    a,b = intval\n    x,y = data\n    idx = (a<x) &  (x<b)\n    ax.hist(y[idx], color=col)\n\n\nfig,ax = plt.subplots(5,2,figsize=(8,16))\nax[0,0].plot(x3,y3,',',color='gray'); g([-2.5,-1.5],[x3,y3],ax[0,0],col='r')\nax[1,0].plot(x3,y3,',',color='gray'); g([-1.5,-0.5],[x3,y3],ax[1,0],col='g')\nax[2,0].plot(x3,y3,',',color='gray'); g([-0.5,+0.5],[x3,y3],ax[2,0],col='b')\nax[3,0].plot(x3,y3,',',color='gray'); g([+0.5,+1.5],[x3,y3],ax[3,0],col='m')\nax[4,0].plot(x3,y3,',',color='gray'); g([+1.5,+2.5],[x3,y3],ax[4,0],col='lime')\n\nh([-2.5,-1.5],[x3,y3],ax[0,1],col='r')\nh([-1.5,-0.5],[x3,y3],ax[1,1],col='g')\nh([-0.5,+0.5],[x3,y3],ax[2,1],col='b')\nh([+0.5,+1.5],[x3,y3],ax[3,1],col='m')\nh([+1.5,+2.5],[x3,y3],ax[4,1],col='lime')"
  },
  {
    "objectID": "posts/DV_4(0926).html#그림만-보고-싶을때",
    "href": "posts/DV_4(0926).html#그림만-보고-싶을때",
    "title": "DV 4주차(1)",
    "section": "그림만 보고 싶을때",
    "text": "그림만 보고 싶을때\n\nplt.plot([0,1,2,3],[2,3,4,1])\n\n\n\n\n\nplt.plot([2,3,4,1])    # [0,1,2,3] 이 기본 default 값이므로 생략 가능\n\n\n\n\n\nplt.plot([2,3,4,1]);   # 그림 위에 올라가는거 없어짐"
  },
  {
    "objectID": "posts/DV_4(0926).html#marker-size-line-width",
    "href": "posts/DV_4(0926).html#marker-size-line-width",
    "title": "DV 4주차(1)",
    "section": "marker size, line width",
    "text": "marker size, line width\n\nplt.plot([2,3,4,1],'o',markersize=13)   # markersize = ms 라고 써도 됨\n\n\n\n\n\nplt.plot([2,3,4,1],'--',lw=12)"
  },
  {
    "objectID": "posts/DV_4(0926).html#label-legend",
    "href": "posts/DV_4(0926).html#label-legend",
    "title": "DV 4주차(1)",
    "section": "label, legend",
    "text": "label, legend\n\nplt.plot([2,3,4,1],'--o', label='A')\nplt.plot([4,3.2,1,3],'--o', label='B')\nplt.legend()  # 범례.. 위의 label\n\n<matplotlib.legend.Legend at 0x7fbc8767d050>"
  },
  {
    "objectID": "posts/DV_4(0926).html#색깔조정-c0-c1",
    "href": "posts/DV_4(0926).html#색깔조정-c0-c1",
    "title": "DV 4주차(1)",
    "section": "색깔조정 (C0, C1,…)",
    "text": "색깔조정 (C0, C1,…)\n\nplt.plot([2,3,4,1],'--o', label='A', color='C1')\nplt.plot([4,3.2,1,3],'--o', label='B', color='C0')  # 그래프 위아래의 선 색 변경시 color='C0'\nplt.legend() \n\n<matplotlib.legend.Legend at 0x7fbc86d99750>"
  },
  {
    "objectID": "posts/DV_4(0926).html#title",
    "href": "posts/DV_4(0926).html#title",
    "title": "DV 4주차(1)",
    "section": "title",
    "text": "title\n- 방법1\n\nplt.plot([1,2,3,2])\nplt.title('title')\n\nText(0.5, 1.0, 'title')\n\n\n\n\n\n- 방법2\n\nfig, ax = plt.subplots()\nax.set_title('asdf')\n\nText(0.5, 1.0, 'asdf')"
  },
  {
    "objectID": "posts/DV_4(0926).html#suptitle",
    "href": "posts/DV_4(0926).html#suptitle",
    "title": "DV 4주차(1)",
    "section": "suptitle",
    "text": "suptitle\n\nfig, ax = plt.subplots(2,2)\nax[0,0].plot([1,2,3,2],'--o',label='A',color='C0')\nax[0,0].set_title('(a)')\nax[0,1].plot([3,2.1,1,3],'--o',label='B',color='C1')\nax[0,1].set_title('(b)')\nax[1,0].plot([-3,-2.1,-1,-3],'--o',label='B',color='C2')\nax[1,0].set_title('(c)')\nax[1,1].plot([3,-2.1,1,-3],'--o',label='B',color='C3')\nax[1,1].set_title('(d)')\n#plt.suptitle('suptitle') 둘다된다\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')"
  },
  {
    "objectID": "posts/DV_4(0926).html#tight_layout",
    "href": "posts/DV_4(0926).html#tight_layout",
    "title": "DV 4주차(1)",
    "section": "tight_layout()",
    "text": "tight_layout()\n\nfig, ax = plt.subplots(2,2)\nax[0,0].plot([1,2,3,2],'--o',label='A',color='C0')\nax[0,0].set_title('(a)')\nax[0,1].plot([3,2.1,1,3],'--o',label='B',color='C1')\nax[0,1].set_title('(b)')\nax[1,0].plot([-3,-2.1,-1,-3],'--o',label='B',color='C2')\nax[1,0].set_title('(c)')\nax[1,1].plot([3,-2.1,1,-3],'--o',label='B',color='C3')\nax[1,1].set_title('(d)')\nfig.suptitle('suptitle')\nfig.tight_layout()   # 컴퓨터에서 알아서 이쁘게 레이아웃 설정"
  },
  {
    "objectID": "posts/DV_4(0926).html#fig-ax-plt-소속",
    "href": "posts/DV_4(0926).html#fig-ax-plt-소속",
    "title": "DV 4주차(1)",
    "section": "fig, ax, plt 소속",
    "text": "fig, ax, plt 소속\n예시\n\nfig, ax = plt.subplots()\nax.plot([1,2,3,1])\n\n\n\n\n- fig에는 있고 ax에는 없는 것\nadd_axes, tight_layout, suptitle, …\n\nset(dir(fig)) - set(dir(ax))    # fig에만 있는 함수\n\n{'_add_axes_internal',\n '_align_label_groups',\n '_axobservers',\n '_axstack',\n '_button_pick_id',\n '_cachedRenderer',\n '_canvas_callbacks',\n '_constrained',\n '_constrained_layout_pads',\n '_dpi',\n '_get_dpi',\n '_get_draw_artists',\n '_gridspecs',\n '_localaxes',\n '_normalize_grid_string',\n '_original_dpi',\n '_process_projection_requirements',\n '_repr_html_',\n '_scroll_pick_id',\n '_set_dpi',\n '_suplabels',\n '_suptitle',\n '_supxlabel',\n '_supylabel',\n '_tight_parameters',\n 'add_axes',\n 'add_axobserver',\n 'add_gridspec',\n 'add_subfigure',\n 'add_subplot',\n 'align_labels',\n 'align_xlabels',\n 'align_ylabels',\n 'autofmt_xdate',\n 'bbox_inches',\n 'canvas',\n 'clf',\n 'colorbar',\n 'delaxes',\n 'dpi',\n 'dpi_scale_trans',\n 'draw_without_rendering',\n 'execute_constrained_layout',\n 'figbbox',\n 'figimage',\n 'frameon',\n 'gca',\n 'get_axes',\n 'get_constrained_layout',\n 'get_constrained_layout_pads',\n 'get_dpi',\n 'get_edgecolor',\n 'get_figheight',\n 'get_figwidth',\n 'get_frameon',\n 'get_linewidth',\n 'get_size_inches',\n 'get_tight_layout',\n 'ginput',\n 'legends',\n 'number',\n 'savefig',\n 'sca',\n 'set_canvas',\n 'set_constrained_layout',\n 'set_constrained_layout_pads',\n 'set_dpi',\n 'set_edgecolor',\n 'set_figheight',\n 'set_figwidth',\n 'set_frameon',\n 'set_linewidth',\n 'set_size_inches',\n 'set_tight_layout',\n 'show',\n 'subfigs',\n 'subfigures',\n 'subplot_mosaic',\n 'subplotpars',\n 'subplots',\n 'subplots_adjust',\n 'suppressComposite',\n 'suptitle',\n 'supxlabel',\n 'supylabel',\n 'tight_layout',\n 'transFigure',\n 'transSubfigure',\n 'waitforbuttonpress'}\n\n\n- ax에는 있고 fig에는 없는 것\nboxplot, hist, plot, set_title, …\n\nset(dir(ax)) - set(dir(fig))   # ax만 있는 함수\n\n{'ArtistList',\n '_add_text',\n '_adjustable',\n '_alias_map',\n '_anchor',\n '_aspect',\n '_autoscaleXon',\n '_autoscaleYon',\n '_autotitlepos',\n '_axes',\n '_axes_class',\n '_axes_locator',\n '_axis_names',\n '_axisbelow',\n '_box_aspect',\n '_check_no_units',\n '_children',\n '_colorbars',\n '_convert_dx',\n '_current_image',\n '_deprecate_noninstance',\n '_facecolor',\n '_fill_between_x_or_y',\n '_frameon',\n '_gen_axes_patch',\n '_gen_axes_spines',\n '_get_axis_list',\n '_get_axis_map',\n '_get_lines',\n '_get_pan_points',\n '_get_patches_for_fill',\n '_get_view',\n '_gridOn',\n '_init_axis',\n '_label_outer_xaxis',\n '_label_outer_yaxis',\n '_left_title',\n '_make_twin_axes',\n '_mouseover_set',\n '_navigate',\n '_navigate_mode',\n '_originalPosition',\n '_parse_scatter_color_args',\n '_pcolor_grid_deprecation_helper',\n '_pcolorargs',\n '_position',\n '_prepare_view_from_bbox',\n '_process_unit_info',\n '_projection_init',\n '_quiver_units',\n '_rasterization_zorder',\n '_remove_legend',\n '_request_autoscale_view',\n '_right_title',\n '_sci',\n '_set_lim_and_transforms',\n '_set_position',\n '_set_title_offset_trans',\n '_set_view',\n '_set_view_from_bbox',\n '_shared_axes',\n '_sharex',\n '_sharey',\n '_stale_viewlims',\n '_subplotspec',\n '_twinned_axes',\n '_unit_change_handler',\n '_unstale_viewLim',\n '_update_image_limits',\n '_update_line_limits',\n '_update_patch_limits',\n '_update_title_position',\n '_update_transScale',\n '_use_sticky_edges',\n '_validate_converted_limits',\n '_viewLim',\n '_xaxis_transform',\n '_xmargin',\n '_yaxis_transform',\n '_ymargin',\n 'acorr',\n 'add_child_axes',\n 'add_collection',\n 'add_container',\n 'add_image',\n 'add_line',\n 'add_patch',\n 'add_table',\n 'angle_spectrum',\n 'annotate',\n 'apply_aspect',\n 'arrow',\n 'autoscale',\n 'autoscale_view',\n 'axhline',\n 'axhspan',\n 'axis',\n 'axison',\n 'axline',\n 'axvline',\n 'axvspan',\n 'bar',\n 'bar_label',\n 'barbs',\n 'barh',\n 'boxplot',\n 'broken_barh',\n 'bxp',\n 'can_pan',\n 'can_zoom',\n 'change_geometry',\n 'child_axes',\n 'cla',\n 'clabel',\n 'cohere',\n 'collections',\n 'containers',\n 'contains_point',\n 'contour',\n 'contourf',\n 'csd',\n 'dataLim',\n 'drag_pan',\n 'end_pan',\n 'errorbar',\n 'eventplot',\n 'figbox',\n 'fill',\n 'fill_between',\n 'fill_betweenx',\n 'fmt_xdata',\n 'fmt_ydata',\n 'format_coord',\n 'format_xdata',\n 'format_ydata',\n 'get_adjustable',\n 'get_anchor',\n 'get_aspect',\n 'get_autoscale_on',\n 'get_autoscalex_on',\n 'get_autoscaley_on',\n 'get_axes_locator',\n 'get_axisbelow',\n 'get_box_aspect',\n 'get_data_ratio',\n 'get_fc',\n 'get_frame_on',\n 'get_geometry',\n 'get_gridspec',\n 'get_images',\n 'get_legend',\n 'get_legend_handles_labels',\n 'get_lines',\n 'get_navigate',\n 'get_navigate_mode',\n 'get_position',\n 'get_rasterization_zorder',\n 'get_renderer_cache',\n 'get_shared_x_axes',\n 'get_shared_y_axes',\n 'get_subplotspec',\n 'get_title',\n 'get_xaxis',\n 'get_xaxis_text1_transform',\n 'get_xaxis_text2_transform',\n 'get_xaxis_transform',\n 'get_xbound',\n 'get_xgridlines',\n 'get_xlabel',\n 'get_xlim',\n 'get_xmajorticklabels',\n 'get_xminorticklabels',\n 'get_xscale',\n 'get_xticklabels',\n 'get_xticklines',\n 'get_xticks',\n 'get_yaxis',\n 'get_yaxis_text1_transform',\n 'get_yaxis_text2_transform',\n 'get_yaxis_transform',\n 'get_ybound',\n 'get_ygridlines',\n 'get_ylabel',\n 'get_ylim',\n 'get_ymajorticklabels',\n 'get_yminorticklabels',\n 'get_yscale',\n 'get_yticklabels',\n 'get_yticklines',\n 'get_yticks',\n 'grid',\n 'has_data',\n 'hexbin',\n 'hist',\n 'hist2d',\n 'hlines',\n 'ignore_existing_data_limits',\n 'imshow',\n 'in_axes',\n 'indicate_inset',\n 'indicate_inset_zoom',\n 'inset_axes',\n 'invert_xaxis',\n 'invert_yaxis',\n 'is_first_col',\n 'is_first_row',\n 'is_last_col',\n 'is_last_row',\n 'label_outer',\n 'legend_',\n 'locator_params',\n 'loglog',\n 'magnitude_spectrum',\n 'margins',\n 'matshow',\n 'minorticks_off',\n 'minorticks_on',\n 'name',\n 'numCols',\n 'numRows',\n 'pcolor',\n 'pcolorfast',\n 'pcolormesh',\n 'phase_spectrum',\n 'pie',\n 'plot',\n 'plot_date',\n 'psd',\n 'quiver',\n 'quiverkey',\n 'redraw_in_frame',\n 'relim',\n 'reset_position',\n 'scatter',\n 'secondary_xaxis',\n 'secondary_yaxis',\n 'semilogx',\n 'semilogy',\n 'set_adjustable',\n 'set_anchor',\n 'set_aspect',\n 'set_autoscale_on',\n 'set_autoscalex_on',\n 'set_autoscaley_on',\n 'set_axes_locator',\n 'set_axis_off',\n 'set_axis_on',\n 'set_axisbelow',\n 'set_box_aspect',\n 'set_fc',\n 'set_frame_on',\n 'set_navigate',\n 'set_navigate_mode',\n 'set_position',\n 'set_prop_cycle',\n 'set_rasterization_zorder',\n 'set_subplotspec',\n 'set_title',\n 'set_xbound',\n 'set_xlabel',\n 'set_xlim',\n 'set_xmargin',\n 'set_xscale',\n 'set_xticklabels',\n 'set_xticks',\n 'set_ybound',\n 'set_ylabel',\n 'set_ylim',\n 'set_ymargin',\n 'set_yscale',\n 'set_yticklabels',\n 'set_yticks',\n 'sharex',\n 'sharey',\n 'specgram',\n 'spines',\n 'spy',\n 'stackplot',\n 'stairs',\n 'start_pan',\n 'stem',\n 'step',\n 'streamplot',\n 'table',\n 'tables',\n 'tick_params',\n 'ticklabel_format',\n 'title',\n 'titleOffsetTrans',\n 'transAxes',\n 'transData',\n 'transLimits',\n 'transScale',\n 'tricontour',\n 'tricontourf',\n 'tripcolor',\n 'triplot',\n 'twinx',\n 'twiny',\n 'update_datalim',\n 'update_params',\n 'use_sticky_edges',\n 'viewLim',\n 'violin',\n 'violinplot',\n 'vlines',\n 'xaxis',\n 'xaxis_date',\n 'xaxis_inverted',\n 'xcorr',\n 'yaxis',\n 'yaxis_date',\n 'yaxis_inverted'}\n\n\n\nset(dir(ax)) & set(dir(fig))   # 교집합\n\n{'_PROPERTIES_EXCLUDED_FROM_SET',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_agg_filter',\n '_alpha',\n '_animated',\n '_callbacks',\n '_clipon',\n '_clippath',\n '_cm_set',\n '_default_contains',\n '_gci',\n '_get_clipping_extent_bbox',\n '_gid',\n '_in_layout',\n '_label',\n '_mouseover',\n '_path_effects',\n '_picker',\n '_rasterized',\n '_remove_method',\n '_set_alpha_for_array',\n '_set_artist_props',\n '_set_gc_clip',\n '_sketch',\n '_snap',\n '_stale',\n '_sticky_edges',\n '_tight',\n '_transform',\n '_transformSet',\n '_update_set_signature_and_docstring',\n '_url',\n '_visible',\n 'add_artist',\n 'add_callback',\n 'artists',\n 'axes',\n 'bbox',\n 'callbacks',\n 'clear',\n 'clipbox',\n 'contains',\n 'convert_xunits',\n 'convert_yunits',\n 'draw',\n 'draw_artist',\n 'figure',\n 'findobj',\n 'format_cursor_data',\n 'get_agg_filter',\n 'get_alpha',\n 'get_animated',\n 'get_children',\n 'get_clip_box',\n 'get_clip_on',\n 'get_clip_path',\n 'get_cursor_data',\n 'get_default_bbox_extra_artists',\n 'get_facecolor',\n 'get_figure',\n 'get_gid',\n 'get_in_layout',\n 'get_label',\n 'get_path_effects',\n 'get_picker',\n 'get_rasterized',\n 'get_sketch_params',\n 'get_snap',\n 'get_tightbbox',\n 'get_transform',\n 'get_transformed_clip_path_and_affine',\n 'get_url',\n 'get_visible',\n 'get_window_extent',\n 'get_zorder',\n 'have_units',\n 'images',\n 'is_transform_set',\n 'legend',\n 'lines',\n 'mouseover',\n 'patch',\n 'patches',\n 'pchanged',\n 'pick',\n 'pickable',\n 'properties',\n 'remove',\n 'remove_callback',\n 'set',\n 'set_agg_filter',\n 'set_alpha',\n 'set_animated',\n 'set_clip_box',\n 'set_clip_on',\n 'set_clip_path',\n 'set_facecolor',\n 'set_figure',\n 'set_gid',\n 'set_in_layout',\n 'set_label',\n 'set_path_effects',\n 'set_picker',\n 'set_rasterized',\n 'set_sketch_params',\n 'set_snap',\n 'set_transform',\n 'set_url',\n 'set_visible',\n 'set_zorder',\n 'stale',\n 'stale_callback',\n 'sticky_edges',\n 'text',\n 'texts',\n 'update',\n 'update_from',\n 'zorder'}\n\n\n- plt는 대부분 다 있음. (의미상 명확한건 대충 알아서 fig, ax에 접근해서 처리해준다)\n\nplt.tight_layout, plt.suptitle, plt.boxplot, plt.hist, plot.plot\nplt.set_title 은 없지만 plt.title 은 있음\nplt.add_axes 는 없음..\n\n\nset(dir(plt)) & {'add_axes'}\n\nset()"
  },
  {
    "objectID": "posts/DV_4(0926).html#x축-y축-label-설정",
    "href": "posts/DV_4(0926).html#x축-y축-label-설정",
    "title": "DV 4주차(1)",
    "section": "x축, y축 label 설정",
    "text": "x축, y축 label 설정\n\nfig,ax = plt.subplots()\nax.plot([1,2,3,2])\n#ax.set_xlabel('x',size=36, style='italic')\n_dct = {'size':36, 'family':'serif', 'style':'italic'}  #family:글꼴\nax.set_xlabel('x',_dct)  #옵션을 딕셔너리 형태로 해서 이렇게 표현도 가능\n\nText(0.5, 0, 'x')\n\n\n\n\n\n\nax.xaxis.set_label_text('xlabel',size=16,family='serif',weight=1000,style='italic')\n#_fontsettings={'size':16,'family':'serif','weight'=1000,'style':'italic'}\n#ax.xaxis.set_label_text('xlabel',_fontsettings)\nfig\n\n# weight 굵음\n# xaxis 도 가능.. (x축)\n\n\n\n\n폰트ref : https://matplotlib.org/stable/api/font_manager_api.html#matplotlib.font_manager.FontProperties\n\nsize:\nfontweight: 0~1000\nfamily: ‘serif’, ‘sans-serif’, ‘monospace’\nstyle: ‘normal’, ‘italic’\n\n\nax.set_xlabel??\n\n\nSignature: ax.set_xlabel(xlabel, fontdict=None, labelpad=None, *, loc=None, **kwargs)\nSource:   \n    def set_xlabel(self, xlabel, fontdict=None, labelpad=None, *,\n                   loc=None, **kwargs):\n        \"\"\"\n        Set the label for the x-axis.\n        Parameters\n        ----------\n        xlabel : str\n            The label text.\n        labelpad : float, default: :rc:`axes.labelpad`\n            Spacing in points from the Axes bounding box including ticks\n            and tick labels.  If None, the previous value is left as is.\n        loc : {'left', 'center', 'right'}, default: :rc:`xaxis.labellocation`\n            The label position. This is a high-level alternative for passing\n            parameters *x* and *horizontalalignment*.\n        Other Parameters\n        ----------------\n        **kwargs : `.Text` properties\n            `.Text` properties control the appearance of the label.\n        See Also\n        --------\n        text : Documents the properties supported by `.Text`.\n        \"\"\"\n        if labelpad is not None:\n            self.xaxis.labelpad = labelpad\n        protected_kw = ['x', 'horizontalalignment', 'ha']\n        if {*kwargs} & {*protected_kw}:\n            if loc is not None:\n                raise TypeError(f\"Specifying 'loc' is disallowed when any of \"\n                                f\"its corresponding low level keyword \"\n                                f\"arguments ({protected_kw}) are also \"\n                                f\"supplied\")\n        else:\n            loc = (loc if loc is not None\n                   else mpl.rcParams['xaxis.labellocation'])\n            _api.check_in_list(('left', 'center', 'right'), loc=loc)\n            if loc == 'left':\n                kwargs.update(x=0, horizontalalignment='left')\n            elif loc == 'center':\n                kwargs.update(x=0.5, horizontalalignment='center')\n            elif loc == 'right':\n                kwargs.update(x=1, horizontalalignment='right')\n        return self.xaxis.set_label_text(xlabel, fontdict, **kwargs)\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py\nType:      method"
  },
  {
    "objectID": "posts/DV_6(1012).html",
    "href": "posts/DV_6(1012).html",
    "title": "DV 6주차",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "posts/DV_6(1012).html#lambda",
    "href": "posts/DV_6(1012).html#lambda",
    "title": "DV 6주차",
    "section": "lambda",
    "text": "lambda\n- 예제1: 람다표현식 (lambda expression) 자체가 하나의 오브젝트임\n\n(lambda x: (x-2)**2)  # lambda가 실행되는 순간 메모리상에 함수 오브젝트가 저장됨\n\n<function __main__.<lambda>(x)>\n\n\n\nlambda x: (x-2)**2 는 \\(lambda(x)=(x-2)^2\\) 의 느낌으로 기억하면 쉬움\n\n(사용방법)\n\n(lambda x: (x-2)**2)(2)  # 입력 2-> 출력 (2-2)^2 = 0\n\n0\n\n\n\n(lambda x: (x-2)**2)(4)  # 입력 4-> 출력 (4-2)^2 = 4\n\n4\n\n\n- 예제2: 람다표현식에 이름을 줄 수 있음\n\nf = lambda x: (x-2)**2\n\n\nf(2),f(4)\n\n(0, 4)\n\n\n위의 코드는 아래와 같다\n\ndef f(x):\n    return (x-2)**2\nf(2), f(4)\n\n(0, 4)\n\n\n- 예제3: 조건부 출력\n\nf = lambda x,y: x if x>y else y  # 큰 값 리턴\n\n\nf(1,2),  f(-4,3)\n\n(2, 3)\n\n\n- 예제4: 람다표현식들의 리스트\n\nfl = [lambda x: x, lambda x: x**2, lambda x: x**3]\n\n\ntype(fl)\n\nlist\n\n\n\nfl[0](10), fl[1](10), fl[2](10)\n\n(10, 100, 1000)\n\n\n\nfor f in fl:\n    print(f(2))\n\n2\n4\n8\n\n\n\nfor s in ['a','b','c']:\n    print(s)\n\na\nb\nc\n\n\n\nfor s in ['a', lambda x:x, 'c']:\n    print(s)\n\na\n<function <lambda> at 0x7f3ddff33c20>\nc\n\n\n\nx = np.linspace(-1,1,100)\nfor f in fl:\n    plt.plot(x,f(x),'--')\n\n\n\n\n- 예제5: 람다표현식들의 딕셔너리\n\nfd = {'f1': lambda x:x, 'f2': lambda x: x**2, 'f3':lambda x:x**3}\nfd\n\n{'f1': <function __main__.<lambda>(x)>,\n 'f2': <function __main__.<lambda>(x)>,\n 'f3': <function __main__.<lambda>(x)>}\n\n\n\nfor k in fd:\n    plt.plot(x,fd[k](x),'--')\n\n\n\n\n- 예제6: 람다표현식을 리턴하는 함수(함수를 리턴하는 함수)\n(예비학습) 함수 \\(g(x)\\)가 정의되어 있을때 \\(\\frac{d}{dx}g(x)\\)의 값을 계산\n\ng = lambda x : x**2\n\n\ng(3)\n\n9\n\n\n\\(f'(x)\\approx \\frac{f(x+h)-f(x)}{h}\\)\n\ngg =  lambda x: (g(x+0.001)-g(x))/0.001\n\n\ngg(3)\n\n6.000999999999479\n\n\n(예비학습끝)\n(목표) 도함수를 구해주는 derivate 함수를 정의. 임의의 함수 g를 입력으로 받으면, g의 도함수 (gg)가 리턴되는 기능을 가진다.\n\ndef derivate(g):\n    gg = lambda x: (g(x+0.001)-g(x))/0.001\n    return gg\n\n(사용)\n\ng = lambda x: np.sin(x)\n\n\ngg = derivate(g)\n\n\nx = np.linspace(0,6.28,1000)\n\n\nplt.plot(x,g(x))\nplt.plot(x,gg(x))\n\n\n\n\n(사용2)\n\ng0 = lambda x: (1/6)*x**3\ng1 = derivate(g0) # (1/2)x^2\ng2 = derivate(g1) # x \n\n\nx = np.linspace(-1,1,100)\n\n\nplt.plot(x,g0(x))\nplt.plot(x,g1(x))\nplt.plot(x,g2(x))\n\n\n\n\n- 예제7: 예제6의 다른표현\n\nderivate = lambda g : lambda x: (g(x+0.001)-g(x))/0.001\n# 위와 같은 코드\n\n\ng = lambda x: np.sin(x)\n\n\ngg = derivate(g)\n\n\nx = np.linspace(0,6.28,1000)\n\n\nplt.plot(x,g(x))\nplt.plot(x,gg(x))\n\n\n\n\n(사용2)\n\ng0 = lambda x: (1/6)*x**3\ng1 = derivate(g0) # (1/2)x^2\ng2 = derivate(g1) # x \n\n\nx = np.linspace(-1,1,100)\n\n\nplt.plot(x,g0(x))\nplt.plot(x,g1(x))\nplt.plot(x,g2(x))"
  },
  {
    "objectID": "posts/DV_6(1012).html#map",
    "href": "posts/DV_6(1012).html#map",
    "title": "DV 6주차",
    "section": "map",
    "text": "map\n- 개념: \\(\\text{map}\\left(f,[x_1,x_2,\\dots,x_n] \\right) = \\left[f(x_1),f(x_2),\\dots,f(x_n)\\right]\\)\n- 예제1\n\nx=[1,2,3]\nf = lambda x: x+1\ny= list(map(f,x))\n\n\nlist(map(f,x))\n\n[2, 3, 4]\n\n\n\nf(x) # 리스트라 오류남\n\nTypeError: can only concatenate list (not \"int\") to list\n\n\n\nf(x[0])\n\n2\n\n\n(다른구현1)\n\nlist(map(lambda x:x+1, x))\n\n[2, 3, 4]\n\n\n\nlist(map(lambda x:x+1, [1,2,3]))\n\n[2, 3, 4]\n\n\n(다른구현2)\n\nf = lambda x: x+1\n[xi for xi in [1,2,3]]\n\n[1, 2, 3]\n\n\n\nf = lambda x: x+1\n[f(xi) for xi in [1,2,3]]\n\n[2, 3, 4]\n\n\n(다른구현3)\n\n[(lambda x:x+1)(xi) for xi in [1,2,3]]\n\n[2, 3, 4]\n\n\n(다른구현4)-최악\n\ny = []\nx = [1,2,3]\nf = lambda x: x+1\nfor xi in x:\n    y.append(f(xi))\n\n\ny\n\n[2, 3, 4]\n\n\n(다른구현5)-더 최악\n\ny = []\nx = [1,2,3]\nf = lambda x: x+1\nfor i in range(len(x)):\n    y.append(f(x[i]))\n\n\ny\n\n[2, 3, 4]\n\n\n- 예제2: 문자열을 입력으로 받고 대문자이면 True, 소문자이면 False\n입력: A,B,C,a,b,c\n출력: T,T,T,F,F,F\n\nf(np.array(x))\n\narray([2, 3, 4])\n\n\n\n'A'.isupper()\n\nTrue\n\n\n\n#x = ['A', 'B', 'C', 'a', 'b', 'c']\nx = list('ABCabc')\nf = lambda s : s.isupper()\ny = list(map(f,x))\n\n\nx,y\n\n(['A', 'B', 'C', 'a', 'b', 'c'], [True, True, True, False, False, False])\n\n\n- 예제3: 두 개의 입력을 받는 함수\n\n(lambda x,y : x+y)(-1,3)\n\n2\n\n\n\nlist(map(lambda x,y: x+y, [1,2,3],[-1,-2,-3]))\n\n[0, 0, 0]\n\n\n(다른 구현) - 리스트컴프리헨션\n\nf = lambda x,y: x+y\n[f(x,y) for x,y in zip([1,2,3],[-1,-2,-3])]\n\n[0, 0, 0]\n\n\n- 예제4: map은 “하나의 함수에 다양한 입력”을 적용하는 경우에만 사용가능, 리스트 컴프리헨션은 “다양한 함수에 다양한 입력”을 지원한다.\n\nflst = [lambda x: x+1, lambda x: x+2, lambda x: x+3]\n\n(map으로 구현 시도) -> 실패\n\nlist(map(flst,[-1,-2,-3])) # 결과가 0,0,0 나오길 시도\n\nTypeError: 'list' object is not callable\n\n\n리스트컴프리헨션으로 구현시도 -> 성공\n\n[f(x) for f,x in zip(flst, [-1,-2,-3])]\n\n[0, 0, 0]\n\n\n- 종합: map과 리스트컴프리헨션과 비교 - map은 반복인덱스를 쓰지 않지만 리스트컴프리헨션은 반복인덱스가 필요함 - map은 좀더 리스트컴프리헨션보다 제약적으로 사용할 수 밖에 없음"
  },
  {
    "objectID": "posts/DV_6(1012).html#데이터프레임-준비",
    "href": "posts/DV_6(1012).html#데이터프레임-준비",
    "title": "DV 6주차",
    "section": "데이터프레임 준비",
    "text": "데이터프레임 준비\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/dv2022.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n200 rows × 4 columns\n\n\n\n- 앞으로는 위와 같은 df형태를 가정할 것이다. 즉 column의 이름은 문자열, row의 이름은 0부터 시작하는 정수로 가정한다.\n\nnp.array([[1,2,3],[1,2,5]])\n\narray([[1, 2, 3],\n       [1, 2, 5]])\n\n\n- 아래와 같은 형태는 일단 생각 안함\n\npd.DataFrame({'att':[60,65,80,90],'rep':[50,100,90,100]},index=['A','B','C','D'])\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      A\n      60\n      50\n    \n    \n      B\n      65\n      100\n    \n    \n      C\n      80\n      90\n    \n    \n      D\n      90\n      100"
  },
  {
    "objectID": "posts/DV_6(1012).html#df의-4가지-컨셉",
    "href": "posts/DV_6(1012).html#df의-4가지-컨셉",
    "title": "DV 6주차",
    "section": "df의 4가지 컨셉",
    "text": "df의 4가지 컨셉\n- 원소에 접근하는 4가지 방법: ., [], iloc[], .loc[]\n\n컨셉1: 클래스느낌\n- 컨셉1: df는 인스턴스이다. 그리고 df.att, df.rep, df.mid, df.fin과 같이 col이름에 대응하는 속성이 있다.\n\ndf.head(6)\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n  \n\n\n\n\n\ndf.att\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndf.fin\n\n0      10\n1      10\n2      20\n3       5\n4      70\n       ..\n195    95\n196    85\n197    10\n198    60\n199    85\nName: fin, Length: 200, dtype: int64\n\n\n- 언제유용? col의 이름을 대충 알고 있을 경우 자동완성으로 쉽게 선택가능\n\n\n컨셉2: 딕셔너리 + \\(\\alpha\\) 느낌\n- 컨셉2: df는 컬럼이름이 key, 컬럼의 데이터가 value가 되는 dictionary로 이해가능. 즉 아래의 dct와 같은 딕셔너리로 이해할 수 있다.\n\ncol indexing\n- 예시1: dct가 가능하면 df도 가능하다.\n\ndct = dict(df)\n\n\ndct['att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndf['att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: dct가 가능하면 df도 가능하다.(2)\n\ndf.get('att')\n#dct.get('att')\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시3: dct에서는 불가능하지만 df에서 가능한 것도 잇다.\n\ndct.get('att')\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndct.get(['att','rep']) #이건 안됨\n\nTypeError: unhashable type: 'list'\n\n\n\ndf.get(['att','rep'])\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      1\n      95\n      30\n    \n    \n      2\n      65\n      85\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      60\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      197\n      85\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시4: dct에서는 불가능하지만 df에서 가능한 것도 잇다.(2)\n\ndct['att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n\ndct[['att','rep']]\n\nTypeError: unhashable type: 'list'\n\n\n\ndf[['att','rep']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      1\n      95\n      30\n    \n    \n      2\n      65\n      85\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      60\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      197\n      85\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n200 rows × 2 columns\n\n\n\n\n\nlow indexing\n- 예시5: dct에서는 불가능하지만 df에서 가능한 것도 잇다.(3)\n\ndct[:5]\n\nTypeError: unhashable type: 'slice'\n\n\n\ndf[:5]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n  \n\n\n\n\n\n\n\n컨셉3: 넘파이느낌\n- 컨셉3: df.iloc은 넘파이어레이처럼 생각 가능하다. 즉 아래와 같은 넘파이 어레이로 생각 가능\n\narr=np.array(df)\narr\n\narray([[ 65,  45,   0,  10],\n       [ 95,  30,  60,  10],\n       [ 65,  85,  15,  20],\n       [ 55,  35,  35,   5],\n       [ 80,  60,  55,  70],\n       [ 75,  40,  75,  85],\n       [ 65,  70,  60,  75],\n       [ 60,  25,  20,  35],\n       [ 95,  55,  65,  90],\n       [ 90,  25,  95,  50],\n       [ 55,  45,  75,  30],\n       [ 95,  60,  25,  55],\n       [ 95,  35,   0,  25],\n       [ 50,  55,  90,  45],\n       [ 50,  65,  50,  70],\n       [ 95, 100,  25,  40],\n       [ 50,  65,  35,  85],\n       [ 65,  85,  10,   5],\n       [ 70,  65,  65,  80],\n       [ 90,  70, 100,  30],\n       [ 80,  45,  80,  85],\n       [ 55,  45,  85,  70],\n       [ 65,  35,  45,  20],\n       [ 70,  25,  50,  70],\n       [ 85,  55,  30,  80],\n       [ 90,  30,  30,   0],\n       [100,  65,  50,  70],\n       [ 80,  70,  50, 100],\n       [ 80,  35,  25,  65],\n       [ 55,  75,  20,  25],\n       [ 75,  75,  85,  95],\n       [ 80,  95,   5,   5],\n       [ 95,  60,  65,  10],\n       [ 95,  60,  90,  75],\n       [100,  75,  70,  25],\n       [100,  55,  35,  85],\n       [ 80,  60,  65,  55],\n       [ 70,  80,   0,  10],\n       [ 85,  65,  60,  60],\n       [100,  95,   0,  25],\n       [ 95,  60,  15,  45],\n       [ 75,  40,  30,  10],\n       [ 70,  80,  50,  25],\n       [ 50,  45,  10,  10],\n       [100, 100, 100,  50],\n       [ 75,  50,  60,   5],\n       [ 85,  50,  35, 100],\n       [ 80,  35,  75,  80],\n       [ 95,  45,  35,  80],\n       [ 65,  85,  85,  15],\n       [ 90,  30,  25,   5],\n       [ 65,  65,  35,  70],\n       [ 80,  65,  30,  90],\n       [ 95,  80,  45,  35],\n       [ 65,  75,  50,  35],\n       [ 90,  55, 100,  30],\n       [ 95,  25,  95,  90],\n       [100,  50,  80,  10],\n       [ 50,  55,  35,  60],\n       [ 90,  70,  35,  25],\n       [ 50,  55,  15,  75],\n       [ 80,  50,  55,  90],\n       [ 50,  75,  65,  90],\n       [ 70,  40,  90,   5],\n       [ 65,  85,  20,  90],\n       [ 60,  30,   0,  50],\n       [ 50,  65,  15,   0],\n       [ 60,  95,  30,  70],\n       [ 70,  70,   5,   0],\n       [ 75,  45,  15,  75],\n       [ 50,  60,  15,  50],\n       [ 85,  90,  90,  90],\n       [ 80,  25,  85,  20],\n       [ 55,  75,  95,  90],\n       [ 85,  30,  45,  15],\n       [ 65,  30,  45,  15],\n       [ 85,  95,  35,  25],\n       [ 60,  25,  10,  50],\n       [ 95,  45,  90,  35],\n       [ 85,  50,  60,  45],\n       [ 60,  50, 100,  70],\n       [100,  75,  60,   0],\n       [100,  90,  85,  75],\n       [ 55, 100, 100,  60],\n       [ 70,  60,  30,  40],\n       [ 70,  90,  95,  40],\n       [ 55,  50,   0,   5],\n       [100, 100,  45,  90],\n       [ 85,  70,  90,  80],\n       [100,  85,  65,  85],\n       [ 60,  65,  35,  15],\n       [ 65,  75,  75,  85],\n       [ 65,  25,  40,   0],\n       [ 75,  75,  50,  40],\n       [ 50,  55,  80,  55],\n       [ 75,  30,  20,  50],\n       [100,  50,  25,  65],\n       [ 90,  30,  95,  35],\n       [ 55, 100,  80,   0],\n       [ 75,  60,  15,  40],\n       [ 60,  25,  25,  50],\n       [ 85,  35,  10,  60],\n       [ 60, 100,  55,  40],\n       [ 70,  55,  50,  75],\n       [ 80,  65,  95,  85],\n       [ 65,  35,  15,  65],\n       [ 85,  70, 100,   0],\n       [100,  30,  60,  65],\n       [ 65,  70,  55,  70],\n       [ 85,  55,  85,  90],\n       [ 85,  95,  80,  10],\n       [ 85,  70,  75,   5],\n       [100,  35,  70,   0],\n       [ 95,  45,  55,  65],\n       [ 95,  85,  40,  65],\n       [ 55,  50,  30,  85],\n       [ 85,  50,   5,  65],\n       [ 75,  90,  85,  85],\n       [ 95,  70,  10,   5],\n       [ 85,  35,  80,  95],\n       [ 95,  50,  80,  90],\n       [100,  65,  75,  40],\n       [ 95,  70,  70,   0],\n       [ 95,  70,  20,  25],\n       [100,  60,  10,   5],\n       [ 55,  35,  25,  10],\n       [ 60,  90,  40,   5],\n       [ 85,  90,  85,  75],\n       [ 75,  85,  25,  35],\n       [ 55,  30,  50,  45],\n       [ 70,  60,  75,  75],\n       [ 80,  30,  95,   5],\n       [ 90,  85,  80,  15],\n       [ 90,  25,  95,   5],\n       [ 60,  85,  50,  20],\n       [ 90,  50,  95,  95],\n       [ 75,  95,  65,  40],\n       [ 60,  40,  35,   0],\n       [ 55, 100,  15,  80],\n       [ 70,  75,  80,   0],\n       [ 75,  65,  25,  20],\n       [ 90,  75,  80,  25],\n       [ 50,  75,  75,  20],\n       [ 55,  45,  35,  45],\n       [ 90,  70,  90,   0],\n       [ 75,  30, 100,  60],\n       [ 90,  85,   0,  40],\n       [ 85,  70,  35,   0],\n       [100,  75, 100,  85],\n       [ 55,  35,  20,  10],\n       [ 70,  75,  90,  90],\n       [ 90,  90,  55,  55],\n       [ 55,  60,  40,   0],\n       [100,  90,   5,  30],\n       [ 50,  55,  25,  80],\n       [100, 100,  90,  55],\n       [ 70,  45,  70,  75],\n       [ 85,  95,  85,  90],\n       [ 55,  25,  95,  45],\n       [ 75,  30,  10,  95],\n       [ 65,  85,  15,  60],\n       [ 70,  90,  70,   0],\n       [ 60,  85,  70,  85],\n       [100,  25,  10,  20],\n       [ 75,  25,  80,  25],\n       [ 90,  95,  40,  80],\n       [ 95,  90,  50,  50],\n       [ 90,  90,  65,  85],\n       [ 95,  75,  50,  40],\n       [ 55,  60,  70,   5],\n       [ 95,  85,   0,  15],\n       [ 65,  60,  35,  20],\n       [ 65,  50,   5,   5],\n       [ 90,  25,  60,  25],\n       [100,  40,  40,  15],\n       [ 70,  25, 100,  75],\n       [100,  30,  70,  70],\n       [ 50,  55,  55,   5],\n       [ 70,  35,  70, 100],\n       [ 70,  60,  60,  80],\n       [ 55,  45,  90,   5],\n       [ 55,  55,  10,  95],\n       [ 65,  80,  10,  30],\n       [ 90,  25,  35,  55],\n       [100,  30,  30,  85],\n       [ 70,  85,  70,  65],\n       [ 60, 100,  45, 100],\n       [ 70,  25, 100,  15],\n       [ 70,  35,  80,  25],\n       [ 65,  60,  30,  35],\n       [ 95,  35,  40,  95],\n       [ 50,  80,  65,  90],\n       [100,  40,  80,  80],\n       [ 55,  30,  95, 100],\n       [ 65,  40,  65,  70],\n       [ 55,  70,  40,  95],\n       [ 65,  85,  25,  85],\n       [ 85,  85, 100,  10],\n       [ 80,  65,  35,  60],\n       [ 50,  95,  45,  85]])\n\n\n\nrow indexing\n- 예시1: 단일레이블\n\narr[0,:] # first row\n\narray([65, 45,  0, 10])\n\n\n\narr[0]\n\narray([65, 45,  0, 10])\n\n\n\narr[0,] # R\n\narray([65, 45,  0, 10])\n\n\n\ndf.iloc[0,:]\n# df.iloc[0,]\n# df.iloc[0]\n\natt    65\nrep    45\nmid     0\nfin    10\nName: 0, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\narr[[0,1,2],:]  # 처음 3개의 row 선택\narr[[0,1,2],]\narr[[0,1,2]]\n\narray([[65, 45,  0, 10],\n       [95, 30, 60, 10],\n       [65, 85, 15, 20]])\n\n\n\ndf.iloc[[0,1,2],:]  # 처음 3개의 row 선택\ndf.iloc[[0,1,2],]\ndf.iloc[[0,1,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n- 예시3: 슬라이싱\n\narr[0:3,:]  # 처음 3개의 row 선택, 끝점포함x\narr[0:3,]\narr[0:3]\n\narray([[65, 45,  0, 10],\n       [95, 30, 60, 10],\n       [65, 85, 15, 20]])\n\n\n\ndf.iloc[0:3,:]  # 처음 3개의 row 선택\ndf.iloc[0:3,]\ndf.iloc[0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n\n\ncol indexing\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n  \n\n\n\n\n- 예시1: 단일레이블\n\n#df.iloc[:,0] # first column \narr[:,0] # first column \n\narray([ 65,  95,  65,  55,  80,  75,  65,  60,  95,  90,  55,  95,  95,\n        50,  50,  95,  50,  65,  70,  90,  80,  55,  65,  70,  85,  90,\n       100,  80,  80,  55,  75,  80,  95,  95, 100, 100,  80,  70,  85,\n       100,  95,  75,  70,  50, 100,  75,  85,  80,  95,  65,  90,  65,\n        80,  95,  65,  90,  95, 100,  50,  90,  50,  80,  50,  70,  65,\n        60,  50,  60,  70,  75,  50,  85,  80,  55,  85,  65,  85,  60,\n        95,  85,  60, 100, 100,  55,  70,  70,  55, 100,  85, 100,  60,\n        65,  65,  75,  50,  75, 100,  90,  55,  75,  60,  85,  60,  70,\n        80,  65,  85, 100,  65,  85,  85,  85, 100,  95,  95,  55,  85,\n        75,  95,  85,  95, 100,  95,  95, 100,  55,  60,  85,  75,  55,\n        70,  80,  90,  90,  60,  90,  75,  60,  55,  70,  75,  90,  50,\n        55,  90,  75,  90,  85, 100,  55,  70,  90,  55, 100,  50, 100,\n        70,  85,  55,  75,  65,  70,  60, 100,  75,  90,  95,  90,  95,\n        55,  95,  65,  65,  90, 100,  70, 100,  50,  70,  70,  55,  55,\n        65,  90, 100,  70,  60,  70,  70,  65,  95,  50, 100,  55,  65,\n        55,  65,  85,  80,  50])\n\n\n\ndf.iloc[:,0] # first column\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\n#arr[:,[0,2]] # col1, col3 선택\n\n\ndf.iloc[:,[0,2]] # 처음 3개의 row선택\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      65\n      0\n    \n    \n      1\n      95\n      60\n    \n    \n      2\n      65\n      15\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      55\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      40\n    \n    \n      196\n      65\n      25\n    \n    \n      197\n      85\n      100\n    \n    \n      198\n      80\n      35\n    \n    \n      199\n      50\n      45\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시3: 슬라이싱\n\ndf.iloc[:,0:3] # 처음 3개의 col선택, 끝점포함X\n#arr[:,0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      199\n      50\n      95\n      45\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\nrow+col indexing\n\ndf.iloc[:2,0:3] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n  \n\n\n\n\n\ndf.iloc[::2,0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      6\n      65\n      70\n      60\n    \n    \n      8\n      95\n      55\n      65\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      190\n      95\n      35\n      40\n    \n    \n      192\n      100\n      40\n      80\n    \n    \n      194\n      65\n      40\n      65\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      198\n      80\n      65\n      35\n    \n  \n\n100 rows × 3 columns\n\n\n\n\n\n\n컨셉4: 데이터프레임 느낌\n- 컨셉4: df.loc새로운 느낌 (R에 익숙하면 dataframe 혹은 티블느낌이라고 보면 된다.)\n\nR에서.. 교수님꺼 강의노트 참고\n\n\nrow indexing\n- 예시1: 단일레이블\n\ndf.loc[0,:]   # 첫번째 row를 선택\ndf.loc[0,]\ndf.loc[0]\n\natt    65\nrep    45\nmid     0\nfin    10\nName: 0, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\ndf.loc[[0,1,2],:]   # 처음 3개의 row를 선택\ndf.loc[[0,1,2],]\ndf.loc[[0,1,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n- 예시3: 슬라이싱(끝점포함 O!!)\n\ndf.loc[0:3,:]   # 처음 4개의 row를 선택\ndf.loc[0:3,]\ndf.loc[0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n  \n\n\n\n\n\n\ncol indexing\n- 예시1: 단일레이블\n\ndf.loc[:,'att']\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\ndf.loc[:,['att','mid']]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      65\n      0\n    \n    \n      1\n      95\n      60\n    \n    \n      2\n      65\n      15\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      55\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      40\n    \n    \n      196\n      65\n      25\n    \n    \n      197\n      85\n      100\n    \n    \n      198\n      80\n      35\n    \n    \n      199\n      50\n      45\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시3: 슬라이싱 (끝점 포함 O)\n\ndf.loc[:,'att':'mid']   # R에서는 안됬었고 끝점 포함\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      199\n      50\n      95\n      45\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\nrow+col indexing\n\ndf.loc[::-1,'att':'mid']   \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      199\n      50\n      95\n      45\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      0\n      65\n      45\n      0\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\n\n컨셉 1~4 정리\n\n\n\n\n.\n[]\n.iloc\n.loc\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\n\n- col 이름을 알아야하는 부담감\n\n. : 앞글자만 대충 알아도 자동완성 가능\n[]: 정확한 col 이름을 알아야 함\n.loc: 보통 정확한 col 이름을 알아야 하지만 슬라이싱 이용시 양 끝의 컬럼이름만 알면 무방\n.iloc: 정확한 col 이름을 몰라도 번호로 인덱싱 가능\n\n- 자주하는 실수\n\n# df['att'] # 가능\n# df.loc['att'] # 불가능\ndf.loc[:,'att'] # 가능\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64"
  },
  {
    "objectID": "posts/DV_6(1012).html#요약",
    "href": "posts/DV_6(1012).html#요약",
    "title": "DV 6주차",
    "section": "요약",
    "text": "요약\n\n\n\n\n.\n[]\n.iloc\n.loc\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\nrow/bool,list\nX\nO\nO\nO\n\n\nrow/bool,ser\nX\nO\nX\nO\n\n\nrow/bool,map\nX\nX\nO\nO"
  },
  {
    "objectID": "posts/DV_6(1012).html#숙제1",
    "href": "posts/DV_6(1012).html#숙제1",
    "title": "DV 6주차",
    "section": "숙제1",
    "text": "숙제1\n아래와 같이 0~9까지 포함된 리스트를 만들어라\n\nx=list(range(10))\nx\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n아래와 동일한 기능을 수행하는 함수를 lambda expression으로 정의하라.\n\ndef f(xi):\n    return '짝' if (xi % 2)==0 else '홀'\n\n\nff = lambda x: \"짝\" if (x % 2)==0 else \" 홀\" \n\n\nff(2)\n\n'짝'\n\n\n\nf(2)\n\n'짝'\n\n\nmap과 lambda expression 을 이용하여 아래와 같은 결과를 만들어라. (리스트컴프리헨션, for문 사용금지)\n\nx=list(range(10))\nff = lambda x: \"짝\" if (x % 2)==0 else \" 홀\" \ny=list(map(ff,x))\ny\n\n['짝', ' 홀', '짝', ' 홀', '짝', ' 홀', '짝', ' 홀', '짝', ' 홀']"
  },
  {
    "objectID": "posts/DV_6(1012).html#숙제2",
    "href": "posts/DV_6(1012).html#숙제2",
    "title": "DV 6주차",
    "section": "숙제2",
    "text": "숙제2\n다음과 같은 데이터프레임을 불러온 뒤 물음에 답하라\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/dv2022.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n200 rows × 4 columns\n\n\n\n(1) 기말고사 성적이 중간고사 성적보다 향상된 학생들을 출력하라. 즉 mid < fin 인 학생들을 출력하라. (다양한 방법으로 연습할 것, 제출은 한 가지 방법으로 구현해도 감점없음)\n\ndf.query('mid<fin')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n\ndf.loc[(df.mid<df.fin)]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n\ndf.iloc[list((df.mid<df.fin))]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n\ndf[list(map(lambda x,y: x<y, df.mid, df.fin))]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n(2) 기말고사 성적이 중간고사 성적보다 향상된 학생들의 출석과 레포트 점수를 출력하라.\n\ndf2 = df.query('mid<fin').copy()\n\n\ndf2.head()\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n  \n\n\n\n\n\ndf2.loc[:,['att','rep']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      2\n      65\n      85\n    \n    \n      4\n      80\n      60\n    \n    \n      5\n      75\n      40\n    \n    \n      6\n      65\n      70\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n93 rows × 2 columns\n\n\n\n\ndf2로 받는 방법 말고 다른 방법이 또 있을 거 같은뎀,,"
  },
  {
    "objectID": "posts/DV_13(1128).html",
    "href": "posts/DV_13(1128).html",
    "title": "DV 13주차(1)",
    "section": "",
    "text": "import folium \nimport pandas as pd \nimport json \nimport requests"
  },
  {
    "objectID": "posts/DV_13(1128).html#folium.polygon",
    "href": "posts/DV_13(1128).html#folium.polygon",
    "title": "DV 13주차(1)",
    "section": "folium.Polygon",
    "text": "folium.Polygon\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Marker(\n    location = [35.8471, 127.1291]\n).add_to(m)\nfolium.Marker(\n    location = [35.8468, 127.1289]\n).add_to(m)\nfolium.Marker(\n    location = [35.84635, 127.1291]\n).add_to(m)\nfolium.Marker(\n    location = [35.84635, 127.1297]\n).add_to(m)\nfolium.Marker(\n    location = [35.8468, 127.12995]\n).add_to(m)\nfolium.Marker(\n    location = [35.8474, 127.1300]\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Polygon(\n    locations = [[35.8471, 127.1291],  # location's'라고 해야함\n                 [35.8468, 127.1289],\n                 [35.84635, 127.1291],\n                 [35.84635, 127.1297],\n                 [35.8468, 127.12995],\n                 [35.8474, 127.1300]],\n    fill=True\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Polygon(\n    locations = [[[35.8471, 127.1291],\n                 [35.8468, 127.1289],\n                 [35.84635, 127.1291],\n                 [35.84635, 127.1297],\n                 [35.8468, 127.12995],\n                 [35.8474, 127.1300]],\n                 \n                 [[ 35.8471 , 127.1302],\n                 [ 35.8468 , 127.1300],\n                 [ 35.84635, 127.1302],\n                 [ 35.84635, 127.1308],\n                 [ 35.8468 , 127.13105],\n                 [ 35.8474 , 127.1311]]],\n    fill=True\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_13(1128).html#dict-view-vs-copy",
    "href": "posts/DV_13(1128).html#dict-view-vs-copy",
    "title": "DV 13주차(1)",
    "section": "dict: view vs copy",
    "text": "dict: view vs copy\n- 원하지 않는 코드\n\ndct1 = {'a':1, 'b':2, 'c':3}\ndct1\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\ndct2 = dct1 \ndct1,dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 3})\n\n\n\ndct2['c']=9999\ndct1, dct2\n\n({'a': 1, 'b': 2, 'c': 9999}, {'a': 1, 'b': 2, 'c': 9999})\n\n\n- 원하는 코드\n\ndct1 = {'a':1, 'b':2, 'c':3}\ndct1\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\ndct2 = dct1.copy()\ndct1, dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 3})\n\n\n\ndct2['c']=9999\ndct1, dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 9999})"
  },
  {
    "objectID": "posts/DV_13(1128).html#json-파일-다운로드",
    "href": "posts/DV_13(1128).html#json-파일-다운로드",
    "title": "DV 13주차(1)",
    "section": "json 파일 다운로드",
    "text": "json 파일 다운로드\n\nglobal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-provinces-2018-geo.json').text)\nlocal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-municipalities-2018-geo.json').text)\n\n\nlocal_dict.keys()\n\ndict_keys(['type', 'features', 'name', 'crs'])"
  },
  {
    "objectID": "posts/DV_13(1128).html#json-파일의-구조",
    "href": "posts/DV_13(1128).html#json-파일의-구조",
    "title": "DV 13주차(1)",
    "section": "json 파일의 구조",
    "text": "json 파일의 구조\n- global_dict의 구조\n\n\n\nlevel_0\nlevel_1\nlevel_2\nlevel3\nlevel4\n\n\n\n\ntype\n‘FeatureCollection’\n\n\n\n\n\nfeatures\n[0]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘Polygon’\n\n\n\n\n\ncoordinates\n(1,??,2) list\n\n\n\n\nproperties\nname\n‘서울특별시’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Seoul’\n\n\n\n\n\ncode\n‘11’\n\n\n\n…\n…\n…\n…\n\n\n\n[16]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(6,1,??,2) list\n\n\n\n\nproperties\nname\n‘’제주특별자치도’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Jeju-do’\n\n\n\n\n\ncode\n‘39’\n\n\nname\n‘sido’\n\n\n\n\n\ncrs\ntype\n‘name’\n\n\n\n\n\nproperties\nname\n‘urn:ogc:def:crs:OGC:1.3:CRS84’\n\n\n\n\n- local_dict의 구조\n\n\n\nlevel_0\nlevel_1\nlevel_2\nlevel3\nlevel4\n\n\n\n\ntype\n‘FeatureCollection’\n\n\n\n\n\nfeatures\n[0]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(1,1,??,2) list\n\n\n\n\nproperties\nname\n‘종로구’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Jongno-gu’\n\n\n\n\n\ncode\n‘11010’\n\n\n\n…\n…\n…\n…\n\n\n\n[249]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(10,1,??,2) list\n\n\n\n\nproperties\nname\n‘서귀포시’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Seogwipo-si’\n\n\n\n\n\ncode\n‘39020’\n\n\nname\n‘sido’\n\n\n\n\n\ncrs\ntype\n‘name’\n\n\n\n\n\nproperties\nname\n‘urn:ogc:def:crs:OGC:1.3:CRS84’"
  },
  {
    "objectID": "posts/DV_13(1128).html#예제1-global-scale",
    "href": "posts/DV_13(1128).html#예제1-global-scale",
    "title": "DV 13주차(1)",
    "section": "예제1: global scale",
    "text": "예제1: global scale\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start = 8,\n    scroolWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data = global_dict\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_13(1128).html#예제2-local-scale",
    "href": "posts/DV_13(1128).html#예제2-local-scale",
    "title": "DV 13주차(1)",
    "section": "예제2: local scale",
    "text": "예제2: local scale\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start = 7,\n    scroolWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data = local_dict\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_13(1128).html#예제3-덕진구-완산구-시각화",
    "href": "posts/DV_13(1128).html#예제3-덕진구-완산구-시각화",
    "title": "DV 13주차(1)",
    "section": "예제3: 덕진구, 완산구 시각화",
    "text": "예제3: 덕진구, 완산구 시각화\n\nlocal_dict2 = local_dict.copy()\n\n\n_features = [local_dict['features'][i] for i in range(250) if local_dict['features'][i]['properties']['name'] == '전주시덕진구' or local_dict['features'][i]['properties']['name'] == '전주시완산구']\nlocal_dict2['features'] = _features\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n_name_lst = [local_dict['features'][i]['properties']['name'] for i in range(250)]\n\n\n[name for name in _name_lst if '완산' in name or '덕진' in name]\n\n['전주시완산구', '전주시덕진구']"
  },
  {
    "objectID": "posts/DV_13(1128).html#예제1-덕진구-vs-완산구",
    "href": "posts/DV_13(1128).html#예제1-덕진구-vs-완산구",
    "title": "DV 13주차(1)",
    "section": "예제1: 덕진구 vs 완산구",
    "text": "예제1: 덕진구 vs 완산구\n\n선실습\n\ndf = pd.DataFrame({'key':['전주시덕진구', '전주시완산구'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      전주시완산구\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name',\n    # 연결의 매개체가 되는 것이 무엇인가? 'key'랑 'properties.name'\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n후실습\n이해를 위해 필요한 약간의 직관\n\n예비생각1: 코로플레스맵을 그리기 위해서는 항상 2개의 데이터를 연결해야하는 구조이다. 하나는 json에서 나온 dict (local_dict2), 다른하나는 df이다.\n예비생각2: 두개의 데이터를 연결하기 위해서는 공유가능한 연결의 매개체가 필요하다. (cbind: row-index를 공유, rbind: colnames공유, merge: 양쪽 데이터프레임에서 같은 이름을 가진 특정 col이 있었음)\n예비생각3: 코로플레스맵의 연결매개체는 ‘완산구’, ’덕진구’와 같은 지역명이다.\n\nfolium.Choropleth() 에 사용될 변수들 상상해보기\n\n재료: 두개의 데이터 (json과 df)를 명시해야 한다.\n연결매개체: 두개의 데이터프레임을 연결하는 변수이름을 명시해야 한다.\n색깔표시: (지역명,value)와 같은 쌍을 전달해야 한다."
  },
  {
    "objectID": "posts/DV_13(1128).html#key_on-에-대한-이해",
    "href": "posts/DV_13(1128).html#key_on-에-대한-이해",
    "title": "DV 13주차(1)",
    "section": "key_on 에 대한 이해",
    "text": "key_on 에 대한 이해\n\n사용예시1: 한글이름으로 key_on\n\ndf = pd.DataFrame({'key':['전주시덕진구', 'Jeonjusiwansangu'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      Jeonjusiwansangu\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n20에 대응하는 것들만 표시되고 미싱되는 것은 검정색 표현\n\n\n\n사용예시2: 영어이름으로 key_on\n\ndf = pd.DataFrame({'key':['전주시덕진구', 'Jeonjusiwansangu'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      Jeonjusiwansangu\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name_eng',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n사용예시3: 코드로 key_on\n\nlocal_dict2['features'][0]['properties'], local_dict2['features'][1]['properties']\n\n({'name': '전주시완산구',\n  'base_year': '2018',\n  'name_eng': 'Jeonjusiwansangu',\n  'code': '35011'},\n {'name': '전주시덕진구',\n  'base_year': '2018',\n  'name_eng': 'Jeonjusideokjingu',\n  'code': '35012'})\n\n\n\ndf = pd.DataFrame({'code':['35012', '35011'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      code\n      value\n    \n  \n  \n    \n      0\n      35012\n      20\n    \n    \n      1\n      35011\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['code','value'],\n    key_on='properties.code',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_13(1128).html#예제2-대한민국-인구수-시각화-global-scale",
    "href": "posts/DV_13(1128).html#예제2-대한민국-인구수-시각화-global-scale",
    "title": "DV 13주차(1)",
    "section": "예제2: 대한민국 인구수 시각화 (global scale)",
    "text": "예제2: 대한민국 인구수 시각화 (global scale)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-prov.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      행정구역(시군구)별\n      총인구수 (명)\n    \n  \n  \n    \n      0\n      서울특별시\n      9532428\n    \n    \n      1\n      부산광역시\n      3356311\n    \n    \n      2\n      대구광역시\n      2390721\n    \n    \n      3\n      인천광역시\n      2945009\n    \n    \n      4\n      광주광역시\n      1442454\n    \n    \n      5\n      대전광역시\n      1454228\n    \n    \n      6\n      울산광역시\n      1122566\n    \n    \n      7\n      세종특별자치시\n      368276\n    \n    \n      8\n      경기도\n      13549577\n    \n    \n      9\n      강원도\n      1537717\n    \n    \n      10\n      충청북도\n      1596948\n    \n    \n      11\n      충청남도\n      2118977\n    \n    \n      12\n      전라북도\n      1789770\n    \n    \n      13\n      전라남도\n      1834653\n    \n    \n      14\n      경상북도\n      2627925\n    \n    \n      15\n      경상남도\n      3318161\n    \n    \n      16\n      제주특별자치도\n      676569\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=global_dict,\n    data=df,\n    columns=['행정구역(시군구)별','총인구수 (명)'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_13(1128).html#예제3-대한민국-인구수-시각화-local-scale",
    "href": "posts/DV_13(1128).html#예제3-대한민국-인구수-시각화-local-scale",
    "title": "DV 13주차(1)",
    "section": "예제3: 대한민국 인구수 시각화 (local scale)",
    "text": "예제3: 대한민국 인구수 시각화 (local scale)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-muni.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      행정구역(시군구)별\n      총인구수 (명)\n    \n  \n  \n    \n      0\n      종로구\n      145346\n    \n    \n      1\n      중구\n      122781\n    \n    \n      2\n      용산구\n      223713\n    \n    \n      3\n      성동구\n      287174\n    \n    \n      4\n      광진구\n      340814\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      269\n      함양군\n      38475\n    \n    \n      270\n      거창군\n      61242\n    \n    \n      271\n      합천군\n      43029\n    \n    \n      272\n      제주시\n      493225\n    \n    \n      273\n      서귀포시\n      183344\n    \n  \n\n274 rows × 2 columns\n\n\n\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict,\n    data=df,\n    columns=['행정구역(시군구)별','총인구수 (명)'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_8(1024).html",
    "href": "posts/DV_8(1024).html",
    "title": "DV 8주차",
    "section": "",
    "text": "!pip install pandas_profiling\n\nCollecting pandas_profiling\n  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 324.4/324.4 kB 13.2 MB/s eta 0:00:00\nCollecting ydata-profiling\n  Downloading ydata_profiling-4.0.0-py2.py3-none-any.whl (344 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 344.5/344.5 kB 43.0 MB/s eta 0:00:00\nCollecting typeguard<2.14,>=2.13.2\n  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: statsmodels<0.14,>=0.13.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.13.5)\nRequirement already satisfied: scipy<1.10,>=1.4.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.7.3)\nRequirement already satisfied: jinja2<3.2,>=2.11.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (3.1.2)\nCollecting PyYAML<6.1,>=5.0.0\n  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 596.3/596.3 kB 68.7 MB/s eta 0:00:00\nCollecting phik<0.13,>=0.11.1\n  Downloading phik-0.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (680 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 680.0/680.0 kB 36.1 MB/s eta 0:00:00\nCollecting multimethod<1.10,>=1.4\n  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\nCollecting pydantic<1.11,>=1.8.1\n  Downloading pydantic-1.10.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 78.6 MB/s eta 0:00:00:00:01\nRequirement already satisfied: matplotlib<3.7,>=3.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (3.5.3)\nRequirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.3.5)\nCollecting htmlmin==0.1.12\n  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... done\nRequirement already satisfied: numpy<1.24,>=1.16.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.21.6)\nRequirement already satisfied: seaborn<0.13,>=0.10.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.12.2)\nCollecting tqdm<4.65,>=4.48.2\n  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 15.4 MB/s eta 0:00:00\nRequirement already satisfied: requests<2.29,>=2.24.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (2.28.2)\nCollecting visions[type_image_path]==0.7.5\n  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.7/102.7 kB 20.6 MB/s eta 0:00:00\nRequirement already satisfied: attrs>=19.3.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (22.2.0)\nCollecting networkx>=2.4\n  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 90.1 MB/s eta 0:00:00\nCollecting tangled-up-in-unicode>=0.0.4\n  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 93.1 MB/s eta 0:00:00ta 0:00:01\nRequirement already satisfied: Pillow in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (9.4.0)\nCollecting imagehash\n  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 296.5/296.5 kB 56.5 MB/s eta 0:00:00\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas_profiling) (2.1.1)\nRequirement already satisfied: packaging>=20.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (23.0)\nRequirement already satisfied: fonttools>=4.22.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (4.38.0)\nRequirement already satisfied: cycler>=0.10 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (1.4.4)\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>1.1->ydata-profiling->pandas_profiling) (2022.7.1)\nCollecting joblib>=0.14.1\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 52.3 MB/s eta 0:00:00\nRequirement already satisfied: typing-extensions>=4.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pydantic<1.11,>=1.8.1->ydata-profiling->pandas_profiling) (4.4.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (3.4)\nRequirement already satisfied: patsy>=0.5.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from statsmodels<0.14,>=0.13.2->ydata-profiling->pandas_profiling) (0.5.3)\nRequirement already satisfied: six in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->ydata-profiling->pandas_profiling) (1.16.0)\nCollecting PyWavelets\n  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.4/6.4 MB 85.2 MB/s eta 0:00:00:00:0100:01\nBuilding wheels for collected packages: htmlmin\n  Building wheel for htmlmin (setup.py) ... done\n  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27082 sha256=7bcfaa4b7942dcfb19895abe1a49d1c43c9f2d12c73d8bc74499ddcb933893c8\n  Stored in directory: /home/koinup4/.cache/pip/wheels/56/18/c1/6b3058b1db1f804221515aac5ecf2513d5ba971f33b8560c7a\nSuccessfully built htmlmin\nInstalling collected packages: htmlmin, typeguard, tqdm, tangled-up-in-unicode, PyYAML, PyWavelets, pydantic, networkx, multimethod, joblib, imagehash, visions, phik, ydata-profiling, pandas_profiling\nSuccessfully installed PyWavelets-1.3.0 PyYAML-6.0 htmlmin-0.1.12 imagehash-4.3.1 joblib-1.2.0 multimethod-1.9.1 networkx-2.6.3 pandas_profiling-3.6.6 phik-0.12.3 pydantic-1.10.5 tangled-up-in-unicode-0.2.0 tqdm-4.64.1 typeguard-2.13.3 visions-0.7.5 ydata-profiling-4.0.0"
  },
  {
    "objectID": "posts/DV_8(1024).html#모티브",
    "href": "posts/DV_8(1024).html#모티브",
    "title": "DV 8주차",
    "section": "모티브",
    "text": "모티브\n- 원본데이터를 가급적 손상시키지 않으면서 데이터를 변형하고 싶음\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n복사본 생성\n\ndf2 = df\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n\ndf2['C'] = (df2.A+df2.B)/2\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n\ndf2['D'] = (df2.C - np.mean(df2.C))/np.std(df2.C)\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\ndf  # 왜 C랑 D 값이 들어가있노?\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\nshallow copy\ndeep copy"
  },
  {
    "objectID": "posts/DV_8(1024).html#해결책1",
    "href": "posts/DV_8(1024).html#해결책1",
    "title": "DV 8주차",
    "section": "해결책1",
    "text": "해결책1\n- 올바른코드1\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf2 = df.copy() \ndf2['C'] = (df2.A+ df2.B)/2\ndf2['D']= (df2.C - np.mean(df2.C))/np.std(df2.C) \n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n- 올바른 코드2 (eval)\n\ndf.eval('C=(A+B)/2').eval('D=C-mean(c))/std(C)')\n\nTokenError: ('EOF in multi-line statement', (2, 0))\n\n\n\nmean([1,2,3]) # 정의가 안되있으무로\n\nNameError: name 'mean' is not defined\n\n\n\nmean = np.mean\n\n\nmean([1,2,3])\n\n2.0\n\n\n\nmean = np.mean\nstd = np.std\ndf.eval('C=(A+B)/2').eval('D=(C-@mean(C))/@std(C)')\n# 외부에서 온 거란 걸 표시해주기 위해서 mean앞에 @ 붙인다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\n어디까지 eval expression 안에서 지원되는지 명확하지 않고\n외부에 함수를 선언하고 eval expression 안에 @를 붙이는게 가독성이 없다.\n\n- 올바른 코드3 (assign) —-> 실패\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf.assign(C=(df.A+df.B)/2)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n\ndf.assign(C=(df.A+df.B)/2).assign(D=(df.C-np.mean(df.C))/np.std(df.C))\n\nAttributeError: 'DataFrame' object has no attribute 'C'\n\n\n\n# df.C 하면 나오는 오류와 동일한 오류가 위처럼 나타난다.\n\n\ndf.assign(C=(df.A+df.B)/2)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n아래와 같이 고쳐야함\n\n_df = df.assign(C=(df.A+df.B)/2)\n_df.assign(D=(_df.C-np.mean(_df.C))/np.std(_df.C))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214"
  },
  {
    "objectID": "posts/DV_8(1024).html#해결책2-assign",
    "href": "posts/DV_8(1024).html#해결책2-assign",
    "title": "DV 8주차",
    "section": "해결책2 (assign)",
    "text": "해결책2 (assign)\n실패한 코드\n\ndf.assign(C=(df.A+df.B)/2).assign(D=(df.C-np.mean(df.C))/np.std(df.C))\n\nAttributeError: 'DataFrame' object has no attribute 'C'\n\n\n두번째 assign에서 표현된 df.C에서 df current df ( = df.assign(C=(df.A+df.B)/2) 까지 연산된 상태) 를 의미하도록 만들고 싶다. \\(\\to\\) 아래와 같이 lambda df: 를 추가하면 된다.\n\ndf.assign(C=(df.A+df.B)/2).assign(D= lambda df: (df.C-np.mean(df.C))/np.std(df.C))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n- 연쇄할당\n\ndf.assign(C= (df.A+df.B)/2).assign(D= lambda df:df.C+2).assign(E = lambda df: df.D - 2)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      2.5\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n      3.5\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n      4.5\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n      5.5\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n      6.5\n      4.5"
  },
  {
    "objectID": "posts/DV_8(1024).html#fifa23-data",
    "href": "posts/DV_8(1024).html#fifa23-data",
    "title": "DV 8주차",
    "section": "FIFA23 DATA",
    "text": "FIFA23 DATA\n- FIFA23 라는 축구게임이 있음\n- 선수들의 능력치에 대한 데이터셋은 캐글에 공개 되어 있다.\nhttps://www.kaggle.com/datasets/bryanb/fifa-player-stats-database?select=FIFA23_official_data.csv"
  },
  {
    "objectID": "posts/DV_8(1024).html#데이터-살펴보기",
    "href": "posts/DV_8(1024).html#데이터-살펴보기",
    "title": "DV 8주차",
    "section": "데이터 살펴보기",
    "text": "데이터 살펴보기\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/FIFA23_official_data.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n  \n\n5 rows × 29 columns\n\n\n\n트랜스포즈하여 보는 것이 편할 때도 있다\n\ndf.T\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      ...\n      17650\n      17651\n      17652\n      17653\n      17654\n      17655\n      17656\n      17657\n      17658\n      17659\n    \n  \n  \n    \n      ID\n      209658\n      212198\n      224334\n      192985\n      224232\n      212622\n      197445\n      187961\n      208333\n      210514\n      ...\n      256879\n      269546\n      267647\n      253186\n      267461\n      269526\n      267946\n      270567\n      256624\n      256376\n    \n    \n      Name\n      L. Goretzka\n      Bruno Fernandes\n      M. Acuña\n      K. De Bruyne\n      N. Barella\n      J. Kimmich\n      D. Alaba\n      22 Paulinho\n      E. Can\n      João Cancelo\n      ...\n      22 G. Leijon\n      Wu Fei\n      22 E. Grosz\n      22 S. Booth\n      22 L. Grimpe\n      Deng Xiongtao\n      22 Lim Jun Sub\n      A. Demir\n      21 S. Czajor\n      21 F. Jakobsson\n    \n    \n      Age\n      27\n      27\n      30\n      31\n      25\n      27\n      30\n      32\n      28\n      28\n      ...\n      19\n      32\n      18\n      20\n      17\n      19\n      17\n      25\n      18\n      20\n    \n    \n      Photo\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      https://cdn.sofifa.net/players/212/622/23_60.png\n      https://cdn.sofifa.net/players/197/445/23_60.png\n      https://cdn.sofifa.net/players/187/961/22_60.png\n      https://cdn.sofifa.net/players/208/333/23_60.png\n      https://cdn.sofifa.net/players/210/514/23_60.png\n      ...\n      https://cdn.sofifa.net/players/256/879/22_60.png\n      https://cdn.sofifa.net/players/269/546/23_60.png\n      https://cdn.sofifa.net/players/267/647/22_60.png\n      https://cdn.sofifa.net/players/253/186/22_60.png\n      https://cdn.sofifa.net/players/267/461/22_60.png\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      https://cdn.sofifa.net/players/256/376/21_60.png\n    \n    \n      Nationality\n      Germany\n      Portugal\n      Argentina\n      Belgium\n      Italy\n      Germany\n      Austria\n      Brazil\n      Germany\n      Portugal\n      ...\n      Sweden\n      China PR\n      Romania\n      England\n      Germany\n      China PR\n      Korea Republic\n      Turkey\n      Poland\n      Sweden\n    \n    \n      Flag\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/pt.png\n      https://cdn.sofifa.net/flags/ar.png\n      https://cdn.sofifa.net/flags/be.png\n      https://cdn.sofifa.net/flags/it.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/at.png\n      https://cdn.sofifa.net/flags/br.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/pt.png\n      ...\n      https://cdn.sofifa.net/flags/se.png\n      https://cdn.sofifa.net/flags/cn.png\n      https://cdn.sofifa.net/flags/ro.png\n      https://cdn.sofifa.net/flags/gb-eng.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/cn.png\n      https://cdn.sofifa.net/flags/kr.png\n      https://cdn.sofifa.net/flags/tr.png\n      https://cdn.sofifa.net/flags/pl.png\n      https://cdn.sofifa.net/flags/se.png\n    \n    \n      Overall\n      87\n      86\n      85\n      91\n      86\n      89\n      86\n      83\n      82\n      88\n      ...\n      52\n      51\n      52\n      51\n      54\n      48\n      48\n      51\n      50\n      50\n    \n    \n      Potential\n      88\n      87\n      85\n      91\n      89\n      90\n      86\n      83\n      82\n      88\n      ...\n      62\n      51\n      70\n      60\n      68\n      61\n      64\n      56\n      65\n      61\n    \n    \n      Club\n      FC Bayern München\n      Manchester United\n      Sevilla FC\n      Manchester City\n      Inter\n      FC Bayern München\n      Real Madrid CF\n      Al Ahli\n      Borussia Dortmund\n      Manchester City\n      ...\n      Örebro SK\n      Wuhan Three Towns\n      Gaz Metan Mediaş\n      Crewe Alexandra\n      RB Leipzig\n      Meizhou Hakka\n      Jeju United FC\n      Ümraniyespor\n      Fleetwood Town\n      IFK Norrköping\n    \n    \n      Club Logo\n      https://cdn.sofifa.net/teams/21/30.png\n      https://cdn.sofifa.net/teams/11/30.png\n      https://cdn.sofifa.net/teams/481/30.png\n      https://cdn.sofifa.net/teams/10/30.png\n      https://cdn.sofifa.net/teams/44/30.png\n      https://cdn.sofifa.net/teams/21/30.png\n      https://cdn.sofifa.net/teams/243/30.png\n      https://cdn.sofifa.net/teams/112387/30.png\n      https://cdn.sofifa.net/teams/22/30.png\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      https://cdn.sofifa.net/teams/705/30.png\n      https://cdn.sofifa.net/teams/116361/30.png\n      https://cdn.sofifa.net/teams/112637/30.png\n      https://cdn.sofifa.net/teams/121/30.png\n      https://cdn.sofifa.net/teams/112172/30.png\n      https://cdn.sofifa.net/teams/114628/30.png\n      https://cdn.sofifa.net/teams/1478/30.png\n      https://cdn.sofifa.net/teams/113796/30.png\n      https://cdn.sofifa.net/teams/112260/30.png\n      https://cdn.sofifa.net/teams/702/30.png\n    \n    \n      Value\n      €91M\n      €78.5M\n      €46.5M\n      €107.5M\n      €89.5M\n      €105.5M\n      €55.5M\n      €28.5M\n      €30.5M\n      €82.5M\n      ...\n      €150K\n      €30K\n      €180K\n      €110K\n      €210K\n      €100K\n      €100K\n      €70K\n      €90K\n      €90K\n    \n    \n      Wage\n      €115K\n      €190K\n      €46K\n      €350K\n      €110K\n      €130K\n      €220K\n      €61K\n      €63K\n      €250K\n      ...\n      €500\n      €2K\n      €500\n      €850\n      €500\n      €500\n      €500\n      €2K\n      €500\n      €500\n    \n    \n      Special\n      2312\n      2305\n      2303\n      2303\n      2296\n      2283\n      2277\n      2273\n      2271\n      2262\n      ...\n      779\n      777\n      775\n      768\n      767\n      762\n      761\n      759\n      758\n      749\n    \n    \n      Preferred Foot\n      Right\n      Right\n      Left\n      Right\n      Right\n      Right\n      Left\n      Right\n      Right\n      Right\n      ...\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Left\n    \n    \n      International Reputation\n      4.0\n      3.0\n      2.0\n      4.0\n      3.0\n      4.0\n      4.0\n      3.0\n      3.0\n      3.0\n      ...\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n    \n    \n      Weak Foot\n      4.0\n      3.0\n      3.0\n      5.0\n      3.0\n      4.0\n      4.0\n      4.0\n      4.0\n      4.0\n      ...\n      3.0\n      2.0\n      2.0\n      2.0\n      3.0\n      3.0\n      2.0\n      2.0\n      2.0\n      2.0\n    \n    \n      Skill Moves\n      3.0\n      4.0\n      3.0\n      4.0\n      3.0\n      3.0\n      3.0\n      4.0\n      3.0\n      4.0\n      ...\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n    \n    \n      Work Rate\n      High/ Medium\n      High/ High\n      High/ High\n      High/ High\n      High/ High\n      High/ Medium\n      Medium/ Medium\n      High/ High\n      Medium/ High\n      High/ Medium\n      ...\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n    \n    \n      Body Type\n      Unique\n      Unique\n      Stocky (170-185)\n      Unique\n      Normal (170-)\n      Normal (170-185)\n      Normal (170-185)\n      Normal (170-185)\n      Stocky (185+)\n      Unique\n      ...\n      Normal (185+)\n      Normal (185+)\n      Lean (185+)\n      Lean (185+)\n      Lean (185+)\n      Normal (185+)\n      Lean (185+)\n      Lean (185+)\n      Normal (185+)\n      Normal (185+)\n    \n    \n      Real Face\n      Yes\n      Yes\n      No\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      ...\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n    \n    \n      Position\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos15\">LCM\n      <span class=\"pos pos7\">LB\n      <span class=\"pos pos13\">RCM\n      <span class=\"pos pos13\">RCM\n      <span class=\"pos pos9\">RDM\n      <span class=\"pos pos6\">LCB\n      <span class=\"pos pos15\">LCM\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos7\">LB\n      ...\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n    \n    \n      Joined\n      Jul 1, 2018\n      Jan 30, 2020\n      Sep 14, 2020\n      Aug 30, 2015\n      Sep 1, 2020\n      Jul 1, 2015\n      Jul 1, 2021\n      Jul 22, 2021\n      Feb 18, 2020\n      Aug 7, 2019\n      ...\n      Jun 14, 2020\n      Feb 15, 2019\n      Jul 1, 2020\n      Jul 1, 2019\n      Feb 7, 2022\n      Apr 11, 2022\n      Jan 1, 2022\n      Jun 6, 2021\n      Jan 1, 2020\n      Jan 8, 2020\n    \n    \n      Loaned From\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      Contract Valid Until\n      2026\n      2026\n      2024\n      2025\n      2026\n      2025\n      2026\n      2024\n      2024\n      2027\n      ...\n      2022\n      2022\n      2022\n      2022\n      2023\n      2027\n      2026\n      2023\n      2021\n      2021\n    \n    \n      Height\n      189cm\n      179cm\n      172cm\n      181cm\n      172cm\n      177cm\n      180cm\n      183cm\n      186cm\n      182cm\n      ...\n      188cm\n      186cm\n      190cm\n      195cm\n      186cm\n      190cm\n      195cm\n      190cm\n      187cm\n      186cm\n    \n    \n      Weight\n      82kg\n      69kg\n      69kg\n      70kg\n      68kg\n      75kg\n      78kg\n      80kg\n      86kg\n      74kg\n      ...\n      81kg\n      78kg\n      70kg\n      80kg\n      78kg\n      78kg\n      84kg\n      82kg\n      79kg\n      78kg\n    \n    \n      Release Clause\n      €157M\n      €155M\n      €97.7M\n      €198.9M\n      €154.4M\n      €182M\n      €113.8M\n      €48.5M\n      €51.9M\n      €152.6M\n      ...\n      €218K\n      €47K\n      €356K\n      €215K\n      €488K\n      €218K\n      €188K\n      €142K\n      €214K\n      €131K\n    \n    \n      Kit Number\n      8.0\n      8.0\n      19.0\n      17.0\n      23.0\n      6.0\n      4.0\n      15.0\n      23.0\n      7.0\n      ...\n      33.0\n      1.0\n      99.0\n      27.0\n      43.0\n      35.0\n      21.0\n      12.0\n      40.0\n      30.0\n    \n    \n      Best Overall Rating\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n29 rows × 17660 columns\n\n\n\n\ncolumns 조사\n\ndf.keys()\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight',\n       'Release Clause', 'Kit Number', 'Best Overall Rating'],\n      dtype='object')\n\n\n\ndf.Body Type\n\nSyntaxError: invalid syntax (<ipython-input-29-8965601661e6>, line 1)\n\n\n띄어쓰기가 되어있어서 흠..\n\n\n각 column별로 자료형 조사\n\ndf['ID'].dtype\n\n\nfor key in df.keys():\n    print(df[key].dtype)\n\n\ndtypes = [df[key].dtype for key in df.keys()]\npd.DataFrame({'colname':df.keys(), 'dtype':dtypes})\n\n\n\n결측치 조사\n\n[df[key].isna().sum() for key in df.keys()]\n\n\npd.DataFrame({'colname':df.keys(), \n              'dtype':[df[key].dtype for key in df.keys()], \n              'na':[df[key].isna().sum() for key in df.keys()]})\n\n\n\n\n\n  \n    \n      \n      colname\n      dtype\n      na\n    \n  \n  \n    \n      0\n      ID\n      int64\n      0\n    \n    \n      1\n      Name\n      object\n      0\n    \n    \n      2\n      Age\n      int64\n      0\n    \n    \n      3\n      Photo\n      object\n      0\n    \n    \n      4\n      Nationality\n      object\n      0\n    \n    \n      5\n      Flag\n      object\n      0\n    \n    \n      6\n      Overall\n      int64\n      0\n    \n    \n      7\n      Potential\n      int64\n      0\n    \n    \n      8\n      Club\n      object\n      211\n    \n    \n      9\n      Club Logo\n      object\n      0\n    \n    \n      10\n      Value\n      object\n      0\n    \n    \n      11\n      Wage\n      object\n      0\n    \n    \n      12\n      Special\n      int64\n      0\n    \n    \n      13\n      Preferred Foot\n      object\n      0\n    \n    \n      14\n      International Reputation\n      float64\n      0\n    \n    \n      15\n      Weak Foot\n      float64\n      0\n    \n    \n      16\n      Skill Moves\n      float64\n      0\n    \n    \n      17\n      Work Rate\n      object\n      0\n    \n    \n      18\n      Body Type\n      object\n      38\n    \n    \n      19\n      Real Face\n      object\n      38\n    \n    \n      20\n      Position\n      object\n      35\n    \n    \n      21\n      Joined\n      object\n      1098\n    \n    \n      22\n      Loaned From\n      object\n      16966\n    \n    \n      23\n      Contract Valid Until\n      object\n      361\n    \n    \n      24\n      Height\n      object\n      0\n    \n    \n      25\n      Weight\n      object\n      0\n    \n    \n      26\n      Release Clause\n      object\n      1151\n    \n    \n      27\n      Kit Number\n      float64\n      35\n    \n    \n      28\n      Best Overall Rating\n      object\n      17639\n    \n  \n\n\n\n\n\n열의선택: 결측치가 10000개 이상인 열을 보고싶다면?\n\n\ndf.loc[:,[df[key].isna().sum()>10000 for key in df.keys()]]\n\n\n\n\n\n  \n    \n      \n      Loaned From\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n    \n    \n      1\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      17655\n      NaN\n      NaN\n    \n    \n      17656\n      NaN\n      NaN\n    \n    \n      17657\n      NaN\n      NaN\n    \n    \n      17658\n      NaN\n      NaN\n    \n    \n      17659\n      NaN\n      NaN\n    \n  \n\n17660 rows × 2 columns\n\n\n\n\n\n.info()\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  object \n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(4), int64(5), object(20)\nmemory usage: 3.9+ MB\n\n\n### .describe()\n숫자들이 저장된 column에 대하여 기본통계량 조사\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      ID\n      Age\n      Overall\n      Potential\n      Special\n      International Reputation\n      Weak Foot\n      Skill Moves\n      Kit Number\n    \n  \n  \n    \n      count\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17625.000000\n    \n    \n      mean\n      246319.424462\n      23.127746\n      63.369592\n      70.981200\n      1537.915855\n      1.106285\n      2.900340\n      2.297169\n      25.037957\n    \n    \n      std\n      31487.892861\n      4.639821\n      8.036268\n      6.529836\n      285.893809\n      0.407021\n      0.663523\n      0.754264\n      19.154116\n    \n    \n      min\n      16.000000\n      15.000000\n      43.000000\n      42.000000\n      749.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n    \n    \n      25%\n      240732.500000\n      20.000000\n      58.000000\n      67.000000\n      1387.000000\n      1.000000\n      3.000000\n      2.000000\n      11.000000\n    \n    \n      50%\n      257041.000000\n      22.000000\n      63.000000\n      71.000000\n      1548.000000\n      1.000000\n      3.000000\n      2.000000\n      22.000000\n    \n    \n      75%\n      263027.500000\n      26.000000\n      69.000000\n      75.000000\n      1727.000000\n      1.000000\n      3.000000\n      3.000000\n      32.000000\n    \n    \n      max\n      271340.000000\n      54.000000\n      91.000000\n      95.000000\n      2312.000000\n      5.000000\n      5.000000\n      5.000000\n      99.000000\n    \n  \n\n\n\n\n- pandas_profiling.ProfileReport()를 이용한 전체적인 조사\n\npandas_profiling.ProfileReport(df).to_file('fifa2023_reprot.html')\n\n\n\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/pandas_profiling/model/correlations.py:73: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\nTo hide this warning, disable the calculation\n(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\nIf this is problematic for your use case, please report this as an issue:\nhttps://github.com/ydataai/pandas-profiling/issues\n(include the error message: 'No data; `observed` has size 0.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n특정열을 중심으로 정렬하여 보기\n\ndf.sort_values(by='Overall', ascending=False) \n# ascending=False  # 내림차순\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      41\n      188545\n      R. Lewandowski\n      33\n      https://cdn.sofifa.net/players/188/545/23_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      91\n      91\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 18, 2022\n      NaN\n      2025\n      185cm\n      81kg\n      €172.2M\n      9.0\n      NaN\n    \n    \n      124\n      165153\n      K. Benzema\n      34\n      https://cdn.sofifa.net/players/165/153/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      91\n      Real Madrid CF\n      https://cdn.sofifa.net/teams/243/30.png\n      ...\n      Yes\n      <span class=\"pos pos21\">CF\n      Jul 9, 2009\n      NaN\n      2023\n      185cm\n      81kg\n      €131.2M\n      9.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      56\n      158023\n      L. Messi\n      35\n      https://cdn.sofifa.net/players/158/023/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      91\n      91\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos23\">RW\n      Aug 10, 2021\n      NaN\n      2023\n      169cm\n      67kg\n      €99.9M\n      30.0\n      NaN\n    \n    \n      75\n      231747\n      K. Mbappé\n      23\n      https://cdn.sofifa.net/players/231/747/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      95\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 1, 2018\n      NaN\n      2025\n      182cm\n      73kg\n      €366.7M\n      7.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      15513\n      266751\n      22 Jung Ho Yeon\n      20\n      https://cdn.sofifa.net/players/266/751/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      45\n      53\n      GwangJu FC\n      https://cdn.sofifa.net/teams/112258/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 20, 2022\n      NaN\n      2026\n      180cm\n      73kg\n      €145K\n      23.0\n      NaN\n    \n    \n      16215\n      268279\n      22 J. Looschen\n      24\n      https://cdn.sofifa.net/players/268/279/22_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      44\n      47\n      SV Meppen\n      https://cdn.sofifa.net/teams/110597/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Mar 19, 2022\n      NaN\n      2026\n      178cm\n      78kg\n      €92K\n      42.0\n      NaN\n    \n    \n      16042\n      255283\n      20 Kim Yeong Geun\n      22\n      https://cdn.sofifa.net/players/255/283/20_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      44\n      49\n      Gyeongnam FC\n      https://cdn.sofifa.net/teams/111588/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 9, 2020\n      NaN\n      2020\n      174cm\n      71kg\n      €53K\n      43.0\n      NaN\n    \n    \n      14634\n      269038\n      22 Zhang Wenxuan\n      16\n      https://cdn.sofifa.net/players/269/038/22_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      44\n      59\n      Guangzhou FC\n      https://cdn.sofifa.net/teams/111839/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      May 1, 2022\n      NaN\n      2022\n      175cm\n      70kg\n      €239K\n      29.0\n      NaN\n    \n    \n      17618\n      168933\n      07 I. Paskov\n      33\n      https://cdn.sofifa.net/players/168/933/07_60.png\n      Bulgaria\n      https://cdn.sofifa.net/flags/bg.png\n      43\n      42\n      NaN\n      https://cdn.sofifa.net/flags/bg.png\n      ...\n      NaN\n      <span class=\"pos pos28\">SUB\n      NaN\n      NaN\n      NaN\n      184cm\n      79kg\n      NaN\n      24.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\ndf.sort_values(by='Overall', ascending=False,ignore_index=True)\n# df.sort_values(by='Overall', ascending=False).reset_index() 와 같음\n# 맨 왼쪽 인덱스 순서 정렬\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      188545\n      R. Lewandowski\n      33\n      https://cdn.sofifa.net/players/188/545/23_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      91\n      91\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 18, 2022\n      NaN\n      2025\n      185cm\n      81kg\n      €172.2M\n      9.0\n      NaN\n    \n    \n      1\n      165153\n      K. Benzema\n      34\n      https://cdn.sofifa.net/players/165/153/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      91\n      Real Madrid CF\n      https://cdn.sofifa.net/teams/243/30.png\n      ...\n      Yes\n      <span class=\"pos pos21\">CF\n      Jul 9, 2009\n      NaN\n      2023\n      185cm\n      81kg\n      €131.2M\n      9.0\n      NaN\n    \n    \n      2\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      3\n      158023\n      L. Messi\n      35\n      https://cdn.sofifa.net/players/158/023/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      91\n      91\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos23\">RW\n      Aug 10, 2021\n      NaN\n      2023\n      169cm\n      67kg\n      €99.9M\n      30.0\n      NaN\n    \n    \n      4\n      231747\n      K. Mbappé\n      23\n      https://cdn.sofifa.net/players/231/747/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      95\n      Paris Saint-Germain\n      https://cdn.sofifa.net/teams/73/30.png\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 1, 2018\n      NaN\n      2025\n      182cm\n      73kg\n      €366.7M\n      7.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      266751\n      22 Jung Ho Yeon\n      20\n      https://cdn.sofifa.net/players/266/751/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      45\n      53\n      GwangJu FC\n      https://cdn.sofifa.net/teams/112258/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 20, 2022\n      NaN\n      2026\n      180cm\n      73kg\n      €145K\n      23.0\n      NaN\n    \n    \n      17656\n      268279\n      22 J. Looschen\n      24\n      https://cdn.sofifa.net/players/268/279/22_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      44\n      47\n      SV Meppen\n      https://cdn.sofifa.net/teams/110597/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Mar 19, 2022\n      NaN\n      2026\n      178cm\n      78kg\n      €92K\n      42.0\n      NaN\n    \n    \n      17657\n      255283\n      20 Kim Yeong Geun\n      22\n      https://cdn.sofifa.net/players/255/283/20_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      44\n      49\n      Gyeongnam FC\n      https://cdn.sofifa.net/teams/111588/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 9, 2020\n      NaN\n      2020\n      174cm\n      71kg\n      €53K\n      43.0\n      NaN\n    \n    \n      17658\n      269038\n      22 Zhang Wenxuan\n      16\n      https://cdn.sofifa.net/players/269/038/22_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      44\n      59\n      Guangzhou FC\n      https://cdn.sofifa.net/teams/111839/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      May 1, 2022\n      NaN\n      2022\n      175cm\n      70kg\n      €239K\n      29.0\n      NaN\n    \n    \n      17659\n      168933\n      07 I. Paskov\n      33\n      https://cdn.sofifa.net/players/168/933/07_60.png\n      Bulgaria\n      https://cdn.sofifa.net/flags/bg.png\n      43\n      42\n      NaN\n      https://cdn.sofifa.net/flags/bg.png\n      ...\n      NaN\n      <span class=\"pos pos28\">SUB\n      NaN\n      NaN\n      NaN\n      184cm\n      79kg\n      NaN\n      24.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\n\n특정열을 중심으로 그룹화하여 보기(\\(\\star\\)): groupby\n\ndf.query('Nationality == \"Germany\"')['Overall'].mean()\n\n63.50481695568401\n\n\n\ndf.Nationality.unique()\n\narray(['Germany', 'Portugal', 'Argentina', 'Belgium', 'Italy', 'Austria',\n       'Brazil', 'Croatia', 'Serbia', 'Spain', 'Netherlands', 'France',\n       'Colombia', 'England', 'Uruguay', 'Morocco', 'Egypt', 'Algeria',\n       'Ukraine', 'United States', \"Côte d'Ivoire\", 'Poland', 'Chile',\n       'Senegal', 'Central African Republic', 'Denmark', 'Nigeria',\n       'Mexico', 'Turkey', 'Canada', 'Wales', 'Scotland', 'Romania',\n       'Czech Republic', 'Ghana', 'Korea Republic',\n       'Bosnia and Herzegovina', 'Mali', 'Slovakia', 'Armenia', 'Norway',\n       'Switzerland', 'Cameroon', 'Peru', 'Jamaica', 'Zambia', 'Guinea',\n       'Sweden', 'North Macedonia', 'Russia', 'Tunisia', 'Malta',\n       'Angola', 'Republic of Ireland', 'Ecuador', 'Benin', 'Paraguay',\n       'Montenegro', 'Australia', 'Comoros', 'Gabon', 'Iceland',\n       'Slovenia', 'Japan', 'Israel', 'China PR', 'Venezuela', 'Liberia',\n       'Greece', 'Bulgaria', 'Honduras', 'Saudi Arabia', 'Curacao',\n       'Northern Ireland', 'Guinea Bissau', 'Kosovo', 'Hungary',\n       'Finland', 'Costa Rica', 'Albania', 'Congo DR', 'Iran',\n       'Mozambique', 'Suriname', 'Cape Verde Islands', 'Bolivia',\n       'Madagascar', 'New Zealand', 'Burkina Faso', 'Dominican Republic',\n       'Kazakhstan', 'Syria', 'Luxembourg', 'Kenya', 'Zimbabwe', 'Haiti',\n       'Uzbekistan', 'South Africa', 'Cyprus', 'Qatar',\n       'Equatorial Guinea', 'Libya', 'Thailand', 'Togo',\n       'Trinidad and Tobago', 'Liechtenstein', 'Gambia', 'Georgia',\n       'Philippines', 'Burundi', 'United Arab Emirates', 'Grenada',\n       'Iraq', 'Panama', 'Malaysia', 'Moldova', 'Congo', 'India',\n       'Jordan', 'Kuwait', 'Antigua and Barbuda', 'Cuba', 'Vietnam',\n       'Korea DPR', 'Uganda', 'Lithuania', 'Estonia', 'Montserrat',\n       'Sierra Leone', 'Afghanistan', 'New Caledonia', 'Belarus', 'Laos',\n       'Saint Lucia', 'Bhutan', 'Guyana', 'Mauritania', 'Faroe Islands',\n       'Namibia', 'Niger', 'Palestine', 'Sudan', 'Azerbaijan',\n       'Hong Kong', 'Gibraltar', 'Tanzania', 'Latvia', 'Chinese Taipei',\n       'Singapore', 'Lebanon', 'El Salvador', 'Indonesia', 'Guatemala',\n       'Papua New Guinea', 'Puerto Rico', 'Malawi', 'South Sudan',\n       'Ethiopia', 'San Marino', 'Andorra', 'Saint Kitts and Nevis'],\n      dtype=object)\n\n\n\nlen(df.Nationality.unique())\n\n161\n\n\n\ndf.groupby(by='Nationality')[['Overall']].agg({np.mean,len}).sort_values(('Overall', 'mean'),ascending=False)\n\n\n\n\n\n  \n    \n      \n      Overall\n    \n    \n      \n      mean\n      len\n    \n    \n      Nationality\n      \n      \n    \n  \n  \n    \n      Philippines\n      74.000000\n      1\n    \n    \n      Namibia\n      72.000000\n      1\n    \n    \n      Mozambique\n      72.000000\n      2\n    \n    \n      Kuwait\n      71.000000\n      1\n    \n    \n      Brazil\n      70.556586\n      539\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      San Marino\n      53.000000\n      1\n    \n    \n      China PR\n      52.230769\n      325\n    \n    \n      South Sudan\n      52.000000\n      5\n    \n    \n      India\n      51.994681\n      188\n    \n    \n      Saint Kitts and Nevis\n      51.000000\n      1\n    \n  \n\n161 rows × 2 columns"
  },
  {
    "objectID": "posts/DV_8(1024).html#데이터-정리하기",
    "href": "posts/DV_8(1024).html#데이터-정리하기",
    "title": "DV 8주차",
    "section": "데이터 정리하기",
    "text": "데이터 정리하기\n\n칼럼이름 변경\n\ndf.columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight',\n       'Release Clause', 'Kit Number', 'Best Overall Rating'],\n      dtype='object')\n\n\n\nlist(map(lambda x: x.replace(' ','_'), df.columns))\n\n['ID',\n 'Name',\n 'Age',\n 'Photo',\n 'Nationality',\n 'Flag',\n 'Overall',\n 'Potential',\n 'Club',\n 'Club_Logo',\n 'Value',\n 'Wage',\n 'Special',\n 'Preferred_Foot',\n 'International_Reputation',\n 'Weak_Foot',\n 'Skill_Moves',\n 'Work_Rate',\n 'Body_Type',\n 'Real_Face',\n 'Position',\n 'Joined',\n 'Loaned_From',\n 'Contract_Valid_Until',\n 'Height',\n 'Weight',\n 'Release_Clause',\n 'Kit_Number',\n 'Best_Overall_Rating']\n\n\n\ndf.set_axis(list(map(lambda x: x.replace(' ','_'), df.columns)), axis=1)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club_Logo\n      ...\n      Real_Face\n      Position\n      Joined\n      Loaned_From\n      Contract_Valid_Until\n      Height\n      Weight\n      Release_Clause\n      Kit_Number\n      Best_Overall_Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\ndf.set_axis(pd.Index(map(lambda x: x.replace(' ','_'), df.columns)), axis=1)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club_Logo\n      ...\n      Real_Face\n      Position\n      Joined\n      Loaned_From\n      Contract_Valid_Until\n      Height\n      Weight\n      Release_Clause\n      Kit_Number\n      Best_Overall_Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\nindex 로 쓰는게 좀 더 명확함\n\n\n\n결측치 제거\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  object \n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(4), int64(5), object(20)\nmemory usage: 3.9+ MB\n\n\n\ndf.drop(columns=['Loaned From', 'Best Overall Rating'])\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Work Rate\n      Body Type\n      Real Face\n      Position\n      Joined\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      High/ Medium\n      Unique\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      High/ High\n      Stocky (170-185)\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      High/ High\n      Normal (170-)\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n    \n  \n\n17660 rows × 27 columns\n\n\n\n- Height, Weight의 자료형을 float형으로 수정하기\n\ndf[['Height', 'Weight']]\n\n\n\n\n\n  \n    \n      \n      Height\n      Weight\n    \n  \n  \n    \n      0\n      189cm\n      82kg\n    \n    \n      1\n      179cm\n      69kg\n    \n    \n      2\n      172cm\n      69kg\n    \n    \n      3\n      181cm\n      70kg\n    \n    \n      4\n      172cm\n      68kg\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      17655\n      190cm\n      78kg\n    \n    \n      17656\n      195cm\n      84kg\n    \n    \n      17657\n      190cm\n      82kg\n    \n    \n      17658\n      187cm\n      79kg\n    \n    \n      17659\n      186cm\n      78kg\n    \n  \n\n17660 rows × 2 columns\n\n\n\ncm, kg으로 되어있어서 object형인데 이걸 float형으로 바꾸자\n\ndf.assign(\n    Height= list(map(lambda x: float(x[:-2]), df.Height)),\n    Weight= list(map(lambda x: float(x[:-2]), df.Weight))\n)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189.0\n      82.0\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179.0\n      69.0\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172.0\n      69.0\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181.0\n      70.0\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172.0\n      68.0\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190.0\n      78.0\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195.0\n      84.0\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190.0\n      82.0\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187.0\n      79.0\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186.0\n      78.0\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n- Release Clause의 자료형을 float으로 수정하기\n\ndf['Release Clause']\n\n0          €157M\n1          €155M\n2         €97.7M\n3        €198.9M\n4        €154.4M\n          ...   \n17655      €218K\n17656      €188K\n17657      €142K\n17658      €214K\n17659      €131K\nName: Release Clause, Length: 17660, dtype: object\n\n\n\n_f = lambda x: float(x[1:-1])*1000 if x[-1]=='K' else float(x[1:-1])*1000000\n\n\n_f('€157M')\n\n157000000.0\n\n\n\n_f('€131K')\n\n131000.0\n\n\n(시도1) - 실패\n\nlist(map(_f, df['Release Clause']))\n\nTypeError: 'float' object is not subscriptable\n\n\n\ndf['Release Clause'].isna().sum()   # 이 column에는 1151개의 결측치가 존재\n\n1151\n\n\n(nan에 대한 예비학습)\n\ndf.loc[df['Release Clause'].isna(), 'Release Clause']\n\n18       NaN\n34       NaN\n38       NaN\n49       NaN\n50       NaN\n        ... \n17378    NaN\n17386    NaN\n17535    NaN\n17590    NaN\n17618    NaN\nName: Release Clause, Length: 1151, dtype: object\n\n\n\ndf.loc[18, 'Release Clause']\n\nnan\n\n\n\npd.isna(df.loc[18, 'Release Clause'])\n\nTrue\n\n\n\ntype(df.loc[18, 'Release Clause'])\n\nfloat\n\n\n\ndf.loc[18, 'Release Clause'][-1]\n\nTypeError: 'float' object is not subscriptable\n\n\n\n_f 함수에는 문자열이 들어가야하는데 nan이 들어가니까 에러가 뜸..\n\n(시도2) - 성공\n\ndf.rename(columns={'Release Clause':'ReleaseClause'})\\\n.assign(ReleaseClause = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df['Release Clause'])))\\\n.rename(columns={'ReleaseClause':'Release Clause'})\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      157000000.0\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      155000000.0\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      97700000.0\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      198900000.0\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      154400000.0\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      218000.0\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      188000.0\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      142000.0\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      214000.0\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      131000.0\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n\ndf.rename(columns={'Release Clause':'ReleaseClause'})\\\n.assign(ReleaseClause = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df['Release Clause'])))\\\n.rename(columns={'ReleaseClause':'Release Clause'}).info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  float64\n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(5), int64(5), object(19)\nmemory usage: 3.9+ MB\n\n\n26번 컬럼이 float64로 바뀜!\n(시도3) - 성공, 그냥 결측치를 제거하고 변경해도 무방\n\ndf2 = df.drop(columns=['Loaned From', 'Best Overall Rating']).dropna()\ndf2['Release Clause'] = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df2['Release Clause']))\ndf2\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Work Rate\n      Body Type\n      Real Face\n      Position\n      Joined\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      High/ Medium\n      Unique\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      2026\n      189cm\n      82kg\n      157000000.0\n      8.0\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      2026\n      179cm\n      69kg\n      155000000.0\n      8.0\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      High/ High\n      Stocky (170-185)\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      2024\n      172cm\n      69kg\n      97700000.0\n      19.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      2025\n      181cm\n      70kg\n      198900000.0\n      17.0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      High/ High\n      Normal (170-)\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      2026\n      172cm\n      68kg\n      154400000.0\n      23.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      2027\n      190cm\n      78kg\n      218000.0\n      35.0\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      2026\n      195cm\n      84kg\n      188000.0\n      21.0\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      2023\n      190cm\n      82kg\n      142000.0\n      12.0\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      2021\n      187cm\n      79kg\n      214000.0\n      40.0\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      2021\n      186cm\n      78kg\n      131000.0\n      30.0\n    \n  \n\n16364 rows × 27 columns\n\n\n\n\ndf2.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 16364 entries, 0 to 17659\nData columns (total 27 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        16364 non-null  int64  \n 1   Name                      16364 non-null  object \n 2   Age                       16364 non-null  int64  \n 3   Photo                     16364 non-null  object \n 4   Nationality               16364 non-null  object \n 5   Flag                      16364 non-null  object \n 6   Overall                   16364 non-null  int64  \n 7   Potential                 16364 non-null  int64  \n 8   Club                      16364 non-null  object \n 9   Club Logo                 16364 non-null  object \n 10  Value                     16364 non-null  object \n 11  Wage                      16364 non-null  object \n 12  Special                   16364 non-null  int64  \n 13  Preferred Foot            16364 non-null  object \n 14  International Reputation  16364 non-null  float64\n 15  Weak Foot                 16364 non-null  float64\n 16  Skill Moves               16364 non-null  float64\n 17  Work Rate                 16364 non-null  object \n 18  Body Type                 16364 non-null  object \n 19  Real Face                 16364 non-null  object \n 20  Position                  16364 non-null  object \n 21  Joined                    16364 non-null  object \n 22  Contract Valid Until      16364 non-null  object \n 23  Height                    16364 non-null  object \n 24  Weight                    16364 non-null  object \n 25  Release Clause            16364 non-null  float64\n 26  Kit Number                16364 non-null  float64\ndtypes: float64(5), int64(5), object(17)\nmemory usage: 3.5+ MB\n\n\n\n분석의 편의를 위하여 (1) colnames를 변경하고 (2) 결측치를 제거하고 (3) 몇 가지 전 처리를 추가로 진행한 뒤 df2를 만들어서 분석하는게 좋음"
  },
  {
    "objectID": "posts/DV_8(1024).html#데이터-분석하기",
    "href": "posts/DV_8(1024).html#데이터-분석하기",
    "title": "DV 8주차",
    "section": "데이터 분석하기",
    "text": "데이터 분석하기\n\nOverall vs Potential\n(의문)현재 능력치가 좋은 선수는 잠재력이 없는 거일까?\n\ndf.Potential # 잠재능력\n\n0        88\n1        87\n2        85\n3        91\n4        89\n         ..\n17655    61\n17656    64\n17657    56\n17658    65\n17659    61\nName: Potential, Length: 17660, dtype: int64\n\n\n\ndf.Overall  # 전반적인\n\n0        87\n1        86\n2        85\n3        91\n4        86\n         ..\n17655    48\n17656    48\n17657    51\n17658    50\n17659    50\nName: Overall, Length: 17660, dtype: int64\n\n\n\nfig = ggplot(data=df) + geom_point(aes(x='Overall',y='Potential'))\nfig\n\n\n\n\n<ggplot: (8736740509057)>\n\n\n\n뭔가 Potential > Overall 인 관계가 성립하는 듯 하다. \\(\\to\\) 우리가 생각하는 포텐셜의 의미는 사실 Potential2 = Potential - Overall 에 더 가깝다. \\(\\to\\) Potential2 = Potential - Overall 인 변수를 새로 만들고 시각화 해보자.\n\n- Potential2 = Potential - Overall 를 계산하여 새로운 열을 추가하자.\n\ndf.eval('Potential2 = Potential - Overall')\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n      1\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n      1\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n      0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n      0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n      13\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n      16\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n      5\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n      15\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n      11\n    \n  \n\n17660 rows × 30 columns\n\n\n\n- 수정된 df에 다시 시각화를 하면\n\nggplot(data=df.eval('Potential2 = Potential - Overall'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.01)\n\n\n\n\n<ggplot: (8785454643557)>\n\n\n\nggplot(data=df.eval('Potential2 = Potential - Overall'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.05,position='jitter')\n\n# position='jitter' 흩뿌려진 점\n\n\n\n\n<ggplot: (8785454337349)>\n\n\n- 해석\n\n해석1: Overall, Potential2는 음의 상관관계가 있다.\n해석2: 0근처에 데이터가 많음.. 이미 은퇴한 선수들이 아닐까?\n해석3: Overall의 값이 작을수록 Potential2의 분산이 크다.\n\n- 은퇴한 선수들을 제외하고 시각화\n\nggplot(data=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.05,position='jitter')\n\n# .query('Potential2 > 1') : 은퇴선수제외, 0에 몰려있는 데이터 제외\n\n\n\n\n<ggplot: (8785454565309)>\n\n\n- Overall에 따라서 구간을 나누고 그 구간에 대응하는 boxplot을 그리자\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.Overall.describe()\n\ncount    13644.000000\nmean        61.415347\nstd          7.247821\nmin         44.000000\n25%         56.000000\n50%         61.000000\n75%         66.000000\nmax         91.000000\nName: Overall, dtype: float64\n\n\n\ndef f(x):\n    if x>66: \n        y='66<'\n    elif x>61:\n        y='61~66'\n    elif x>56:\n        y='56~61'\n    else:\n        y='<56' \n    return y\n\n\nggplot(data=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall))))\\\n    + geom_boxplot(aes(x='Overall_grouped',y='Potential2',color='Overall_grouped'))\n\nNameError: name 'f' is not defined\n\n\n\nOverall_grouped = “<56” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “<56”에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “56 ~ 61” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “56~61” 에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “61 ~ 66” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “61 ~ 66” 에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “66<” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “66<” 에 대응하는 박스플랏의 x축위치로 설정\n\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.query(\"Overall_grouped == '66<'\").Overall.mean()\n\n71.8127687727423\n\n\n(방법1)\n\ndef g(x):\n    if x=='66<': \n        y= 71.8127687727423\n    elif x=='61~66':\n        y= 63.773918342474104\n    elif x=='56~61':\n        y= 59.155840684309005\n    else:\n        y= 52.87743190661479\n    return y\n\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.assign(Overall_x= lambda df: list(map(g,df.Overall_grouped)))\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n      Overall_grouped\n      Overall_x\n    \n  \n  \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      10\n      228251\n      L. Pellegrini\n      26\n      https://cdn.sofifa.net/players/228/251/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      84\n      87\n      Roma\n      https://cdn.sofifa.net/teams/52/30.png\n      ...\n      NaN\n      2026\n      186cm\n      77kg\n      €97.6M\n      7.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      13\n      225193\n      Merino\n      26\n      https://cdn.sofifa.net/players/225/193/23_60.png\n      Spain\n      https://cdn.sofifa.net/flags/es.png\n      83\n      86\n      Real Sociedad\n      https://cdn.sofifa.net/teams/457/30.png\n      ...\n      NaN\n      2025\n      189cm\n      83kg\n      €102.2M\n      8.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      17\n      228702\n      F. de Jong\n      25\n      https://cdn.sofifa.net/players/228/702/23_60.png\n      Netherlands\n      https://cdn.sofifa.net/flags/nl.png\n      87\n      92\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      NaN\n      2026\n      180cm\n      74kg\n      €247.6M\n      21.0\n      NaN\n      5\n      66<\n      71.812769\n    \n    \n      21\n      231281\n      T. Alexander-Arnold\n      23\n      https://cdn.sofifa.net/players/231/281/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      87\n      90\n      Liverpool\n      https://cdn.sofifa.net/teams/9/30.png\n      ...\n      NaN\n      2025\n      180cm\n      69kg\n      €193.5M\n      66.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n      13\n      <56\n      52.877432\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n      16\n      <56\n      52.877432\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n      5\n      <56\n      52.877432\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n      15\n      <56\n      52.877432\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n      11\n      <56\n      52.877432\n    \n  \n\n13644 rows × 32 columns\n\n\n\n\ndf2=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.assign(Overall_x= lambda df: list(map(g,df.Overall_grouped)))\n\n\nggplot(data=df2)\\\n+geom_point(aes(x='Overall',y='Potential2',color='Overall_grouped'),position='jitter',alpha=0.05)\\\n+geom_boxplot(aes(x='Overall_x',y='Potential2',color='Overall_grouped'))\n\n<ggplot: (8751309238629)>\n\n\n(방법2)\n\n_df = df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\n\n\ndf3=_df.groupby(by=\"Overall_grouped\").agg({'Overall':np.mean}).reset_index()\\\n.rename(columns={'Overall':'Overall_x'}).merge(_df)\n\n\nggplot(data=df3)\\\n+geom_point(aes(x='Overall',y='Potential2',color='Overall_grouped'),position='jitter',alpha=0.05)\\\n+geom_boxplot(aes(x='Overall_x',y='Potential2',color='Overall_grouped'))\n\n<ggplot: (8751308728441)>\n\n\n\ndf3.head()\n\n\n\n\n\n  \n    \n      \n      Overall_grouped\n      Overall_x\n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      ...\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n    \n  \n  \n    \n      0\n      56~61\n      59.155841\n      227288\n      J. Flores\n      26\n      https://cdn.sofifa.net/players/227/288/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      61\n      64\n      ...\n      <span class=\"pos pos9\">RDM\n      Jan 31, 2022\n      NaN\n      2024\n      180cm\n      75kg\n      €609K\n      21.0\n      NaN\n      3\n    \n    \n      1\n      56~61\n      59.155841\n      270916\n      A. Smrcka\n      19\n      https://cdn.sofifa.net/players/270/916/23_60.png\n      Austria\n      https://cdn.sofifa.net/flags/at.png\n      60\n      70\n      ...\n      <span class=\"pos pos29\">RES\n      Jul 1, 2022\n      NaN\n      2025\n      177cm\n      72kg\n      €866K\n      43.0\n      NaN\n      10\n    \n    \n      2\n      56~61\n      59.155841\n      246789\n      A. Smith\n      23\n      https://cdn.sofifa.net/players/246/789/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      61\n      66\n      ...\n      <span class=\"pos pos13\">RCM\n      Jul 1, 2021\n      NaN\n      2023\n      185cm\n      73kg\n      €913K\n      8.0\n      NaN\n      5\n    \n    \n      3\n      56~61\n      59.155841\n      242056\n      C. Timmins\n      22\n      https://cdn.sofifa.net/players/242/056/23_60.png\n      Australia\n      https://cdn.sofifa.net/flags/au.png\n      61\n      68\n      ...\n      <span class=\"pos pos28\">SUB\n      Aug 4, 2022\n      NaN\n      2023\n      182cm\n      72kg\n      €979K\n      15.0\n      NaN\n      7\n    \n    \n      4\n      56~61\n      59.155841\n      262363\n      22 M. Anderson\n      20\n      https://cdn.sofifa.net/players/262/363/22_60.png\n      Scotland\n      https://cdn.sofifa.net/flags/gb-sct.png\n      61\n      71\n      ...\n      <span class=\"pos pos13\">RCM\n      Nov 5, 2019\n      NaN\n      2023\n      167cm\n      70kg\n      €1.4M\n      24.0\n      NaN\n      10\n    \n  \n\n5 rows × 32 columns"
  },
  {
    "objectID": "posts/DV_8(1024).html#flights-data",
    "href": "posts/DV_8(1024).html#flights-data",
    "title": "DV 8주차",
    "section": "flights data",
    "text": "flights data\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 58492 entries, 0 to 58491\nData columns (total 14 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   MONTH      58492 non-null  int64  \n 1   DAY        58492 non-null  int64  \n 2   WEEKDAY    58492 non-null  int64  \n 3   AIRLINE    58492 non-null  object \n 4   ORG_AIR    58492 non-null  object \n 5   DEST_AIR   58492 non-null  object \n 6   SCHED_DEP  58492 non-null  int64  \n 7   DEP_DELAY  57659 non-null  float64\n 8   AIR_TIME   57474 non-null  float64\n 9   DIST       58492 non-null  int64  \n 10  SCHED_ARR  58492 non-null  int64  \n 11  ARR_DELAY  57474 non-null  float64\n 12  DIVERTED   58492 non-null  int64  \n 13  CANCELLED  58492 non-null  int64  \ndtypes: float64(3), int64(8), object(3)\nmemory usage: 6.2+ MB\n\n\n\ndf[['ARR_DELAY','CANCELLED']]\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n      CANCELLED\n    \n  \n  \n    \n      0\n      65.0\n      0\n    \n    \n      1\n      -13.0\n      0\n    \n    \n      2\n      35.0\n      0\n    \n    \n      3\n      -7.0\n      0\n    \n    \n      4\n      39.0\n      0\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      58487\n      -19.0\n      0\n    \n    \n      58488\n      4.0\n      0\n    \n    \n      58489\n      -5.0\n      0\n    \n    \n      58490\n      34.0\n      0\n    \n    \n      58491\n      -1.0\n      0\n    \n  \n\n58492 rows × 2 columns"
  },
  {
    "objectID": "posts/DV_8(1024).html#get_groups",
    "href": "posts/DV_8(1024).html#get_groups",
    "title": "DV 8주차",
    "section": "get_groups",
    "text": "get_groups\n- groupby\n\n데이터프레임을 여러개의 서브데이터프레임으로 나누는 기준\n단독으로 쓸 이유는 별로 없다. \\(\\to\\) 그룹을 나누고 그룹을 어떠한 “변수”에 “연산”을 하기 위함이다.\n\n\ndf['AIRLINE'].unique()\n\narray(['WN', 'UA', 'MQ', 'AA', 'F9', 'EV', 'OO', 'NK', 'US', 'AS', 'DL',\n       'VX', 'B6', 'HA'], dtype=object)\n\n\n\ndf.groupby(by='AIRLINE')\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f58e3f69090>\n\n\n\n지금 이것은 항공사별로 데이터프레임이 나누어진 상태\n\n- sub dataframe으로 나누어져 있는지 확인\n\ngrouped = df.groupby(by='AIRLINE')\ngrouped.groups.keys()\n\ndict_keys(['AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US', 'VX', 'WN'])\n\n\n\ngrouped.get_group('AS')\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      38\n      1\n      1\n      4\n      AS\n      PHX\n      SEA\n      1505\n      -2.0\n      155.0\n      1107\n      1702\n      -3.0\n      0\n      0\n    \n    \n      198\n      1\n      2\n      5\n      AS\n      LAX\n      SEA\n      2110\n      5.0\n      145.0\n      954\n      2352\n      8.0\n      0\n      0\n    \n    \n      241\n      1\n      2\n      5\n      AS\n      LAS\n      PDX\n      650\n      -5.0\n      117.0\n      763\n      906\n      -3.0\n      0\n      0\n    \n    \n      277\n      1\n      2\n      5\n      AS\n      ORD\n      ANC\n      935\n      -1.0\n      402.0\n      2846\n      1339\n      -6.0\n      0\n      0\n    \n    \n      397\n      1\n      3\n      6\n      AS\n      LAS\n      SEA\n      1300\n      48.0\n      137.0\n      867\n      1535\n      47.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58305\n      12\n      30\n      3\n      AS\n      LAX\n      SEA\n      1325\n      -2.0\n      134.0\n      954\n      1608\n      -7.0\n      0\n      0\n    \n    \n      58355\n      12\n      31\n      4\n      AS\n      PHX\n      SEA\n      1200\n      -5.0\n      145.0\n      1107\n      1407\n      -24.0\n      0\n      0\n    \n    \n      58404\n      12\n      31\n      4\n      AS\n      SFO\n      SLC\n      2110\n      -2.0\n      80.0\n      599\n      2358\n      -4.0\n      0\n      0\n    \n    \n      58407\n      12\n      31\n      4\n      AS\n      SFO\n      PDX\n      645\n      -2.0\n      81.0\n      550\n      832\n      -3.0\n      0\n      0\n    \n    \n      58428\n      12\n      31\n      4\n      AS\n      LAX\n      SEA\n      1420\n      -8.0\n      127.0\n      954\n      1709\n      -25.0\n      0\n      0\n    \n  \n\n768 rows × 14 columns\n\n\n\n\n#collapse_output\nfor key in grouped.groups.keys():\n    display(grouped.get_group(key))\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      3\n      1\n      1\n      4\n      AA\n      DFW\n      DCA\n      1555\n      7.0\n      126.0\n      1192\n      1935\n      -7.0\n      0\n      0\n    \n    \n      6\n      1\n      1\n      4\n      AA\n      DFW\n      MSY\n      1250\n      84.0\n      64.0\n      447\n      1410\n      83.0\n      0\n      0\n    \n    \n      8\n      1\n      1\n      4\n      AA\n      ORD\n      STL\n      1845\n      -5.0\n      44.0\n      258\n      1950\n      -5.0\n      0\n      0\n    \n    \n      15\n      1\n      1\n      4\n      AA\n      DEN\n      DFW\n      1445\n      -6.0\n      93.0\n      641\n      1745\n      4.0\n      0\n      0\n    \n    \n      26\n      1\n      1\n      4\n      AA\n      LAX\n      AUS\n      1430\n      33.0\n      157.0\n      1242\n      1925\n      41.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58470\n      12\n      31\n      4\n      AA\n      DFW\n      FAT\n      1020\n      -3.0\n      196.0\n      1313\n      1156\n      -2.0\n      0\n      0\n    \n    \n      58475\n      12\n      31\n      4\n      AA\n      IAH\n      CLT\n      710\n      1.0\n      113.0\n      912\n      1037\n      -12.0\n      0\n      0\n    \n    \n      58476\n      12\n      31\n      4\n      AA\n      DFW\n      TPA\n      1020\n      -3.0\n      121.0\n      929\n      1340\n      -6.0\n      0\n      0\n    \n    \n      58479\n      12\n      31\n      4\n      AA\n      DFW\n      ELP\n      1200\n      3.0\n      94.0\n      551\n      1250\n      13.0\n      0\n      0\n    \n    \n      58487\n      12\n      31\n      4\n      AA\n      SFO\n      DFW\n      515\n      5.0\n      166.0\n      1464\n      1045\n      -19.0\n      0\n      0\n    \n  \n\n8900 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      38\n      1\n      1\n      4\n      AS\n      PHX\n      SEA\n      1505\n      -2.0\n      155.0\n      1107\n      1702\n      -3.0\n      0\n      0\n    \n    \n      198\n      1\n      2\n      5\n      AS\n      LAX\n      SEA\n      2110\n      5.0\n      145.0\n      954\n      2352\n      8.0\n      0\n      0\n    \n    \n      241\n      1\n      2\n      5\n      AS\n      LAS\n      PDX\n      650\n      -5.0\n      117.0\n      763\n      906\n      -3.0\n      0\n      0\n    \n    \n      277\n      1\n      2\n      5\n      AS\n      ORD\n      ANC\n      935\n      -1.0\n      402.0\n      2846\n      1339\n      -6.0\n      0\n      0\n    \n    \n      397\n      1\n      3\n      6\n      AS\n      LAS\n      SEA\n      1300\n      48.0\n      137.0\n      867\n      1535\n      47.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58305\n      12\n      30\n      3\n      AS\n      LAX\n      SEA\n      1325\n      -2.0\n      134.0\n      954\n      1608\n      -7.0\n      0\n      0\n    \n    \n      58355\n      12\n      31\n      4\n      AS\n      PHX\n      SEA\n      1200\n      -5.0\n      145.0\n      1107\n      1407\n      -24.0\n      0\n      0\n    \n    \n      58404\n      12\n      31\n      4\n      AS\n      SFO\n      SLC\n      2110\n      -2.0\n      80.0\n      599\n      2358\n      -4.0\n      0\n      0\n    \n    \n      58407\n      12\n      31\n      4\n      AS\n      SFO\n      PDX\n      645\n      -2.0\n      81.0\n      550\n      832\n      -3.0\n      0\n      0\n    \n    \n      58428\n      12\n      31\n      4\n      AS\n      LAX\n      SEA\n      1420\n      -8.0\n      127.0\n      954\n      1709\n      -25.0\n      0\n      0\n    \n  \n\n768 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      123\n      1\n      1\n      4\n      B6\n      LAS\n      BOS\n      1230\n      0.0\n      246.0\n      2381\n      2026\n      -27.0\n      0\n      0\n    \n    \n      127\n      1\n      1\n      4\n      B6\n      LAS\n      BOS\n      2359\n      68.0\n      247.0\n      2381\n      749\n      46.0\n      0\n      0\n    \n    \n      239\n      1\n      2\n      5\n      B6\n      ORD\n      BOS\n      540\n      -8.0\n      96.0\n      867\n      856\n      -22.0\n      0\n      0\n    \n    \n      333\n      1\n      3\n      6\n      B6\n      LAX\n      FLL\n      2237\n      32.0\n      270.0\n      2342\n      619\n      42.0\n      0\n      0\n    \n    \n      548\n      1\n      4\n      7\n      B6\n      SFO\n      FLL\n      2307\n      -4.0\n      298.0\n      2583\n      724\n      -1.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58262\n      12\n      30\n      3\n      B6\n      SFO\n      LGB\n      1921\n      -6.0\n      57.0\n      354\n      2038\n      -14.0\n      0\n      0\n    \n    \n      58301\n      12\n      30\n      3\n      B6\n      LAX\n      JFK\n      630\n      4.0\n      285.0\n      2475\n      1445\n      -6.0\n      0\n      0\n    \n    \n      58425\n      12\n      31\n      4\n      B6\n      ORD\n      SJU\n      700\n      239.0\n      250.0\n      2072\n      1335\n      239.0\n      0\n      0\n    \n    \n      58477\n      12\n      31\n      4\n      B6\n      DFW\n      BOS\n      1145\n      12.0\n      161.0\n      1562\n      1608\n      -14.0\n      0\n      0\n    \n    \n      58483\n      12\n      31\n      4\n      B6\n      PHX\n      BOS\n      2236\n      -12.0\n      231.0\n      2300\n      515\n      -45.0\n      0\n      0\n    \n  \n\n543 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      53\n      1\n      1\n      4\n      DL\n      LAS\n      MSP\n      713\n      -5.0\n      156.0\n      1299\n      1220\n      -18.0\n      0\n      0\n    \n    \n      57\n      1\n      1\n      4\n      DL\n      MSP\n      RSW\n      700\n      -1.0\n      169.0\n      1416\n      1130\n      -20.0\n      0\n      0\n    \n    \n      77\n      1\n      1\n      4\n      DL\n      LAX\n      ATL\n      1130\n      24.0\n      217.0\n      1947\n      1840\n      16.0\n      0\n      0\n    \n    \n      79\n      1\n      1\n      4\n      DL\n      LAX\n      CMH\n      2146\n      -3.0\n      223.0\n      1995\n      459\n      -13.0\n      0\n      0\n    \n    \n      85\n      1\n      1\n      4\n      DL\n      ATL\n      OKC\n      2059\n      -4.0\n      116.0\n      761\n      2227\n      -12.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58440\n      12\n      31\n      4\n      DL\n      ATL\n      CVG\n      1611\n      -4.0\n      61.0\n      373\n      1736\n      -6.0\n      0\n      0\n    \n    \n      58448\n      12\n      31\n      4\n      DL\n      ATL\n      SRQ\n      1610\n      0.0\n      61.0\n      444\n      1740\n      -13.0\n      0\n      0\n    \n    \n      58464\n      12\n      31\n      4\n      DL\n      LAX\n      SFO\n      700\n      108.0\n      54.0\n      337\n      825\n      105.0\n      0\n      0\n    \n    \n      58467\n      12\n      31\n      4\n      DL\n      ATL\n      IND\n      1235\n      -3.0\n      63.0\n      432\n      1407\n      -13.0\n      0\n      0\n    \n    \n      58485\n      12\n      31\n      4\n      DL\n      ATL\n      CMH\n      2206\n      2.0\n      64.0\n      447\n      2338\n      -8.0\n      0\n      0\n    \n  \n\n10601 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      11\n      1\n      1\n      4\n      EV\n      ORD\n      JAN\n      1155\n      6.0\n      113.0\n      677\n      1403\n      5.0\n      0\n      0\n    \n    \n      13\n      1\n      1\n      4\n      EV\n      ORD\n      CMH\n      1010\n      -2.0\n      46.0\n      296\n      1228\n      -9.0\n      0\n      0\n    \n    \n      29\n      1\n      1\n      4\n      EV\n      ORD\n      IND\n      1025\n      -6.0\n      29.0\n      177\n      1228\n      -19.0\n      0\n      0\n    \n    \n      40\n      1\n      1\n      4\n      EV\n      IAH\n      CLE\n      1038\n      -3.0\n      126.0\n      1091\n      1425\n      -18.0\n      0\n      0\n    \n    \n      69\n      1\n      1\n      4\n      EV\n      ATL\n      RAP\n      1930\n      -5.0\n      181.0\n      1230\n      2104\n      -15.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58445\n      12\n      31\n      4\n      EV\n      DFW\n      TXK\n      850\n      -5.0\n      30.0\n      181\n      948\n      -17.0\n      0\n      0\n    \n    \n      58452\n      12\n      31\n      4\n      EV\n      DFW\n      SHV\n      1650\n      -4.0\n      32.0\n      190\n      1746\n      -12.0\n      0\n      0\n    \n    \n      58459\n      12\n      31\n      4\n      EV\n      MSP\n      ORD\n      1435\n      18.0\n      61.0\n      334\n      1609\n      3.0\n      0\n      0\n    \n    \n      58463\n      12\n      31\n      4\n      EV\n      ORD\n      MSN\n      1220\n      18.0\n      32.0\n      108\n      1319\n      27.0\n      0\n      0\n    \n    \n      58486\n      12\n      31\n      4\n      EV\n      DFW\n      LFT\n      850\n      21.0\n      52.0\n      351\n      1012\n      14.0\n      0\n      0\n    \n  \n\n5858 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      7\n      1\n      1\n      4\n      F9\n      SFO\n      PHX\n      1020\n      -7.0\n      91.0\n      651\n      1315\n      -6.0\n      0\n      0\n    \n    \n      93\n      1\n      1\n      4\n      F9\n      ATL\n      DEN\n      859\n      16.0\n      181.0\n      1199\n      1026\n      10.0\n      0\n      0\n    \n    \n      209\n      1\n      2\n      5\n      F9\n      MSP\n      DEN\n      1025\n      -6.0\n      97.0\n      680\n      1134\n      -13.0\n      0\n      0\n    \n    \n      232\n      1\n      2\n      5\n      F9\n      DEN\n      PHX\n      2040\n      -7.0\n      83.0\n      602\n      2228\n      -18.0\n      0\n      0\n    \n    \n      247\n      1\n      2\n      5\n      F9\n      ORD\n      ATL\n      730\n      10.0\n      86.0\n      606\n      1020\n      23.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58288\n      12\n      30\n      3\n      F9\n      DEN\n      ORD\n      625\n      -4.0\n      136.0\n      888\n      1000\n      14.0\n      0\n      0\n    \n    \n      58331\n      12\n      30\n      3\n      F9\n      ORD\n      PHX\n      825\n      18.0\n      207.0\n      1440\n      1127\n      14.0\n      0\n      0\n    \n    \n      58447\n      12\n      31\n      4\n      F9\n      DEN\n      LAS\n      1245\n      13.0\n      94.0\n      628\n      1340\n      13.0\n      0\n      0\n    \n    \n      58449\n      12\n      31\n      4\n      F9\n      DEN\n      MCO\n      645\n      11.0\n      169.0\n      1546\n      1224\n      -11.0\n      0\n      0\n    \n    \n      58488\n      12\n      31\n      4\n      F9\n      LAS\n      SFO\n      1910\n      13.0\n      71.0\n      414\n      2050\n      4.0\n      0\n      0\n    \n  \n\n1317 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      582\n      1\n      4\n      7\n      HA\n      LAX\n      OGG\n      1115\n      -11.0\n      310.0\n      2486\n      1500\n      -27.0\n      0\n      0\n    \n    \n      712\n      1\n      5\n      1\n      HA\n      LAS\n      HNL\n      900\n      -5.0\n      357.0\n      2762\n      1315\n      5.0\n      0\n      0\n    \n    \n      878\n      1\n      6\n      2\n      HA\n      PHX\n      HNL\n      800\n      1.0\n      374.0\n      2917\n      1140\n      3.0\n      0\n      0\n    \n    \n      1053\n      1\n      7\n      3\n      HA\n      LAX\n      HNL\n      1705\n      0.0\n      332.0\n      2556\n      2055\n      -2.0\n      0\n      0\n    \n    \n      1269\n      1\n      8\n      4\n      HA\n      LAX\n      HNL\n      1000\n      -1.0\n      335.0\n      2556\n      1350\n      0.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      55883\n      12\n      16\n      3\n      HA\n      LAX\n      HNL\n      835\n      1.0\n      314.0\n      2556\n      1235\n      -18.0\n      0\n      0\n    \n    \n      56174\n      12\n      18\n      5\n      HA\n      LAX\n      HNL\n      835\n      -5.0\n      342.0\n      2556\n      1235\n      -4.0\n      0\n      0\n    \n    \n      56350\n      12\n      19\n      6\n      HA\n      PHX\n      HNL\n      800\n      -5.0\n      363.0\n      2917\n      1155\n      -34.0\n      0\n      0\n    \n    \n      56816\n      12\n      21\n      1\n      HA\n      LAX\n      LIH\n      740\n      20.0\n      303.0\n      2615\n      1145\n      -11.0\n      0\n      0\n    \n    \n      58391\n      12\n      31\n      4\n      HA\n      LAX\n      HNL\n      1000\n      0.0\n      324.0\n      2556\n      1350\n      -9.0\n      0\n      0\n    \n  \n\n112 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      2\n      1\n      1\n      4\n      MQ\n      DFW\n      VPS\n      1305\n      36.0\n      85.0\n      641\n      1453\n      35.0\n      0\n      0\n    \n    \n      10\n      1\n      1\n      4\n      MQ\n      DFW\n      DRO\n      1335\n      28.0\n      104.0\n      674\n      1438\n      28.0\n      0\n      0\n    \n    \n      18\n      1\n      1\n      4\n      MQ\n      ORD\n      DAY\n      2220\n      19.0\n      37.0\n      240\n      23\n      20.0\n      0\n      0\n    \n    \n      24\n      1\n      1\n      4\n      MQ\n      DFW\n      BTR\n      730\n      NaN\n      NaN\n      383\n      853\n      NaN\n      0\n      1\n    \n    \n      50\n      1\n      1\n      4\n      MQ\n      ORD\n      CID\n      1135\n      -7.0\n      37.0\n      196\n      1238\n      -15.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58415\n      12\n      31\n      4\n      MQ\n      ORD\n      FWA\n      845\n      -2.0\n      37.0\n      157\n      1045\n      -4.0\n      0\n      0\n    \n    \n      58426\n      12\n      31\n      4\n      MQ\n      DFW\n      FAR\n      1154\n      4.0\n      124.0\n      968\n      1437\n      -13.0\n      0\n      0\n    \n    \n      58468\n      12\n      31\n      4\n      MQ\n      DFW\n      OKC\n      1720\n      -3.0\n      31.0\n      175\n      1819\n      -10.0\n      0\n      0\n    \n    \n      58474\n      12\n      31\n      4\n      MQ\n      ORD\n      FNT\n      829\n      4.0\n      40.0\n      223\n      1034\n      -4.0\n      0\n      0\n    \n    \n      58484\n      12\n      31\n      4\n      MQ\n      ORD\n      DSM\n      1333\n      1.0\n      57.0\n      299\n      1455\n      -7.0\n      0\n      0\n    \n  \n\n3471 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      17\n      1\n      1\n      4\n      NK\n      DEN\n      DTW\n      1952\n      37.0\n      124.0\n      1123\n      31\n      54.0\n      0\n      0\n    \n    \n      74\n      1\n      1\n      4\n      NK\n      PHX\n      DFW\n      159\n      -1.0\n      103.0\n      868\n      502\n      1.0\n      0\n      0\n    \n    \n      95\n      1\n      1\n      4\n      NK\n      LAS\n      OAK\n      1115\n      22.0\n      62.0\n      407\n      1246\n      10.0\n      0\n      0\n    \n    \n      109\n      1\n      1\n      4\n      NK\n      MSP\n      ORD\n      616\n      2.0\n      49.0\n      334\n      745\n      -19.0\n      0\n      0\n    \n    \n      166\n      1\n      2\n      5\n      NK\n      LAS\n      PDX\n      1535\n      -8.0\n      123.0\n      763\n      1754\n      -4.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58160\n      12\n      29\n      2\n      NK\n      MSP\n      MCO\n      740\n      0.0\n      171.0\n      1310\n      1158\n      33.0\n      0\n      0\n    \n    \n      58197\n      12\n      30\n      3\n      NK\n      IAH\n      ORD\n      755\n      -8.0\n      136.0\n      925\n      1030\n      -2.0\n      0\n      0\n    \n    \n      58437\n      12\n      31\n      4\n      NK\n      ORD\n      DFW\n      1952\n      15.0\n      135.0\n      802\n      2225\n      23.0\n      0\n      0\n    \n    \n      58461\n      12\n      31\n      4\n      NK\n      ORD\n      LGA\n      1801\n      -5.0\n      84.0\n      733\n      2109\n      -26.0\n      0\n      0\n    \n    \n      58469\n      12\n      31\n      4\n      NK\n      LAS\n      MSY\n      1950\n      124.0\n      163.0\n      1500\n      112\n      101.0\n      0\n      0\n    \n  \n\n1516 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      12\n      1\n      1\n      4\n      OO\n      ORD\n      MSP\n      1510\n      2.0\n      65.0\n      334\n      1646\n      4.0\n      0\n      0\n    \n    \n      16\n      1\n      1\n      4\n      OO\n      DEN\n      SGU\n      1105\n      21.0\n      66.0\n      517\n      1249\n      20.0\n      0\n      0\n    \n    \n      22\n      1\n      1\n      4\n      OO\n      LAS\n      LAX\n      1544\n      -4.0\n      39.0\n      236\n      1655\n      -12.0\n      0\n      0\n    \n    \n      25\n      1\n      1\n      4\n      OO\n      ORD\n      SPI\n      2110\n      -4.0\n      31.0\n      174\n      2205\n      5.0\n      0\n      0\n    \n    \n      27\n      1\n      1\n      4\n      OO\n      IAH\n      JAC\n      1104\n      -1.0\n      161.0\n      1265\n      1316\n      -1.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58451\n      12\n      31\n      4\n      OO\n      ATL\n      FWA\n      1905\n      -3.0\n      72.0\n      508\n      2051\n      -14.0\n      0\n      0\n    \n    \n      58480\n      12\n      31\n      4\n      OO\n      MSP\n      BIS\n      1310\n      -2.0\n      65.0\n      386\n      1449\n      -9.0\n      0\n      0\n    \n    \n      58482\n      12\n      31\n      4\n      OO\n      DEN\n      CPR\n      1850\n      -2.0\n      38.0\n      230\n      1956\n      1.0\n      0\n      0\n    \n    \n      58489\n      12\n      31\n      4\n      OO\n      SFO\n      SBA\n      1846\n      -6.0\n      46.0\n      262\n      1956\n      -5.0\n      0\n      0\n    \n    \n      58491\n      12\n      31\n      4\n      OO\n      SFO\n      BOI\n      859\n      5.0\n      73.0\n      522\n      1146\n      -1.0\n      0\n      0\n    \n  \n\n6588 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      1\n      1\n      1\n      4\n      UA\n      DEN\n      IAD\n      823\n      7.0\n      154.0\n      1452\n      1333\n      -13.0\n      0\n      0\n    \n    \n      5\n      1\n      1\n      4\n      UA\n      IAH\n      SAN\n      1450\n      1.0\n      178.0\n      1303\n      1620\n      -14.0\n      0\n      0\n    \n    \n      9\n      1\n      1\n      4\n      UA\n      IAH\n      SJC\n      925\n      3.0\n      215.0\n      1608\n      1136\n      -14.0\n      0\n      0\n    \n    \n      14\n      1\n      1\n      4\n      UA\n      IAH\n      IND\n      1426\n      -1.0\n      102.0\n      844\n      1742\n      -20.0\n      0\n      0\n    \n    \n      21\n      1\n      1\n      4\n      UA\n      ORD\n      CLE\n      2102\n      48.0\n      47.0\n      315\n      2320\n      41.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58422\n      12\n      31\n      4\n      UA\n      DEN\n      SAN\n      1535\n      0.0\n      124.0\n      853\n      1704\n      -13.0\n      0\n      0\n    \n    \n      58432\n      12\n      31\n      4\n      UA\n      ORD\n      SAN\n      1915\n      7.0\n      238.0\n      1723\n      2143\n      -3.0\n      0\n      0\n    \n    \n      58457\n      12\n      31\n      4\n      UA\n      ORD\n      LAX\n      659\n      -1.0\n      241.0\n      1744\n      946\n      0.0\n      0\n      0\n    \n    \n      58460\n      12\n      31\n      4\n      UA\n      SFO\n      PHL\n      2235\n      -6.0\n      265.0\n      2521\n      700\n      -42.0\n      0\n      0\n    \n    \n      58481\n      12\n      31\n      4\n      UA\n      IAH\n      LAX\n      1433\n      1.0\n      197.0\n      1379\n      1625\n      -13.0\n      0\n      0\n    \n  \n\n7792 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      31\n      1\n      1\n      4\n      US\n      PHX\n      DEN\n      1810\n      29.0\n      94.0\n      602\n      1954\n      49.0\n      0\n      0\n    \n    \n      35\n      1\n      1\n      4\n      US\n      ORD\n      PHL\n      1600\n      -2.0\n      80.0\n      678\n      1857\n      -9.0\n      0\n      0\n    \n    \n      49\n      1\n      1\n      4\n      US\n      IAH\n      PHX\n      1445\n      -1.0\n      147.0\n      1009\n      1638\n      -7.0\n      0\n      0\n    \n    \n      96\n      1\n      1\n      4\n      US\n      ATL\n      PHL\n      1445\n      -4.0\n      90.0\n      666\n      1644\n      -11.0\n      0\n      0\n    \n    \n      104\n      1\n      1\n      4\n      US\n      MSP\n      PHX\n      730\n      -3.0\n      174.0\n      1276\n      1010\n      -20.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      31514\n      6\n      30\n      2\n      US\n      DEN\n      PHL\n      705\n      -4.0\n      188.0\n      1558\n      1240\n      1.0\n      0\n      0\n    \n    \n      31523\n      6\n      30\n      2\n      US\n      PHX\n      DEN\n      1451\n      6.0\n      85.0\n      602\n      1738\n      7.0\n      0\n      0\n    \n    \n      31535\n      6\n      30\n      2\n      US\n      PHX\n      AUS\n      840\n      -3.0\n      116.0\n      872\n      1304\n      -11.0\n      0\n      0\n    \n    \n      31561\n      6\n      30\n      2\n      US\n      ORD\n      PHX\n      710\n      -5.0\n      170.0\n      1440\n      901\n      -50.0\n      0\n      0\n    \n    \n      31582\n      6\n      30\n      2\n      US\n      PHX\n      OGG\n      800\n      -4.0\n      356.0\n      2845\n      1127\n      -13.0\n      0\n      0\n    \n  \n\n1615 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      56\n      1\n      1\n      4\n      VX\n      LAS\n      SFO\n      900\n      23.0\n      65.0\n      414\n      1035\n      11.0\n      0\n      0\n    \n    \n      227\n      1\n      2\n      5\n      VX\n      SFO\n      LAS\n      1220\n      -5.0\n      68.0\n      414\n      1350\n      -5.0\n      0\n      0\n    \n    \n      243\n      1\n      2\n      5\n      VX\n      SFO\n      SEA\n      700\n      -4.0\n      104.0\n      679\n      905\n      -1.0\n      0\n      0\n    \n    \n      417\n      1\n      3\n      6\n      VX\n      SFO\n      LAS\n      900\n      -2.0\n      62.0\n      414\n      1030\n      -11.0\n      0\n      0\n    \n    \n      432\n      1\n      3\n      6\n      VX\n      SFO\n      SEA\n      2035\n      -2.0\n      106.0\n      679\n      2240\n      -2.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58332\n      12\n      30\n      3\n      VX\n      SFO\n      LAS\n      1950\n      -3.0\n      58.0\n      414\n      2120\n      -4.0\n      0\n      0\n    \n    \n      58383\n      12\n      31\n      4\n      VX\n      SFO\n      PSP\n      1630\n      -7.0\n      65.0\n      421\n      1755\n      -12.0\n      0\n      0\n    \n    \n      58400\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      1125\n      -4.0\n      54.0\n      337\n      1245\n      -10.0\n      0\n      0\n    \n    \n      58471\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      700\n      6.0\n      51.0\n      337\n      820\n      3.0\n      0\n      0\n    \n    \n      58478\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      1530\n      29.0\n      52.0\n      337\n      1650\n      22.0\n      0\n      0\n    \n  \n\n993 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      0\n      1\n      1\n      4\n      WN\n      LAX\n      SLC\n      1625\n      58.0\n      94.0\n      590\n      1905\n      65.0\n      0\n      0\n    \n    \n      4\n      1\n      1\n      4\n      WN\n      LAX\n      MCI\n      1720\n      48.0\n      166.0\n      1363\n      2225\n      39.0\n      0\n      0\n    \n    \n      19\n      1\n      1\n      4\n      WN\n      PHX\n      LAX\n      1640\n      51.0\n      58.0\n      370\n      1700\n      59.0\n      0\n      0\n    \n    \n      20\n      1\n      1\n      4\n      WN\n      ATL\n      BWI\n      1115\n      1.0\n      76.0\n      577\n      1305\n      -15.0\n      0\n      0\n    \n    \n      23\n      1\n      1\n      4\n      WN\n      ATL\n      HOU\n      1555\n      30.0\n      113.0\n      696\n      1720\n      18.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58455\n      12\n      31\n      4\n      WN\n      LAX\n      SMF\n      1420\n      -2.0\n      64.0\n      373\n      1540\n      -7.0\n      0\n      0\n    \n    \n      58458\n      12\n      31\n      4\n      WN\n      LAS\n      SFO\n      1825\n      25.0\n      67.0\n      414\n      1955\n      17.0\n      0\n      0\n    \n    \n      58472\n      12\n      31\n      4\n      WN\n      PHX\n      HOU\n      845\n      5.0\n      119.0\n      1020\n      1210\n      7.0\n      0\n      0\n    \n    \n      58473\n      12\n      31\n      4\n      WN\n      DEN\n      PDX\n      1205\n      4.0\n      130.0\n      991\n      1400\n      -13.0\n      0\n      0\n    \n    \n      58490\n      12\n      31\n      4\n      WN\n      MSP\n      ATL\n      525\n      39.0\n      124.0\n      907\n      855\n      34.0\n      0\n      0\n    \n  \n\n8418 rows × 14 columns"
  },
  {
    "objectID": "posts/DV_8(1024).html#범주형-변수를-기준으로-groupby---agg",
    "href": "posts/DV_8(1024).html#범주형-변수를-기준으로-groupby---agg",
    "title": "DV 8주차",
    "section": "범주형 변수를 기준으로 groupby -> agg",
    "text": "범주형 변수를 기준으로 groupby -> agg\n\nEX1: [AIRLINE] \\(\\to\\) {ARR_DELAY:mean}\n- 방법1: groupby() \\(\\to\\) .agg({colname: function})\n\ndf.groupby(by=\"AIRLINE\")\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f5900e60850>\n\n\n\ndf.AIRLINE.unique().__len__()\n\n14\n\n\n(예시1)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':np.mean})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      5.542661\n    \n    \n      AS\n      -0.833333\n    \n    \n      B6\n      8.692593\n    \n    \n      DL\n      0.339691\n    \n    \n      EV\n      7.034580\n    \n    \n      F9\n      13.630651\n    \n    \n      HA\n      4.972973\n    \n    \n      MQ\n      6.860591\n    \n    \n      NK\n      18.436070\n    \n    \n      OO\n      7.593463\n    \n    \n      UA\n      7.765755\n    \n    \n      US\n      1.681105\n    \n    \n      VX\n      5.348884\n    \n    \n      WN\n      6.397353\n    \n  \n\n\n\n\n(예시2)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':mean})\n\n# numpy로 하지 않고 mean만을 해도 된다\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      5.542661\n    \n    \n      AS\n      -0.833333\n    \n    \n      B6\n      8.692593\n    \n    \n      DL\n      0.339691\n    \n    \n      EV\n      7.034580\n    \n    \n      F9\n      13.630651\n    \n    \n      HA\n      4.972973\n    \n    \n      MQ\n      6.860591\n    \n    \n      NK\n      18.436070\n    \n    \n      OO\n      7.593463\n    \n    \n      UA\n      7.765755\n    \n    \n      US\n      1.681105\n    \n    \n      VX\n      5.348884\n    \n    \n      WN\n      6.397353\n    \n  \n\n\n\n\n(실습)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':std})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      43.323160\n    \n    \n      AS\n      31.168354\n    \n    \n      B6\n      40.221718\n    \n    \n      DL\n      32.299471\n    \n    \n      EV\n      36.682336\n    \n    \n      F9\n      53.030912\n    \n    \n      HA\n      37.528283\n    \n    \n      MQ\n      36.324657\n    \n    \n      NK\n      48.727259\n    \n    \n      OO\n      35.331344\n    \n    \n      UA\n      46.405935\n    \n    \n      US\n      27.030227\n    \n    \n      VX\n      33.747675\n    \n    \n      WN\n      32.610666\n    \n  \n\n\n\n\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':max})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      858.0\n    \n    \n      AS\n      344.0\n    \n    \n      B6\n      331.0\n    \n    \n      DL\n      741.0\n    \n    \n      EV\n      669.0\n    \n    \n      F9\n      839.0\n    \n    \n      HA\n      298.0\n    \n    \n      MQ\n      357.0\n    \n    \n      NK\n      474.0\n    \n    \n      OO\n      724.0\n    \n    \n      UA\n      1185.0\n    \n    \n      US\n      431.0\n    \n    \n      VX\n      236.0\n    \n    \n      WN\n      493.0\n    \n  \n\n\n\n\n- 방법2: groupby() \\(\\to\\) key로 column 선택 \\(\\to\\) .agg(function) or .function()\n(예시1)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].agg(np.mean)\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n(예시2)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].agg(mean)\n# mean에 \" \" 들어가도 된다\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n(예시3)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].mean()\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n\n\nEX2: [AIRLINE, WEEKDAY] \\(\\to\\) {CANCELLED:mean}\n- 방법1\n(예시1)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY']).agg({'CANCELLED':np.sum})\n# 몇요일에 항공사별로 취소가 많이 되었는지 (sum)\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n(예시2)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY']).agg({'CANCELLED':sum})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n- 방법2\n(예시1)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[\"CANCELLED\"].agg(np.sum)\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n(예시2)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[\"CANCELLED\"].agg(\"sum\")\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n(예시3)\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[\"CANCELLED\"].sum()\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n\ndf.groupby(by=['AIRLINE', 'WEEKDAY'])[[\"CANCELLED\"]].sum()\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n\n\nEX3: [AIRLINE,WEEKDAY] \\(\\to\\) {CANCELLED:sum,mean}, {DIVERTED: sum,mean}\n- 방법1\n(예시1)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({\"CANCELLED\":[np.sum,np.mean],\"DIVERTED\":[np.sum,np.mean]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시2)\n\nnp.sum([1,2,3])\n\n6\n\n\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({\"CANCELLED\":[sum,np.mean],\"DIVERTED\":[sum,np.mean]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n- 방법2\n(예시1)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])[[\"CANCELLED\",\"DIVERTED\"]]\\\n.agg([np.sum,np.mean])\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시2)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])[[\"CANCELLED\",\"DIVERTED\"]]\\\n.agg([\"sum\",\"mean\"])\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시3) - 사용불가\n\n\nEX4: [AIRLINE,WEEKDAY] \\(\\to\\) {CANCELLED:sum,mean,count}, {AIR_TIME: mean,var}\n방법2 불가\n- 방법1\n(예시1)\n\ndf.groupby(['AIRLINE','WEEKDAY'])\\\n.agg({'CANCELLED':[np.sum,np.mean,len], 'AIR_TIME':[np.mean,np.var]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      len\n      mean\n      var\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns\n\n\n\n(예시2)\n\ndf.groupby(['AIRLINE','WEEKDAY'])\\\n.agg({'CANCELLED':[sum,mean,size], 'AIR_TIME':[mean\",\"var\"]})\n# 그 전에서는 큰 따옴표 없이도 다 됬는데, 여기서는 size 정의가 안 되어 있다고 나온다. 그래서 큰 따옴표를 해줘야 함!\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      size\n      mean\n      var\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns\n\n\n\n(사용자정의함수)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({'CANCELLED':[np.sum,np.mean,len],\n      'AIR_TIME':[np.mean,lambda x: np.std(x,ddof=1)**2]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      len\n      mean\n      <lambda_0>\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns"
  },
  {
    "objectID": "posts/DV_8(1024).html#연속형-변수를-기준으로-groupby---agg",
    "href": "posts/DV_8(1024).html#연속형-변수를-기준으로-groupby---agg",
    "title": "DV 8주차",
    "section": "연속형 변수를 기준으로 groupby -> agg",
    "text": "연속형 변수를 기준으로 groupby -> agg\n\ndf.T\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      ...\n      58482\n      58483\n      58484\n      58485\n      58486\n      58487\n      58488\n      58489\n      58490\n      58491\n    \n  \n  \n    \n      MONTH\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      ...\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n    \n    \n      DAY\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      ...\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n    \n    \n      WEEKDAY\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      ...\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n    \n    \n      AIRLINE\n      WN\n      UA\n      MQ\n      AA\n      WN\n      UA\n      AA\n      F9\n      AA\n      UA\n      ...\n      OO\n      B6\n      MQ\n      DL\n      EV\n      AA\n      F9\n      OO\n      WN\n      OO\n    \n    \n      ORG_AIR\n      LAX\n      DEN\n      DFW\n      DFW\n      LAX\n      IAH\n      DFW\n      SFO\n      ORD\n      IAH\n      ...\n      DEN\n      PHX\n      ORD\n      ATL\n      DFW\n      SFO\n      LAS\n      SFO\n      MSP\n      SFO\n    \n    \n      DEST_AIR\n      SLC\n      IAD\n      VPS\n      DCA\n      MCI\n      SAN\n      MSY\n      PHX\n      STL\n      SJC\n      ...\n      CPR\n      BOS\n      DSM\n      CMH\n      LFT\n      DFW\n      SFO\n      SBA\n      ATL\n      BOI\n    \n    \n      SCHED_DEP\n      1625\n      823\n      1305\n      1555\n      1720\n      1450\n      1250\n      1020\n      1845\n      925\n      ...\n      1850\n      2236\n      1333\n      2206\n      850\n      515\n      1910\n      1846\n      525\n      859\n    \n    \n      DEP_DELAY\n      58.0\n      7.0\n      36.0\n      7.0\n      48.0\n      1.0\n      84.0\n      -7.0\n      -5.0\n      3.0\n      ...\n      -2.0\n      -12.0\n      1.0\n      2.0\n      21.0\n      5.0\n      13.0\n      -6.0\n      39.0\n      5.0\n    \n    \n      AIR_TIME\n      94.0\n      154.0\n      85.0\n      126.0\n      166.0\n      178.0\n      64.0\n      91.0\n      44.0\n      215.0\n      ...\n      38.0\n      231.0\n      57.0\n      64.0\n      52.0\n      166.0\n      71.0\n      46.0\n      124.0\n      73.0\n    \n    \n      DIST\n      590\n      1452\n      641\n      1192\n      1363\n      1303\n      447\n      651\n      258\n      1608\n      ...\n      230\n      2300\n      299\n      447\n      351\n      1464\n      414\n      262\n      907\n      522\n    \n    \n      SCHED_ARR\n      1905\n      1333\n      1453\n      1935\n      2225\n      1620\n      1410\n      1315\n      1950\n      1136\n      ...\n      1956\n      515\n      1455\n      2338\n      1012\n      1045\n      2050\n      1956\n      855\n      1146\n    \n    \n      ARR_DELAY\n      65.0\n      -13.0\n      35.0\n      -7.0\n      39.0\n      -14.0\n      83.0\n      -6.0\n      -5.0\n      -14.0\n      ...\n      1.0\n      -45.0\n      -7.0\n      -8.0\n      14.0\n      -19.0\n      4.0\n      -5.0\n      34.0\n      -1.0\n    \n    \n      DIVERTED\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      CANCELLED\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n14 rows × 58492 columns\n\n\n\n\ndf.DIST.describe()\n\ncount    58492.000000\nmean       872.900072\nstd        624.996805\nmin         67.000000\n25%        391.000000\n50%        690.000000\n75%       1199.000000\nmax       4502.000000\nName: DIST, dtype: float64\n\n\n\ndf.assign(DIST2 = pd.cut(df.DIST,[-np.inf,391,690,1199,np.inf]))\\\n.groupby([\"AIRLINE\",\"DIST2\"]).agg({'CANCELLED':[\"sum\",\"mean\",\"count\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      \n      \n      sum\n      mean\n      count\n    \n    \n      AIRLINE\n      DIST2\n      \n      \n      \n    \n  \n  \n    \n      AA\n      (-inf, 391.0]\n      18\n      0.015986\n      1126\n    \n    \n      (391.0, 690.0]\n      17\n      0.013589\n      1251\n    \n    \n      (690.0, 1199.0]\n      69\n      0.022066\n      3127\n    \n    \n      (1199.0, inf]\n      50\n      0.014723\n      3396\n    \n    \n      AS\n      (-inf, 391.0]\n      0\n      NaN\n      0\n    \n    \n      (391.0, 690.0]\n      0\n      0.000000\n      145\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      462\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      161\n    \n    \n      B6\n      (-inf, 391.0]\n      0\n      0.000000\n      71\n    \n    \n      (391.0, 690.0]\n      0\n      0.000000\n      38\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      61\n    \n    \n      (1199.0, inf]\n      1\n      0.002681\n      373\n    \n    \n      DL\n      (-inf, 391.0]\n      7\n      0.003086\n      2268\n    \n    \n      (391.0, 690.0]\n      8\n      0.002421\n      3304\n    \n    \n      (690.0, 1199.0]\n      16\n      0.006405\n      2498\n    \n    \n      (1199.0, inf]\n      7\n      0.002766\n      2531\n    \n    \n      EV\n      (-inf, 391.0]\n      77\n      0.028785\n      2675\n    \n    \n      (391.0, 690.0]\n      47\n      0.022793\n      2062\n    \n    \n      (690.0, 1199.0]\n      22\n      0.019982\n      1101\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      20\n    \n    \n      F9\n      (-inf, 391.0]\n      0\n      0.000000\n      27\n    \n    \n      (391.0, 690.0]\n      6\n      0.013825\n      434\n    \n    \n      (690.0, 1199.0]\n      4\n      0.007105\n      563\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      293\n    \n    \n      HA\n      (-inf, 391.0]\n      0\n      NaN\n      0\n    \n    \n      (391.0, 690.0]\n      0\n      NaN\n      0\n    \n    \n      (690.0, 1199.0]\n      0\n      NaN\n      0\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      112\n    \n    \n      MQ\n      (-inf, 391.0]\n      90\n      0.047120\n      1910\n    \n    \n      (391.0, 690.0]\n      39\n      0.037356\n      1044\n    \n    \n      (690.0, 1199.0]\n      22\n      0.044266\n      497\n    \n    \n      (1199.0, inf]\n      1\n      0.050000\n      20\n    \n    \n      NK\n      (-inf, 391.0]\n      5\n      0.036496\n      137\n    \n    \n      (391.0, 690.0]\n      4\n      0.013201\n      303\n    \n    \n      (690.0, 1199.0]\n      6\n      0.011029\n      544\n    \n    \n      (1199.0, inf]\n      10\n      0.018797\n      532\n    \n    \n      OO\n      (-inf, 391.0]\n      75\n      0.024826\n      3021\n    \n    \n      (391.0, 690.0]\n      39\n      0.019364\n      2014\n    \n    \n      (690.0, 1199.0]\n      19\n      0.016351\n      1162\n    \n    \n      (1199.0, inf]\n      9\n      0.023018\n      391\n    \n    \n      UA\n      (-inf, 391.0]\n      5\n      0.007143\n      700\n    \n    \n      (391.0, 690.0]\n      14\n      0.011824\n      1184\n    \n    \n      (690.0, 1199.0]\n      26\n      0.010924\n      2380\n    \n    \n      (1199.0, inf]\n      48\n      0.013605\n      3528\n    \n    \n      US\n      (-inf, 391.0]\n      0\n      0.000000\n      254\n    \n    \n      (391.0, 690.0]\n      7\n      0.021944\n      319\n    \n    \n      (690.0, 1199.0]\n      2\n      0.006329\n      316\n    \n    \n      (1199.0, inf]\n      12\n      0.016529\n      726\n    \n    \n      VX\n      (-inf, 391.0]\n      2\n      0.008299\n      241\n    \n    \n      (391.0, 690.0]\n      1\n      0.003861\n      259\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      22\n    \n    \n      (1199.0, inf]\n      3\n      0.006369\n      471\n    \n    \n      WN\n      (-inf, 391.0]\n      55\n      0.023810\n      2310\n    \n    \n      (391.0, 690.0]\n      14\n      0.006487\n      2158\n    \n    \n      (690.0, 1199.0]\n      17\n      0.007896\n      2153\n    \n    \n      (1199.0, inf]\n      7\n      0.003895\n      1797\n    \n  \n\n\n\n\ncut과 관련된 설명: https://seong6496.tistory.com/247 참고\n\ndf.assign(DIST2 = pd.cut(df.DIST,[-np.inf,400,700,1200,np.inf],labels=['~400','400~700','700~1200','1200~']))\\\n.groupby([\"AIRLINE\",\"DIST2\"]).agg({'CANCELLED':[\"sum\",\"mean\",\"count\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      \n      \n      sum\n      mean\n      count\n    \n    \n      AIRLINE\n      DIST2\n      \n      \n      \n    \n  \n  \n    \n      AA\n      ~400\n      18\n      0.015986\n      1126\n    \n    \n      400~700\n      17\n      0.013589\n      1251\n    \n    \n      700~1200\n      69\n      0.022066\n      3127\n    \n    \n      1200~\n      50\n      0.014723\n      3396\n    \n    \n      AS\n      ~400\n      0\n      NaN\n      0\n    \n    \n      400~700\n      0\n      0.000000\n      145\n    \n    \n      700~1200\n      0\n      0.000000\n      462\n    \n    \n      1200~\n      0\n      0.000000\n      161\n    \n    \n      B6\n      ~400\n      0\n      0.000000\n      71\n    \n    \n      400~700\n      0\n      0.000000\n      38\n    \n    \n      700~1200\n      0\n      0.000000\n      61\n    \n    \n      1200~\n      1\n      0.002681\n      373\n    \n    \n      DL\n      ~400\n      7\n      0.003040\n      2303\n    \n    \n      400~700\n      8\n      0.002352\n      3402\n    \n    \n      700~1200\n      16\n      0.006765\n      2365\n    \n    \n      1200~\n      7\n      0.002766\n      2531\n    \n    \n      EV\n      ~400\n      77\n      0.027838\n      2766\n    \n    \n      400~700\n      48\n      0.023312\n      2059\n    \n    \n      700~1200\n      21\n      0.020731\n      1013\n    \n    \n      1200~\n      0\n      0.000000\n      20\n    \n    \n      F9\n      ~400\n      0\n      0.000000\n      27\n    \n    \n      400~700\n      7\n      0.015837\n      442\n    \n    \n      700~1200\n      3\n      0.005405\n      555\n    \n    \n      1200~\n      0\n      0.000000\n      293\n    \n    \n      HA\n      ~400\n      0\n      NaN\n      0\n    \n    \n      400~700\n      0\n      NaN\n      0\n    \n    \n      700~1200\n      0\n      NaN\n      0\n    \n    \n      1200~\n      0\n      0.000000\n      112\n    \n    \n      MQ\n      ~400\n      92\n      0.047472\n      1938\n    \n    \n      400~700\n      39\n      0.035682\n      1093\n    \n    \n      700~1200\n      20\n      0.047619\n      420\n    \n    \n      1200~\n      1\n      0.050000\n      20\n    \n    \n      NK\n      ~400\n      5\n      0.036496\n      137\n    \n    \n      400~700\n      4\n      0.013201\n      303\n    \n    \n      700~1200\n      6\n      0.011029\n      544\n    \n    \n      1200~\n      10\n      0.018797\n      532\n    \n    \n      OO\n      ~400\n      76\n      0.024837\n      3060\n    \n    \n      400~700\n      38\n      0.018673\n      2035\n    \n    \n      700~1200\n      19\n      0.017241\n      1102\n    \n    \n      1200~\n      9\n      0.023018\n      391\n    \n    \n      UA\n      ~400\n      5\n      0.006993\n      715\n    \n    \n      400~700\n      14\n      0.011966\n      1170\n    \n    \n      700~1200\n      26\n      0.010929\n      2379\n    \n    \n      1200~\n      48\n      0.013605\n      3528\n    \n    \n      US\n      ~400\n      0\n      0.000000\n      254\n    \n    \n      400~700\n      7\n      0.021944\n      319\n    \n    \n      700~1200\n      2\n      0.006329\n      316\n    \n    \n      1200~\n      12\n      0.016529\n      726\n    \n    \n      VX\n      ~400\n      2\n      0.008299\n      241\n    \n    \n      400~700\n      1\n      0.003861\n      259\n    \n    \n      700~1200\n      0\n      0.000000\n      22\n    \n    \n      1200~\n      3\n      0.006369\n      471\n    \n    \n      WN\n      ~400\n      55\n      0.023022\n      2389\n    \n    \n      400~700\n      17\n      0.007795\n      2181\n    \n    \n      700~1200\n      14\n      0.006826\n      2051\n    \n    \n      1200~\n      7\n      0.003895\n      1797"
  },
  {
    "objectID": "posts/DV_4(0928).html",
    "href": "posts/DV_4(0928).html",
    "title": "DV 4주차(2)",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/DV_4(0928).html#plt복습",
    "href": "posts/DV_4(0928).html#plt복습",
    "title": "DV 4주차(2)",
    "section": "plt복습",
    "text": "plt복습\n\nplt.boxplot([y1,y2])\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f2a64e7a950>,\n  <matplotlib.lines.Line2D at 0x7f2a64e7ac90>,\n  <matplotlib.lines.Line2D at 0x7f2a64e910d0>,\n  <matplotlib.lines.Line2D at 0x7f2a64e913d0>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f2a64e83050>,\n  <matplotlib.lines.Line2D at 0x7f2a64e83350>,\n  <matplotlib.lines.Line2D at 0x7f2a64e91710>,\n  <matplotlib.lines.Line2D at 0x7f2a64e91a50>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f2a64e7a650>,\n  <matplotlib.lines.Line2D at 0x7f2a64e83d50>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f2a64e836d0>,\n  <matplotlib.lines.Line2D at 0x7f2a64e91d90>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f2a64e83a10>,\n  <matplotlib.lines.Line2D at 0x7f2a64e9e110>],\n 'means': []}"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-wide-df",
    "href": "posts/DV_4(0928).html#sns-wide-df",
    "title": "DV 4주차(2)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf1=pd.DataFrame({1:y1,2:y2})\ndf1\n\n\n\n\n\n  \n    \n      \n      1\n      2\n    \n  \n  \n    \n      0\n      75\n      76\n    \n    \n      1\n      75\n      76\n    \n    \n      2\n      76\n      77\n    \n    \n      3\n      76\n      77\n    \n    \n      4\n      77\n      78\n    \n    \n      5\n      77\n      78\n    \n    \n      6\n      79\n      80\n    \n    \n      7\n      79\n      80\n    \n    \n      8\n      79\n      80\n    \n    \n      9\n      98\n      81\n    \n  \n\n\n\n\n- 예시1\n\nsns.boxplot(data=df1)\n\n<AxesSubplot:>\n\n\n\n\n\n\nsns.boxplot(np.stack([y1,y2],axis=1))   # 잘 쓰진 않는데 된다\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-long-df",
    "href": "posts/DV_4(0928).html#sns-long-df",
    "title": "DV 4주차(2)",
    "section": "sns: long df",
    "text": "sns: long df\nvalue 를 넣고 그 value가 어떤 category에 있는지 넣는 방법\n\ndf2 = pd.DataFrame({'score': y1+y2, 'class': ['A']*len(y1)+['B']*len(y2)})\ndf2\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      75\n      A\n    \n    \n      1\n      75\n      A\n    \n    \n      2\n      76\n      A\n    \n    \n      3\n      76\n      A\n    \n    \n      4\n      77\n      A\n    \n    \n      5\n      77\n      A\n    \n    \n      6\n      79\n      A\n    \n    \n      7\n      79\n      A\n    \n    \n      8\n      79\n      A\n    \n    \n      9\n      98\n      A\n    \n    \n      10\n      76\n      B\n    \n    \n      11\n      76\n      B\n    \n    \n      12\n      77\n      B\n    \n    \n      13\n      77\n      B\n    \n    \n      14\n      78\n      B\n    \n    \n      15\n      78\n      B\n    \n    \n      16\n      80\n      B\n    \n    \n      17\n      80\n      B\n    \n    \n      18\n      80\n      B\n    \n    \n      19\n      81\n      B\n    \n  \n\n\n\n\n- 예시1\n\nsns.boxplot(data=df2, x='class', y='score')\n\n<AxesSubplot:xlabel='class', ylabel='score'>"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-array",
    "href": "posts/DV_4(0928).html#sns-array",
    "title": "DV 4주차(2)",
    "section": "sns: array",
    "text": "sns: array\n- 예시1\n\nsns.boxplot(data=y1)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시2\n\nsns.boxplot(y=y1)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시3\n\nsns.boxplot(x=y1)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/DV_4(0928).html#plt-복습",
    "href": "posts/DV_4(0928).html#plt-복습",
    "title": "DV 4주차(2)",
    "section": "plt 복습",
    "text": "plt 복습\n\nplt.hist(x,alpha=0.5)\nplt.hist(y,alpha=0.5)\n\n(array([2.000e+00, 1.500e+01, 1.550e+02, 7.670e+02, 2.062e+03, 3.085e+03,\n        2.479e+03, 1.117e+03, 2.790e+02, 3.900e+01]),\n array([-3.5473064 , -2.74724651, -1.94718662, -1.14712673, -0.34706684,\n         0.45299304,  1.25305293,  2.05311282,  2.85317271,  3.6532326 ,\n         4.45329248]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 예시2\n\nplt.hist([x,y]);"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-wide-df-1",
    "href": "posts/DV_4(0928).html#sns-wide-df-1",
    "title": "DV 4주차(2)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf1=pd.DataFrame({'x':x, 'y':y})\ndf1\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.392340\n      -0.520932\n    \n    \n      1\n      -0.027382\n      2.332888\n    \n    \n      2\n      -0.266977\n      0.973511\n    \n    \n      3\n      -0.493336\n      2.801266\n    \n    \n      4\n      0.282255\n      0.433189\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      9995\n      -0.752878\n      2.394238\n    \n    \n      9996\n      -0.212005\n      2.293700\n    \n    \n      9997\n      -1.118235\n      2.660186\n    \n    \n      9998\n      1.558492\n      0.886679\n    \n    \n      9999\n      -0.753399\n      1.977537\n    \n  \n\n10000 rows × 2 columns\n\n\n\n- 예시\n\nsns.histplot(data=df1);\n\n\n\n\n\nsns.histplot(data=df1,bins=20)  # 칸 조정\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nsns.histplot(data=df1,bins=20,kde=True);    # kde : 곡선\n\n\n\n\n\nsns.histplot(data=df1,bins=20,kde=True,element=\"step\");\n\n\n\n\n\nsns.histplot(data=df1,bins=20,kde=True,element=\"step\",lw=5) # mpl에 대한 존경심 확인 \n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-long-df-1",
    "href": "posts/DV_4(0928).html#sns-long-df-1",
    "title": "DV 4주차(2)",
    "section": "sns: long df",
    "text": "sns: long df\n\ndf2=pd.DataFrame({'val' : np.concatenate([x,y]), 'var': ['x']*len(x) + ['y']*len(y)})\ndf2\n\n\n\n\n\n  \n    \n      \n      val\n      var\n    \n  \n  \n    \n      0\n      0.392340\n      x\n    \n    \n      1\n      -0.027382\n      x\n    \n    \n      2\n      -0.266977\n      x\n    \n    \n      3\n      -0.493336\n      x\n    \n    \n      4\n      0.282255\n      x\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      19995\n      2.394238\n      y\n    \n    \n      19996\n      2.293700\n      y\n    \n    \n      19997\n      2.660186\n      y\n    \n    \n      19998\n      0.886679\n      y\n    \n    \n      19999\n      1.977537\n      y\n    \n  \n\n20000 rows × 2 columns\n\n\n\n\nsns.histplot(data=df2, x='val', hue='var', bins=20, kde=True, lw=0)\n# hue:색깔 var로 구분하겠다! \n\n<AxesSubplot:xlabel='val', ylabel='Count'>"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-array-1",
    "href": "posts/DV_4(0928).html#sns-array-1",
    "title": "DV 4주차(2)",
    "section": "sns: array",
    "text": "sns: array\n\nsns.histplot(data=x)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nsns.histplot(x=x)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nsns.histplot(x=x, color='C0', bins=20, lw=0)\nsns.histplot(x=y, color='C0', bins=20, lw=0)\n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/DV_4(0928).html#plt복습-1",
    "href": "posts/DV_4(0928).html#plt복습-1",
    "title": "DV 4주차(2)",
    "section": "plt복습",
    "text": "plt복습\n\nplt.plot(ϵ,'--o')\n\n\n\n\n\nplt.plot(y,'--o')"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-array-2",
    "href": "posts/DV_4(0928).html#sns-array-2",
    "title": "DV 4주차(2)",
    "section": "sns: array",
    "text": "sns: array\n\nsns.lineplot(data=ϵ)\n\n<AxesSubplot:>\n\n\n\n\n\n\nsns.lineplot(data=y)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-wide-df-2",
    "href": "posts/DV_4(0928).html#sns-wide-df-2",
    "title": "DV 4주차(2)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf4 = pd.DataFrame({'ϵ' : ϵ , 'y' : y})\ndf4\n\n\n\n\n\n  \n    \n      \n      ϵ\n      y\n    \n  \n  \n    \n      0\n      0.383420\n      0.383420\n    \n    \n      1\n      1.084175\n      1.467595\n    \n    \n      2\n      1.142778\n      2.610373\n    \n    \n      3\n      0.307894\n      2.918267\n    \n    \n      4\n      0.237787\n      3.156054\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      1.308688\n      -10.598788\n    \n    \n      96\n      0.405376\n      -10.193412\n    \n    \n      97\n      -0.185070\n      -10.378481\n    \n    \n      98\n      1.055388\n      -9.323094\n    \n    \n      99\n      1.187014\n      -8.136079\n    \n  \n\n100 rows × 2 columns\n\n\n\n\nsns.lineplot(data=df4)\n\n<AxesSubplot:>\n\n\n\n\n\n\nsns.lineplot(data=df4, dashes=False)   # dashes : 둘다 실선\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/DV_4(0928).html#sns-long-df-2",
    "href": "posts/DV_4(0928).html#sns-long-df-2",
    "title": "DV 4주차(2)",
    "section": "sns: long df",
    "text": "sns: long df\n\ndf5= pd.DataFrame({'idx':list(range(100))*2,'val':np.concatenate([ϵ,y]),'cat':['eps']*100 + ['y']*100 })\ndf5\n\n\n\n\n\n  \n    \n      \n      idx\n      val\n      cat\n    \n  \n  \n    \n      0\n      0\n      0.383420\n      eps\n    \n    \n      1\n      1\n      1.084175\n      eps\n    \n    \n      2\n      2\n      1.142778\n      eps\n    \n    \n      3\n      3\n      0.307894\n      eps\n    \n    \n      4\n      4\n      0.237787\n      eps\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      95\n      -10.598788\n      y\n    \n    \n      196\n      96\n      -10.193412\n      y\n    \n    \n      197\n      97\n      -10.378481\n      y\n    \n    \n      198\n      98\n      -9.323094\n      y\n    \n    \n      199\n      99\n      -8.136079\n      y\n    \n  \n\n200 rows × 3 columns\n\n\n\n\nsns.lineplot(data=df5, x='idx',y='val',hue='cat')\n\n<AxesSubplot:xlabel='idx', ylabel='val'>\n\n\n\n\n\n\nsns.lineplot(data=df5, x='idx',y='val',style='cat',hue='cat',markers=True)\n\n<AxesSubplot:xlabel='idx', ylabel='val'>\n\n\n\n\n\n\nsns.lineplot(data=df5, x='idx',y='val',style='cat',hue='cat',dashes=[(3,1),(3,3)],markers=['o','o'])\n\n<AxesSubplot:xlabel='idx', ylabel='val'>"
  },
  {
    "objectID": "posts/DV_10(1107).html",
    "href": "posts/DV_10(1107).html",
    "title": "DV 10주차(1)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom plotnine import *"
  },
  {
    "objectID": "posts/DV_10(1107).html#melt",
    "href": "posts/DV_10(1107).html#melt",
    "title": "DV 10주차(1)",
    "section": "melt",
    "text": "melt\n- 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      461\n      324\n      136\n      109\n      76\n      81\n      43\n      37\n      135\n      28\n      39\n      14\n      22\n      17\n      20\n      17\n    \n    \n      1\n      2019-11\n      461\n      358\n      167\n      141\n      86\n      61\n      29\n      36\n      141\n      27\n      29\n      20\n      23\n      10\n      19\n      27\n    \n    \n      2\n      2019-12\n      426\n      383\n      143\n      105\n      53\n      45\n      51\n      48\n      129\n      30\n      20\n      26\n      28\n      18\n      18\n      19\n    \n    \n      3\n      2020-01\n      677\n      494\n      212\n      187\n      110\n      79\n      65\n      49\n      158\n      23\n      13\n      19\n      19\n      22\n      27\n      22\n    \n    \n      4\n      2020-02\n      593\n      520\n      217\n      195\n      112\n      67\n      62\n      71\n      157\n      25\n      18\n      16\n      24\n      18\n      23\n      20\n    \n    \n      5\n      2020-03\n      637\n      537\n      246\n      187\n      92\n      66\n      59\n      67\n      145\n      21\n      16\n      24\n      18\n      31\n      22\n      14\n    \n    \n      6\n      2020-04\n      647\n      583\n      222\n      154\n      98\n      59\n      48\n      64\n      113\n      20\n      23\n      25\n      19\n      19\n      23\n      21\n    \n    \n      7\n      2020-05\n      629\n      518\n      192\n      176\n      91\n      87\n      50\n      66\n      150\n      43\n      27\n      15\n      18\n      19\n      19\n      13\n    \n    \n      8\n      2020-06\n      663\n      552\n      209\n      185\n      93\n      69\n      54\n      60\n      140\n      39\n      16\n      16\n      17\n      29\n      25\n      16\n    \n    \n      9\n      2020-07\n      599\n      471\n      214\n      193\n      89\n      78\n      65\n      59\n      130\n      40\n      27\n      25\n      21\n      18\n      18\n      12\n    \n    \n      10\n      2020-08\n      615\n      567\n      204\n      182\n      105\n      82\n      62\n      42\n      129\n      47\n      16\n      23\n      21\n      27\n      23\n      20\n    \n    \n      11\n      2020-09\n      621\n      481\n      230\n      220\n      102\n      88\n      56\n      49\n      143\n      54\n      14\n      15\n      17\n      15\n      19\n      15\n    \n    \n      12\n      2020-10\n      637\n      555\n      232\n      203\n      90\n      52\n      63\n      49\n      140\n      33\n      17\n      20\n      22\n      9\n      22\n      21\n    \n  \n\n\n\n\n- 사용예시\n\ndf.melt()\n\n\n\n\n\n  \n    \n      \n      variable\n      value\n    \n  \n  \n    \n      0\n      Date\n      2019-10\n    \n    \n      1\n      Date\n      2019-11\n    \n    \n      2\n      Date\n      2019-12\n    \n    \n      3\n      Date\n      2020-01\n    \n    \n      4\n      Date\n      2020-02\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      216\n      Asus\n      16\n    \n    \n      217\n      Asus\n      12\n    \n    \n      218\n      Asus\n      20\n    \n    \n      219\n      Asus\n      15\n    \n    \n      220\n      Asus\n      21\n    \n  \n\n221 rows × 2 columns\n\n\n\n\nvariable: column name들이 들어간다.\nvalue: column name에 대응하는 값들이 들어간다.\n\n- 사용예시2: id_vars -> tidy data\n\ndf.melt(id_vars='Date')\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-11\n      Samsung\n      461\n    \n    \n      2\n      2019-12\n      Samsung\n      426\n    \n    \n      3\n      2020-01\n      Samsung\n      677\n    \n    \n      4\n      2020-02\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-06\n      Asus\n      16\n    \n    \n      204\n      2020-07\n      Asus\n      12\n    \n    \n      205\n      2020-08\n      Asus\n      20\n    \n    \n      206\n      2020-09\n      Asus\n      15\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns\n\n\n\n- 사용예시3:\n\ndf.set_index('Date').melt()\n# 인덱스를 무시하면서 녹여버림\n\n\n\n\n\n  \n    \n      \n      variable\n      value\n    \n  \n  \n    \n      0\n      Samsung\n      461\n    \n    \n      1\n      Samsung\n      461\n    \n    \n      2\n      Samsung\n      426\n    \n    \n      3\n      Samsung\n      677\n    \n    \n      4\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      203\n      Asus\n      16\n    \n    \n      204\n      Asus\n      12\n    \n    \n      205\n      Asus\n      20\n    \n    \n      206\n      Asus\n      15\n    \n    \n      207\n      Asus\n      21\n    \n  \n\n208 rows × 2 columns\n\n\n\n- 사용예시4: ignore_index=False\n\ndf.set_index('Date').melt(ignore_index=False).reset_index()\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-11\n      Samsung\n      461\n    \n    \n      2\n      2019-12\n      Samsung\n      426\n    \n    \n      3\n      2020-01\n      Samsung\n      677\n    \n    \n      4\n      2020-02\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-06\n      Asus\n      16\n    \n    \n      204\n      2020-07\n      Asus\n      12\n    \n    \n      205\n      2020-08\n      Asus\n      20\n    \n    \n      206\n      2020-09\n      Asus\n      15\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns"
  },
  {
    "objectID": "posts/DV_10(1107).html#stack",
    "href": "posts/DV_10(1107).html#stack",
    "title": "DV 10주차(1)",
    "section": "stack",
    "text": "stack\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\\\n.groupby([\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":[np.mean,\"count\"],\"DIVERTED\":[np.mean,\"count\"]})\ndf\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277\n      0.004699\n      1277\n    \n    \n      2\n      0.007341\n      1226\n      0.001631\n      1226\n    \n    \n      3\n      0.011949\n      1339\n      0.001494\n      1339\n    \n    \n      4\n      0.015004\n      1333\n      0.003751\n      1333\n    \n    \n      5\n      0.014151\n      1272\n      0.000786\n      1272\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275\n      0.001569\n      1275\n    \n    \n      4\n      0.007911\n      1264\n      0.003165\n      1264\n    \n    \n      5\n      0.005828\n      1201\n      0.000000\n      1201\n    \n    \n      6\n      0.010132\n      987\n      0.003040\n      987\n    \n    \n      7\n      0.006066\n      1154\n      0.002600\n      1154\n    \n  \n\n98 rows × 4 columns\n\n\n\n\ndf.stack()\n\n\n\n\n\n  \n    \n      \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      mean\n      0.032106\n      0.004699\n    \n    \n      count\n      1277.000000\n      1277.000000\n    \n    \n      2\n      mean\n      0.007341\n      0.001631\n    \n    \n      count\n      1226.000000\n      1226.000000\n    \n    \n      3\n      mean\n      0.011949\n      0.001494\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      5\n      count\n      1201.000000\n      1201.000000\n    \n    \n      6\n      mean\n      0.010132\n      0.003040\n    \n    \n      count\n      987.000000\n      987.000000\n    \n    \n      7\n      mean\n      0.006066\n      0.002600\n    \n    \n      count\n      1154.000000\n      1154.000000\n    \n  \n\n196 rows × 2 columns\n\n\n\n- 사용에시2\n\ndf.stack().stack().reset_index().rename({0:'value'},axis=1)\n#df.stack().stack().reset_index().rename(columns={'level_2':'aggtype'})\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      level_2\n      level_3\n      value\n    \n  \n  \n    \n      0\n      AA\n      1\n      mean\n      CANCELLED\n      0.032106\n    \n    \n      1\n      AA\n      1\n      mean\n      DIVERTED\n      0.004699\n    \n    \n      2\n      AA\n      1\n      count\n      CANCELLED\n      1277.000000\n    \n    \n      3\n      AA\n      1\n      count\n      DIVERTED\n      1277.000000\n    \n    \n      4\n      AA\n      2\n      mean\n      CANCELLED\n      0.007341\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      6\n      count\n      DIVERTED\n      987.000000\n    \n    \n      388\n      WN\n      7\n      mean\n      CANCELLED\n      0.006066\n    \n    \n      389\n      WN\n      7\n      mean\n      DIVERTED\n      0.002600\n    \n    \n      390\n      WN\n      7\n      count\n      CANCELLED\n      1154.000000\n    \n    \n      391\n      WN\n      7\n      count\n      DIVERTED\n      1154.000000\n    \n  \n\n392 rows × 5 columns\n\n\n\n- 사용예시3(unstack)\n\ndf.stack().unstack()\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277.0\n      0.004699\n      1277.0\n    \n    \n      2\n      0.007341\n      1226.0\n      0.001631\n      1226.0\n    \n    \n      3\n      0.011949\n      1339.0\n      0.001494\n      1339.0\n    \n    \n      4\n      0.015004\n      1333.0\n      0.003751\n      1333.0\n    \n    \n      5\n      0.014151\n      1272.0\n      0.000786\n      1272.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275.0\n      0.001569\n      1275.0\n    \n    \n      4\n      0.007911\n      1264.0\n      0.003165\n      1264.0\n    \n    \n      5\n      0.005828\n      1201.0\n      0.000000\n      1201.0\n    \n    \n      6\n      0.010132\n      987.0\n      0.003040\n      987.0\n    \n    \n      7\n      0.006066\n      1154.0\n      0.002600\n      1154.0\n    \n  \n\n98 rows × 4 columns\n\n\n\ntidy data를 만들기 위해 melt, stack를 잘 이용하자"
  },
  {
    "objectID": "posts/DV_10(1107).html#tidydata의-정의",
    "href": "posts/DV_10(1107).html#tidydata의-정의",
    "title": "DV 10주차(1)",
    "section": "tidydata의 정의",
    "text": "tidydata의 정의\n- 느낌: ggplot로 그림 그리기 좋은 데이터 + pandas로 query, group by 등을 쓰기 좋은 자료\n- 정의: https://r4ds.had.co.nz/tidy-data.html\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n- 예시1 (tidydata)\n\n\n\nobs\nx\ny\nshape\ncolor\n\n\n\n\n0\n0\n0\n‘star’\n‘F’\n\n\n1\n0\n1\n‘circ’\n‘F’\n\n\n2\n1\n0\n‘star’\n‘M’\n\n\n3\n1\n1\n‘circ’\n‘M’\n\n\n\n- 예시2 (tidy data x)\n\n\n\n\nshape=star\nshape=circ\n\n\n\n\ncolor=F\n(0,0)\n(0,1)\n\n\ncolor=M\n(1,0)\n(1,1)"
  },
  {
    "objectID": "posts/DV_10(1107).html#예제1-wide-df",
    "href": "posts/DV_10(1107).html#예제1-wide-df",
    "title": "DV 10주차(1)",
    "section": "예제1: wide df",
    "text": "예제1: wide df\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      461\n      324\n      136\n      109\n      76\n      81\n      43\n      37\n      135\n      28\n      39\n      14\n      22\n      17\n      20\n      17\n    \n    \n      1\n      2019-11\n      461\n      358\n      167\n      141\n      86\n      61\n      29\n      36\n      141\n      27\n      29\n      20\n      23\n      10\n      19\n      27\n    \n    \n      2\n      2019-12\n      426\n      383\n      143\n      105\n      53\n      45\n      51\n      48\n      129\n      30\n      20\n      26\n      28\n      18\n      18\n      19\n    \n    \n      3\n      2020-01\n      677\n      494\n      212\n      187\n      110\n      79\n      65\n      49\n      158\n      23\n      13\n      19\n      19\n      22\n      27\n      22\n    \n    \n      4\n      2020-02\n      593\n      520\n      217\n      195\n      112\n      67\n      62\n      71\n      157\n      25\n      18\n      16\n      24\n      18\n      23\n      20\n    \n    \n      5\n      2020-03\n      637\n      537\n      246\n      187\n      92\n      66\n      59\n      67\n      145\n      21\n      16\n      24\n      18\n      31\n      22\n      14\n    \n    \n      6\n      2020-04\n      647\n      583\n      222\n      154\n      98\n      59\n      48\n      64\n      113\n      20\n      23\n      25\n      19\n      19\n      23\n      21\n    \n    \n      7\n      2020-05\n      629\n      518\n      192\n      176\n      91\n      87\n      50\n      66\n      150\n      43\n      27\n      15\n      18\n      19\n      19\n      13\n    \n    \n      8\n      2020-06\n      663\n      552\n      209\n      185\n      93\n      69\n      54\n      60\n      140\n      39\n      16\n      16\n      17\n      29\n      25\n      16\n    \n    \n      9\n      2020-07\n      599\n      471\n      214\n      193\n      89\n      78\n      65\n      59\n      130\n      40\n      27\n      25\n      21\n      18\n      18\n      12\n    \n    \n      10\n      2020-08\n      615\n      567\n      204\n      182\n      105\n      82\n      62\n      42\n      129\n      47\n      16\n      23\n      21\n      27\n      23\n      20\n    \n    \n      11\n      2020-09\n      621\n      481\n      230\n      220\n      102\n      88\n      56\n      49\n      143\n      54\n      14\n      15\n      17\n      15\n      19\n      15\n    \n    \n      12\n      2020-10\n      637\n      555\n      232\n      203\n      90\n      52\n      63\n      49\n      140\n      33\n      17\n      20\n      22\n      9\n      22\n      21\n    \n  \n\n\n\n\n\ntidy data 아님\n정의에 의한 판단: 하나의 observation이 하나의 행을 차지하고 있지 않음.\n직관적인 판단: 회사별로 색을 다르게 하여 x:‘Date’, y:’판매량’을 하고 싶다면?\n\n- tidydata로 변환 (melt는 너무 쉬우니까 stack으로 해보자)\n\ndf.set_index('Date').stack().reset_index().rename({'level_1':'Company',0:'Sales'},axis=1)\n\n# axis=1 을 설정을 안해주면 index에 있는 0이 바뀌므로 컬럼에 있는 0 값을 바꿔주기 위해서 axis를 표시\n\n\n\n\n\n  \n    \n      \n      Date\n      Company\n      Sales\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-10\n      Apple\n      324\n    \n    \n      2\n      2019-10\n      Huawei\n      136\n    \n    \n      3\n      2019-10\n      Xiaomi\n      109\n    \n    \n      4\n      2019-10\n      Oppo\n      76\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-10\n      Nokia\n      20\n    \n    \n      204\n      2020-10\n      Lenovo\n      22\n    \n    \n      205\n      2020-10\n      OnePlus\n      9\n    \n    \n      206\n      2020-10\n      Sony\n      22\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns\n\n\n\n\ndf.melt('Date')\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-11\n      Samsung\n      461\n    \n    \n      2\n      2019-12\n      Samsung\n      426\n    \n    \n      3\n      2020-01\n      Samsung\n      677\n    \n    \n      4\n      2020-02\n      Samsung\n      593\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-06\n      Asus\n      16\n    \n    \n      204\n      2020-07\n      Asus\n      12\n    \n    \n      205\n      2020-08\n      Asus\n      20\n    \n    \n      206\n      2020-09\n      Asus\n      15\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns"
  },
  {
    "objectID": "posts/DV_10(1107).html#예제2-multi-indexed-data",
    "href": "posts/DV_10(1107).html#예제2-multi-indexed-data",
    "title": "DV 10주차(1)",
    "section": "예제2: multi-indexed data",
    "text": "예제2: multi-indexed data\n- 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\\\n.groupby([\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":[np.mean,\"count\"],\"DIVERTED\":[np.mean,\"count\"]})\ndf\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277\n      0.004699\n      1277\n    \n    \n      2\n      0.007341\n      1226\n      0.001631\n      1226\n    \n    \n      3\n      0.011949\n      1339\n      0.001494\n      1339\n    \n    \n      4\n      0.015004\n      1333\n      0.003751\n      1333\n    \n    \n      5\n      0.014151\n      1272\n      0.000786\n      1272\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275\n      0.001569\n      1275\n    \n    \n      4\n      0.007911\n      1264\n      0.003165\n      1264\n    \n    \n      5\n      0.005828\n      1201\n      0.000000\n      1201\n    \n    \n      6\n      0.010132\n      987\n      0.003040\n      987\n    \n    \n      7\n      0.006066\n      1154\n      0.002600\n      1154\n    \n  \n\n98 rows × 4 columns\n\n\n\n\nWEEKDAY == 4 and mean(CANCELLED)> 0.001\n\n- tidydata로 변환 (stack으로 풀면 너무 쉬우니까 melt로 해보자)\n\ndf.melt(ignore_index=False).reset_index()\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      variable_0\n      variable_1\n      value\n    \n  \n  \n    \n      0\n      AA\n      1\n      CANCELLED\n      mean\n      0.032106\n    \n    \n      1\n      AA\n      2\n      CANCELLED\n      mean\n      0.007341\n    \n    \n      2\n      AA\n      3\n      CANCELLED\n      mean\n      0.011949\n    \n    \n      3\n      AA\n      4\n      CANCELLED\n      mean\n      0.015004\n    \n    \n      4\n      AA\n      5\n      CANCELLED\n      mean\n      0.014151\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      3\n      DIVERTED\n      count\n      1275.000000\n    \n    \n      388\n      WN\n      4\n      DIVERTED\n      count\n      1264.000000\n    \n    \n      389\n      WN\n      5\n      DIVERTED\n      count\n      1201.000000\n    \n    \n      390\n      WN\n      6\n      DIVERTED\n      count\n      987.000000\n    \n    \n      391\n      WN\n      7\n      DIVERTED\n      count\n      1154.000000\n    \n  \n\n392 rows × 5 columns\n\n\n\n\ndf.stack().stack().reset_index()\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      level_2\n      level_3\n      0\n    \n  \n  \n    \n      0\n      AA\n      1\n      mean\n      CANCELLED\n      0.032106\n    \n    \n      1\n      AA\n      1\n      mean\n      DIVERTED\n      0.004699\n    \n    \n      2\n      AA\n      1\n      count\n      CANCELLED\n      1277.000000\n    \n    \n      3\n      AA\n      1\n      count\n      DIVERTED\n      1277.000000\n    \n    \n      4\n      AA\n      2\n      mean\n      CANCELLED\n      0.007341\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      6\n      count\n      DIVERTED\n      987.000000\n    \n    \n      388\n      WN\n      7\n      mean\n      CANCELLED\n      0.006066\n    \n    \n      389\n      WN\n      7\n      mean\n      DIVERTED\n      0.002600\n    \n    \n      390\n      WN\n      7\n      count\n      CANCELLED\n      1154.000000\n    \n    \n      391\n      WN\n      7\n      count\n      DIVERTED\n      1154.000000\n    \n  \n\n392 rows × 5 columns"
  },
  {
    "objectID": "posts/DV_10(1107).html#geom_col",
    "href": "posts/DV_10(1107).html#geom_col",
    "title": "DV 10주차(1)",
    "section": "geom_col",
    "text": "geom_col\n- 예시1: 한국과 일본의 평균능력치 비교\n\ndf.groupby(\"Nationality\").agg({'Overall':np.mean})\n\n\n\n\n\n  \n    \n      \n      Overall\n    \n    \n      Nationality\n      \n    \n  \n  \n    \n      Japan\n      66.478873\n    \n    \n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\ndata=df.groupby(\"Nationality\").agg({'Overall':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n    \n    \n      1\n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\nggplot(data) + geom_col(aes(x='Nationality',y='Overall'))\n\n\n\n\n<ggplot: (8768299681497)>\n\n\n- 예시2: 한국과 일본의 평균능력치 비교 (색상비교)\n\nggplot(data) + geom_col(aes(x='Nationality',y='Overall', color='Nationality'))\n\n\n\n\n<ggplot: (8768299537529)>\n\n\n\ncolor로 설정하니까 테두리에만 색이 변경\n\n\nggplot(data) + geom_col(aes(x='Nationality',y='Overall', fill='Nationality'))\n\n\n\n\n<ggplot: (8768299479765)>\n\n\n- 예시3: 한국과 일본의 평균연령 비교\n\ndata=df.groupby(\"Nationality\").agg({'Age':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Age\n    \n  \n  \n    \n      0\n      Japan\n      26.084507\n    \n    \n      1\n      Korea Republic\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data) + geom_col(aes(x='Nationality',y='Age', fill='Nationality'))\n\n\n\n\n<ggplot: (8768299452801)>"
  },
  {
    "objectID": "posts/DV_10(1107).html#geom_col-position-dodge",
    "href": "posts/DV_10(1107).html#geom_col-position-dodge",
    "title": "DV 10주차(1)",
    "section": "geom_col + position = ‘dodge’",
    "text": "geom_col + position = ‘dodge’\n- 예시1: 한국과 일본의 평균연령+ 평균능력치 비교\n\ndata=df.groupby('Nationality')[['Overall','Age']].mean().reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n      Age\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n      26.084507\n    \n    \n      1\n      Korea Republic\n      65.457627\n      27.158192\n    \n  \n\n\n\n\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean,'Age':np.mean})\\\n.stack().reset_index().rename({0:'value'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      level_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      66.478873\n    \n    \n      1\n      Japan\n      Age\n      26.084507\n    \n    \n      2\n      Korea Republic\n      Overall\n      65.457627\n    \n    \n      3\n      Korea Republic\n      Age\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'))\n\n\n\n\n<ggplot: (8768299401365)>\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\n\n\n\n\n<ggplot: (8768299487993)>"
  },
  {
    "objectID": "posts/DV_10(1107).html#geom_col-coord_flip-90도회전",
    "href": "posts/DV_10(1107).html#geom_col-coord_flip-90도회전",
    "title": "DV 10주차(1)",
    "section": "geom_col + coord_flip() 90도회전",
    "text": "geom_col + coord_flip() 90도회전\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+coord_flip() # 90도 회전\n\n\n\n\n<ggplot: (8768299486913)>"
  },
  {
    "objectID": "posts/DV_10(1107).html#geom_col-facet_wrapvar-면분할",
    "href": "posts/DV_10(1107).html#geom_col-facet_wrapvar-면분할",
    "title": "DV 10주차(1)",
    "section": "geom_col + facet_wrap(var) 면분할",
    "text": "geom_col + facet_wrap(var) 면분할\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('level_1')\n\n\n\n\n<ggplot: (8768299327049)>\n\n\n\nggplot(data)+geom_col(aes(x='Nationality',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('level_1')\n\n\n\n\n<ggplot: (8768299261221)>\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('Nationality')\n\n\n\n\n<ggplot: (8768299202429)>"
  },
  {
    "objectID": "posts/DV_10(1107).html#geom_col-facet_gridvar_y-var_x",
    "href": "posts/DV_10(1107).html#geom_col-facet_gridvar_y-var_x",
    "title": "DV 10주차(1)",
    "section": "geom_col + facet_grid(‘var_y ~ var_x’)",
    "text": "geom_col + facet_grid(‘var_y ~ var_x’)\n- 예시1: 한국과 일본의 평균연령+평균능력치+최대능력치 비교(면분할)\n\ndata=df.groupby('Nationality').agg({'Overall':[np.mean,np.max],'Age':np.mean})\\\n.melt(ignore_index=False).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      variable_0\n      variable_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      mean\n      66.478873\n    \n    \n      1\n      Korea Republic\n      Overall\n      mean\n      65.457627\n    \n    \n      2\n      Japan\n      Overall\n      amax\n      79.000000\n    \n    \n      3\n      Korea Republic\n      Overall\n      amax\n      89.000000\n    \n    \n      4\n      Japan\n      Age\n      mean\n      26.084507\n    \n    \n      5\n      Korea Republic\n      Age\n      mean\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(fill='Nationality',x='Nationality',y='value'),position='dodge')\\\n+facet_grid('variable_1~variable_0')\n\n\n\n\n<ggplot: (8768299165069)>"
  },
  {
    "objectID": "posts/DV_10(1107).html#geom_bar-vs-geom_col",
    "href": "posts/DV_10(1107).html#geom_bar-vs-geom_col",
    "title": "DV 10주차(1)",
    "section": "geom_bar vs geom_col",
    "text": "geom_bar vs geom_col\n- 예시1: 한국과 일본의 단순 선수 숫자 비교 (with goem_col)\n\ndata=df.groupby('Nationality').agg({'Age':'count'}).reset_index().rename({'Age':'count'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      count\n    \n  \n  \n    \n      0\n      Japan\n      284\n    \n    \n      1\n      Korea Republic\n      177\n    \n  \n\n\n\n\n단순 숫자 비교이므로 Age, Overall 아무거나 변수 넣어도 상관 없음\n\nggplot(data) + geom_col(aes(x='Nationality',fill='Nationality', y='count'))\n\n\n\n\n<ggplot: (8768298937265)>\n\n\n- 예시2: 한국과 일본의 단순 선수 숫자 비교 (with goem_bar)\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'))\n\n\n\n\n<ggplot: (8768298906069)>\n\n\n\ngeom_bar : groupby + count 가 자동으로 수행된다.\n특징1: 원래 데이터프레임 그대로 하는게 아니라 뭔가 변형된 값이 출력 (정확하게는 groupby + count가 변형요소)\n특징2: y는 당연히 count이므로 y를 명시할 필요가 없음. (잘 생각해보면 명시하고 싶어도 명시할 수 없음, y는 groupby + count 에 의해서 계산된 값이고 df자체에는 존재하지 않음)\n\n- 이렇게 약속된 변형은 stat='count' 옵션 때문에 가능함\n\nstat='count'는 그룹바이이후에 count를 하라는 의미\n\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'), stat='count')\n\n\n\n\n<ggplot: (8768298885053)>\n\n\n- stat='identity’ 로 옵션을 바꾸면 약속된 변환이 수행되지 않음\n\nstat='identity'는 아무 변환도 하지말라는 의미\n\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'), stat='identity')\n\nKeyError: 'y'\n\n\n\n아무것도 변환하지 말라는 의미이므로 에러가 난다.\n\n- 아래 3개의 코드는 모두 같다.\n\nggplot(df)+geom_bar(aes(x='Nationality',y='..count..',fill='Nationality'),stat='count')\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'),stat='count') # y='..count..' 생략,\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality')) # y='..count..' 생략, stat='count' 생략\n\n\n\n\n<ggplot: (8768298833649)>"
  },
  {
    "objectID": "posts/DV_10(1107).html#geom_bar의-불편한-점",
    "href": "posts/DV_10(1107).html#geom_bar의-불편한-점",
    "title": "DV 10주차(1)",
    "section": "geom_bar()의 불편한 점",
    "text": "geom_bar()의 불편한 점\n- 사실 편하라고 만든것 같은데, 그닥 편하지 않음.\n\n편하라고 만든 점1: groupby를 자동으로 해줘서 groupby를 못하는 유저들이 사용하기 편리하게 함 -> 그런데 우리는 groupby 잘함\n편하라고 만든 점2: groupby이후 count연산을 알아서 해줌 -> 그런데 count연산만 알아서해주고 그 이외의 연산은 잘 지원안됨\n\n- 결론: groupby + count 조합에서만 편리하고 나머지는 편하지 않다.\n- 불편한 예시: 나라별 overall의 평균을 geom_bar()로 플랏해보라.\n\ndata= df.groupby('Nationality').agg({'Overall':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n    \n    \n      1\n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\nggplot(data)+geom_bar(aes(x='Nationality',y='Overall',fill='Nationality'),stat='identity')\nggplot(data)+geom_col(aes(x='Nationality',y='Overall',fill='Nationality'))\n\n\n\n\n<ggplot: (8768298826637)>"
  },
  {
    "objectID": "posts/DV_2(0914).html",
    "href": "posts/DV_2(0914).html",
    "title": "DV 2주차",
    "section": "",
    "text": "!pip install opencv-python\n\nCollecting opencv-python\n  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.8/61.8 MB 42.7 MB/s eta 0:00:0000:0100:01\nRequirement already satisfied: numpy>=1.17.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from opencv-python) (1.21.6)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.7.0.68\n- 히스토그램 이퀄라이제이션(https://en.wikipedia.org/wiki/Histogram_equalization)"
  },
  {
    "objectID": "posts/DV_2(0914).html#이미지-자료-다운로드",
    "href": "posts/DV_2(0914).html#이미지-자료-다운로드",
    "title": "DV 2주차",
    "section": "이미지 자료 다운로드",
    "text": "이미지 자료 다운로드\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg')\n\n--2023-02-22 16:32:29--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg.1’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   519KB/s    in 0.2s    \n\n2023-02-22 16:32:29 (519 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg.1’ saved [110895/110895]\n\n\n\n\nimg.shape  # 가로, 세로 픽셀, 채널(빨,녹,파..)\n\n(683, 1024, 3)\n\n\n\nplt.imshow(img)\n\n<matplotlib.image.AxesImage at 0x7fc8361704d0>"
  },
  {
    "objectID": "posts/DV_2(0914).html#이미지-자료의-이해",
    "href": "posts/DV_2(0914).html#이미지-자료의-이해",
    "title": "DV 2주차",
    "section": "이미지 자료의 이해",
    "text": "이미지 자료의 이해\n\n비밀1: 이미지는 사실 숫자들의 집합이다.\n- 예시1\n\n_img1 = np.array([0,30,90,120,150,180,210,240,255]).reshape(3,3)\n_img1\n\narray([[  0,  30,  90],\n       [120, 150, 180],\n       [210, 240, 255]])\n\n\n\nplt.imshow(_img1, cmap='gray')\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fc831d80090>\n\n\n\n\n\n- 예시2\n\n_img2 = np.array([0,20,40,60,80,100,120,140,160]).reshape(3,3)\n_img2\n\narray([[  0,  20,  40],\n       [ 60,  80, 100],\n       [120, 140, 160]])\n\n\n\nplt.imshow(_img2, cmap='gray')\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fc831e82510>\n\n\n\n\n\n- 예시3\n\n_img3=np.concatenate([_img1, _img2], axis=1)\n_img3\n\narray([[  0,  30,  90,   0,  20,  40],\n       [120, 150, 180,  60,  80, 100],\n       [210, 240, 255, 120, 140, 160]])\n\n\n\nplt.imshow(_img3, cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7fc830ec8d50>\n\n\n\n\n\n\n\n비밀2: 칼라이미지는 red + green + blue 의 조합으로 표현가능 (다른방식도 가능)\n- 예시1\n\nr=np.array([0]*25*3).reshape(5,5,3)\ng=np.array([0]*25*3).reshape(5,5,3)\nb=np.array([0]*25*3).reshape(5,5,3)\n\n\nr[:3,:3,0] = 255   \ng[:3,2:,1] = 255 \nb[2:,:,2] = 255\n\n\nplt.imshow(r)\n\n<matplotlib.image.AxesImage at 0x7fc830cd4f50>\n\n\n\n\n\n\nplt.imshow(g)\n\n<matplotlib.image.AxesImage at 0x7fc830e48650>\n\n\n\n\n\n\nplt.imshow(b)\n\n<matplotlib.image.AxesImage at 0x7fc830bd8950>\n\n\n\n\n\n\nplt.imshow(r+g+b)   # 빛의 3원색..색의 3원색\n\n<matplotlib.image.AxesImage at 0x7fc830be4f90>\n\n\n\n\n\n- 예시2: R,G,B를 같은 비율로 섞으면 무채색이 된다.\n\nr = np.array([0]*25*3).reshape(5,5,3) \ng = np.array([0]*25*3).reshape(5,5,3) \nb = np.array([0]*25*3).reshape(5,5,3) \nr[:3,:3,0] = 80   \ng[:3,2:,1] = 80\nb[2:,:,2] = 80 \n\n\nplt.imshow(r+g+b)\n\n<matplotlib.image.AxesImage at 0x7fc830bd8d10>\n\n\n\n\n\n- 예시3\n\nimg.shape\n\n(683, 1024, 3)\n\n\n\nimg_red = img * 0\nimg_green = img * 0\nimg_blue = img * 0\n\n\nimg_red[...,0] = img[...,0]\nimg_green[...,0] = img[...,1]\nimg_blue[...,0] = img[...,2]\n\n\nplt.imshow(img_red)\n\n<matplotlib.image.AxesImage at 0x7fc8309c6ed0>\n\n\n\n\n\n\nplt.imshow(img_red)"
  },
  {
    "objectID": "posts/DV_2(0914).html#히스토그램-이퀄라이제이션",
    "href": "posts/DV_2(0914).html#히스토그램-이퀄라이제이션",
    "title": "DV 2주차",
    "section": "히스토그램 이퀄라이제이션",
    "text": "히스토그램 이퀄라이제이션\n- 이미지를 rgb로 각각 분리하고 각 색깔들의 히스토그램을 그려보자.\n\nimg_red[:,:,0].reshape(-1).shape\n\n(699392,)\n\n\n\nimg_red[:,:,0].shape  # 위 699392 = 683 * 1024\n\n(683, 1024)\n\n\n\nplt.hist(img[:,:,0].reshape(-1))\n\n(array([  3691.,  56282., 235628., 170392., 120545.,  60511.,  22052.,\n         14354.,  15246.,    691.]),\n array([114. , 123.4, 132.8, 142.2, 151.6, 161. , 170.4, 179.8, 189.2,\n        198.6, 208. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nplt.hist(img_red[:,:,0].reshape(-1),bins=255)\n\n(array([1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n        1.2000e+01, 0.0000e+00, 0.0000e+00, 1.9000e+01, 0.0000e+00,\n        4.9000e+01, 0.0000e+00, 0.0000e+00, 9.3000e+01, 0.0000e+00,\n        0.0000e+00, 2.2000e+02, 0.0000e+00, 4.8800e+02, 0.0000e+00,\n        0.0000e+00, 1.0610e+03, 0.0000e+00, 0.0000e+00, 1.7470e+03,\n        0.0000e+00, 0.0000e+00, 2.1600e+03, 0.0000e+00, 2.7180e+03,\n        0.0000e+00, 0.0000e+00, 3.2590e+03, 0.0000e+00, 0.0000e+00,\n        4.0390e+03, 0.0000e+00, 5.1080e+03, 0.0000e+00, 0.0000e+00,\n        6.3950e+03, 0.0000e+00, 0.0000e+00, 8.4630e+03, 0.0000e+00,\n        0.0000e+00, 1.0610e+04, 0.0000e+00, 1.3530e+04, 0.0000e+00,\n        0.0000e+00, 1.6115e+04, 0.0000e+00, 0.0000e+00, 1.9125e+04,\n        0.0000e+00, 2.2186e+04, 0.0000e+00, 0.0000e+00, 2.5696e+04,\n        0.0000e+00, 0.0000e+00, 2.8701e+04, 0.0000e+00, 0.0000e+00,\n        2.8324e+04, 0.0000e+00, 2.5759e+04, 0.0000e+00, 0.0000e+00,\n        2.4369e+04, 0.0000e+00, 0.0000e+00, 2.3578e+04, 0.0000e+00,\n        2.1775e+04, 0.0000e+00, 0.0000e+00, 2.0385e+04, 0.0000e+00,\n        0.0000e+00, 1.9839e+04, 0.0000e+00, 0.0000e+00, 1.9781e+04,\n        0.0000e+00, 1.9445e+04, 0.0000e+00, 0.0000e+00, 1.8856e+04,\n        0.0000e+00, 0.0000e+00, 1.8457e+04, 0.0000e+00, 1.7906e+04,\n        0.0000e+00, 0.0000e+00, 1.7917e+04, 0.0000e+00, 0.0000e+00,\n        1.7806e+04, 0.0000e+00, 0.0000e+00, 1.8485e+04, 0.0000e+00,\n        1.7680e+04, 0.0000e+00, 0.0000e+00, 1.5799e+04, 0.0000e+00,\n        0.0000e+00, 1.4163e+04, 0.0000e+00, 1.2812e+04, 0.0000e+00,\n        0.0000e+00, 1.1576e+04, 0.0000e+00, 0.0000e+00, 1.0751e+04,\n        0.0000e+00, 0.0000e+00, 9.8990e+03, 0.0000e+00, 9.3800e+03,\n        0.0000e+00, 0.0000e+00, 8.8630e+03, 0.0000e+00, 0.0000e+00,\n        8.3990e+03, 0.0000e+00, 7.4040e+03, 0.0000e+00, 0.0000e+00,\n        6.4030e+03, 0.0000e+00, 0.0000e+00, 5.9110e+03, 0.0000e+00,\n        0.0000e+00, 5.5910e+03, 0.0000e+00, 5.1500e+03, 0.0000e+00,\n        0.0000e+00, 4.6100e+03, 0.0000e+00, 0.0000e+00, 4.3200e+03,\n        0.0000e+00, 3.8600e+03, 0.0000e+00, 0.0000e+00, 3.6160e+03,\n        0.0000e+00, 0.0000e+00, 3.4300e+03, 0.0000e+00, 0.0000e+00,\n        3.0630e+03, 0.0000e+00, 2.6490e+03, 0.0000e+00, 0.0000e+00,\n        2.2130e+03, 0.0000e+00, 0.0000e+00, 2.0460e+03, 0.0000e+00,\n        1.8590e+03, 0.0000e+00, 0.0000e+00, 1.6920e+03, 0.0000e+00,\n        0.0000e+00, 1.4840e+03, 0.0000e+00, 0.0000e+00, 1.3620e+03,\n        0.0000e+00, 1.2900e+03, 0.0000e+00, 0.0000e+00, 1.1530e+03,\n        0.0000e+00, 0.0000e+00, 1.2320e+03, 0.0000e+00, 1.3000e+03,\n        0.0000e+00, 0.0000e+00, 1.5200e+03, 0.0000e+00, 0.0000e+00,\n        1.3840e+03, 0.0000e+00, 0.0000e+00, 1.5270e+03, 0.0000e+00,\n        1.7350e+03, 0.0000e+00, 0.0000e+00, 1.8510e+03, 0.0000e+00,\n        0.0000e+00, 1.5320e+03, 0.0000e+00, 1.3590e+03, 0.0000e+00,\n        0.0000e+00, 1.4140e+03, 0.0000e+00, 0.0000e+00, 1.4830e+03,\n        0.0000e+00, 0.0000e+00, 1.5410e+03, 0.0000e+00, 1.5950e+03,\n        0.0000e+00, 0.0000e+00, 2.3690e+03, 0.0000e+00, 0.0000e+00,\n        2.8100e+03, 0.0000e+00, 1.1430e+03, 0.0000e+00, 0.0000e+00,\n        4.2000e+02, 0.0000e+00, 0.0000e+00, 1.2800e+02, 0.0000e+00,\n        0.0000e+00, 5.6000e+01, 0.0000e+00, 4.1000e+01, 0.0000e+00,\n        0.0000e+00, 1.8000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+01,\n        0.0000e+00, 1.0000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+00,\n        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00]),\n array([114.        , 114.36862745, 114.7372549 , 115.10588235,\n        115.4745098 , 115.84313725, 116.21176471, 116.58039216,\n        116.94901961, 117.31764706, 117.68627451, 118.05490196,\n        118.42352941, 118.79215686, 119.16078431, 119.52941176,\n        119.89803922, 120.26666667, 120.63529412, 121.00392157,\n        121.37254902, 121.74117647, 122.10980392, 122.47843137,\n        122.84705882, 123.21568627, 123.58431373, 123.95294118,\n        124.32156863, 124.69019608, 125.05882353, 125.42745098,\n        125.79607843, 126.16470588, 126.53333333, 126.90196078,\n        127.27058824, 127.63921569, 128.00784314, 128.37647059,\n        128.74509804, 129.11372549, 129.48235294, 129.85098039,\n        130.21960784, 130.58823529, 130.95686275, 131.3254902 ,\n        131.69411765, 132.0627451 , 132.43137255, 132.8       ,\n        133.16862745, 133.5372549 , 133.90588235, 134.2745098 ,\n        134.64313725, 135.01176471, 135.38039216, 135.74901961,\n        136.11764706, 136.48627451, 136.85490196, 137.22352941,\n        137.59215686, 137.96078431, 138.32941176, 138.69803922,\n        139.06666667, 139.43529412, 139.80392157, 140.17254902,\n        140.54117647, 140.90980392, 141.27843137, 141.64705882,\n        142.01568627, 142.38431373, 142.75294118, 143.12156863,\n        143.49019608, 143.85882353, 144.22745098, 144.59607843,\n        144.96470588, 145.33333333, 145.70196078, 146.07058824,\n        146.43921569, 146.80784314, 147.17647059, 147.54509804,\n        147.91372549, 148.28235294, 148.65098039, 149.01960784,\n        149.38823529, 149.75686275, 150.1254902 , 150.49411765,\n        150.8627451 , 151.23137255, 151.6       , 151.96862745,\n        152.3372549 , 152.70588235, 153.0745098 , 153.44313725,\n        153.81176471, 154.18039216, 154.54901961, 154.91764706,\n        155.28627451, 155.65490196, 156.02352941, 156.39215686,\n        156.76078431, 157.12941176, 157.49803922, 157.86666667,\n        158.23529412, 158.60392157, 158.97254902, 159.34117647,\n        159.70980392, 160.07843137, 160.44705882, 160.81568627,\n        161.18431373, 161.55294118, 161.92156863, 162.29019608,\n        162.65882353, 163.02745098, 163.39607843, 163.76470588,\n        164.13333333, 164.50196078, 164.87058824, 165.23921569,\n        165.60784314, 165.97647059, 166.34509804, 166.71372549,\n        167.08235294, 167.45098039, 167.81960784, 168.18823529,\n        168.55686275, 168.9254902 , 169.29411765, 169.6627451 ,\n        170.03137255, 170.4       , 170.76862745, 171.1372549 ,\n        171.50588235, 171.8745098 , 172.24313725, 172.61176471,\n        172.98039216, 173.34901961, 173.71764706, 174.08627451,\n        174.45490196, 174.82352941, 175.19215686, 175.56078431,\n        175.92941176, 176.29803922, 176.66666667, 177.03529412,\n        177.40392157, 177.77254902, 178.14117647, 178.50980392,\n        178.87843137, 179.24705882, 179.61568627, 179.98431373,\n        180.35294118, 180.72156863, 181.09019608, 181.45882353,\n        181.82745098, 182.19607843, 182.56470588, 182.93333333,\n        183.30196078, 183.67058824, 184.03921569, 184.40784314,\n        184.77647059, 185.14509804, 185.51372549, 185.88235294,\n        186.25098039, 186.61960784, 186.98823529, 187.35686275,\n        187.7254902 , 188.09411765, 188.4627451 , 188.83137255,\n        189.2       , 189.56862745, 189.9372549 , 190.30588235,\n        190.6745098 , 191.04313725, 191.41176471, 191.78039216,\n        192.14901961, 192.51764706, 192.88627451, 193.25490196,\n        193.62352941, 193.99215686, 194.36078431, 194.72941176,\n        195.09803922, 195.46666667, 195.83529412, 196.20392157,\n        196.57254902, 196.94117647, 197.30980392, 197.67843137,\n        198.04705882, 198.41568627, 198.78431373, 199.15294118,\n        199.52156863, 199.89019608, 200.25882353, 200.62745098,\n        200.99607843, 201.36470588, 201.73333333, 202.10196078,\n        202.47058824, 202.83921569, 203.20784314, 203.57647059,\n        203.94509804, 204.31372549, 204.68235294, 205.05098039,\n        205.41960784, 205.78823529, 206.15686275, 206.5254902 ,\n        206.89411765, 207.2627451 , 207.63137255, 208.        ]),\n <BarContainer object of 255 artists>)\n\n\n\n\n\n\n히스토그램 그림1\n\n\n_fig = plt.hist(img_red[:,:,0].reshape(-1),bins=255, range=[0,255])\n# 위의 숫자 보기 싫으니까 걍 _fig로 받으면 그림만 나온다.\n# 빨간색 말고 그린, 블루도 다 같은 모양의 그림이 나옴\n\n\n\n\n\n히스토그램 그림 2\n120~200 사이에 값이 몰려있음\n그런데 컴퓨터가 표현가능한 색은 0~244..\n만약에 120-200까지의 분포된 모양은 그대로 유지하면서 range를 0-255까지 늘린다면?\n\n- 분포의 모양은 대략적으로 유지하면서 값을 퍼트리자\n\nimg2_red = cv2.equalizeHist(img[...,0])\n\n\nplt.hist(img2_red.reshape(-1))\n\n(array([59973., 57426., 82721., 73706., 61999., 76539., 72114., 72030.,\n        72601., 70283.]),\n array([  0. ,  25.5,  51. ,  76.5, 102. , 127.5, 153. , 178.5, 204. ,\n        229.5, 255. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n히스토그램이 평평해졌네?\n\n_fig=plt.hist(img2_red.reshape(-1), bins=255, range=(0,255))\n\n\n\n\n- red말고 다른채널에도 이와 같은 변환을 정의한다면?\n\nimg2=np.stack([img2_red,img2_red,img2_red],axis=-1)   # 색깔 3개 합치기 위해서\n\n\nimg2.shape\n\n(683, 1024, 3)\n\n\n\nplt.imshow(img2)\n\n<matplotlib.image.AxesImage at 0x7fc8300ea750>\n\n\n\n\n\n\nplt.imshow(img) #원래이미지\n\n<matplotlib.image.AxesImage at 0x7fc83010db90>\n\n\n\n\n\n\nplt.imshow(np.concatenate([img,img2],axis=1))\n\n<matplotlib.image.AxesImage at 0x7fc8301308d0>"
  },
  {
    "objectID": "posts/DV_2(0914).html#히스토그램-이퀄라이제이션-흑백버전",
    "href": "posts/DV_2(0914).html#히스토그램-이퀄라이제이션-흑백버전",
    "title": "DV 2주차",
    "section": "히스토그램 이퀄라이제이션 (흑백버전)",
    "text": "히스토그램 이퀄라이제이션 (흑백버전)\n\nimg_black =  cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg',0)\n# 컴마하고 0하면 흑밸처리된다\n\n\nimg_black.shape\n\n(683, 1024)\n\n\n\nimg_black2 = cv2.equalizeHist(img_black)\n\n\nplt.imshow(np.concatenate([img_black,img_black2],axis=1),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7fc830044090>"
  },
  {
    "objectID": "posts/DV_2(0914).html#숙제",
    "href": "posts/DV_2(0914).html#숙제",
    "title": "DV 2주차",
    "section": "숙제",
    "text": "숙제\nHE(Histogram Equalization)을 이용하여 아래주소에 저장된 이미지의 명암비를 보존하라\nhttps://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png\n\n!wget https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png\nhw = cv2.imread('hw_img.png')\n\n--2023-02-22 17:18:34--  https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 120618 (118K) [image/png]\nSaving to: ‘hw_img.png.2’\n\nhw_img.png.2        100%[===================>] 117.79K  --.-KB/s    in 0.01s   \n\n2023-02-22 17:18:34 (10.4 MB/s) - ‘hw_img.png.2’ saved [120618/120618]\n\n\n\n\nhw.shape\n\n(531, 468, 3)\n\n\n\nhw_2 = cv2.equalizeHist(hw[...,0])\n\n\nhw_2.shape\n\n(531, 468)\n\n\n\nhw2=np.stack([hw_2,hw_2,hw_2],axis=-1)\n\n\nplt.imshow(hw2)\n\n<matplotlib.image.AxesImage at 0x7fc82bd948d0>\n\n\n\n\n\n\nplt.imshow(np.concatenate([hw,hw2],axis=1))\n\n<matplotlib.image.AxesImage at 0x7fc86b573d10>"
  },
  {
    "objectID": "posts/DV_12(1121).html",
    "href": "posts/DV_12(1121).html",
    "title": "DV 12주차",
    "section": "",
    "text": "!pip install folium\n\nCollecting folium\n  Downloading folium-0.14.0-py2.py3-none-any.whl (102 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.3/102.3 kB 5.6 MB/s eta 0:00:00\nRequirement already satisfied: requests in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from folium) (2.28.2)\nCollecting branca>=0.6.0\n  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: jinja2>=2.9 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from folium) (3.1.2)\nRequirement already satisfied: numpy in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from folium) (1.21.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jinja2>=2.9->folium) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->folium) (2022.12.7)\nInstalling collected packages: branca, folium\nSuccessfully installed branca-0.6.0 folium-0.14.0\n\n\n\nimport numpy as np\nimport pandas as pd\nimport folium\nimport folium.plugins"
  },
  {
    "objectID": "posts/DV_12(1121).html#folium.map",
    "href": "posts/DV_12(1121).html#folium.map",
    "title": "DV 12주차",
    "section": "folium.Map()",
    "text": "folium.Map()\n- global view\n\nfolium.Map(scrollWheelZoom=False)\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 줌스크롤을 False 시키는 방법: scrollWheelZoom=False\n- 이 옵션을 확인하려면? (1) 도움말 (2) folium 공식홈페이지 (3) Leaflet 공식홈페이지\n\nfolium.Map?\n\n\nInit signature:\nfolium.Map(\n    location=None,\n    width='100%',\n    height='100%',\n    left='0%',\n    top='0%',\n    position='relative',\n    tiles='OpenStreetMap',\n    attr=None,\n    min_zoom=0,\n    max_zoom=18,\n    zoom_start=10,\n    min_lat=-90,\n    max_lat=90,\n    min_lon=-180,\n    max_lon=180,\n    max_bounds=False,\n    crs='EPSG3857',\n    control_scale=False,\n    prefer_canvas=False,\n    no_touch=False,\n    disable_3d=False,\n    png_enabled=False,\n    zoom_control=True,\n    **kwargs,\n)\nDocstring:     \nCreate a Map with Folium and Leaflet.js\nGenerate a base map of given width and height with either default\ntilesets or a custom tileset URL. The following tilesets are built-in\nto Folium. Pass any of the following to the \"tiles\" keyword:\n    - \"OpenStreetMap\"\n    - \"Mapbox Bright\" (Limited levels of zoom for free tiles)\n    - \"Mapbox Control Room\" (Limited levels of zoom for free tiles)\n    - \"Stamen\" (Terrain, Toner, and Watercolor)\n    - \"Cloudmade\" (Must pass API key)\n    - \"Mapbox\" (Must pass API key)\n    - \"CartoDB\" (positron and dark_matter)\nYou can pass a custom tileset to Folium by passing a\n:class:`xyzservices.TileProvider` or a Leaflet-style\nURL to the tiles parameter: ``http://{s}.yourtiles.com/{z}/{x}/{y}.png``.\nYou can find a list of free tile providers here:\n``http://leaflet-extras.github.io/leaflet-providers/preview/``.\nBe sure to check their terms and conditions and to provide attribution\nwith the `attr` keyword.\nParameters\n----------\nlocation: tuple or list, default None\n    Latitude and Longitude of Map (Northing, Easting).\nwidth: pixel int or percentage string (default: '100%')\n    Width of the map.\nheight: pixel int or percentage string (default: '100%')\n    Height of the map.\ntiles: str or TileLayer or :class:`xyzservices.TileProvider`, default 'OpenStreetMap'\n    Map tileset to use. Can choose from a list of built-in tiles,\n    pass a :class:`xyzservices.TileProvider`,\n    pass a custom URL, pass a TileLayer object,\n    or pass `None` to create a map without tiles.\n    For more advanced tile layer options, use the `TileLayer` class.\nmin_zoom: int, default 0\n    Minimum allowed zoom level for the tile layer that is created.\nmax_zoom: int, default 18\n    Maximum allowed zoom level for the tile layer that is created.\nzoom_start: int, default 10\n    Initial zoom level for the map.\nattr: string, default None\n    Map tile attribution; only required if passing custom tile URL.\ncrs : str, default 'EPSG3857'\n    Defines coordinate reference systems for projecting geographical points\n    into pixel (screen) coordinates and back.\n    You can use Leaflet's values :\n    * EPSG3857 : The most common CRS for online maps, used by almost all\n    free and commercial tile providers. Uses Spherical Mercator projection.\n    Set in by default in Map's crs option.\n    * EPSG4326 : A common CRS among GIS enthusiasts.\n    Uses simple Equirectangular projection.\n    * EPSG3395 : Rarely used by some commercial tile providers.\n    Uses Elliptical Mercator projection.\n    * Simple : A simple CRS that maps longitude and latitude into\n    x and y directly. May be used for maps of flat surfaces\n    (e.g. game maps). Note that the y axis should still be inverted\n    (going from bottom to top).\ncontrol_scale : bool, default False\n    Whether to add a control scale on the map.\nprefer_canvas : bool, default False\n    Forces Leaflet to use the Canvas back-end (if available) for\n    vector layers instead of SVG. This can increase performance\n    considerably in some cases (e.g. many thousands of circle\n    markers on the map).\nno_touch : bool, default False\n    Forces Leaflet to not use touch events even if it detects them.\ndisable_3d : bool, default False\n    Forces Leaflet to not use hardware-accelerated CSS 3D\n    transforms for positioning (which may cause glitches in some\n    rare environments) even if they're supported.\nzoom_control : bool, default True\n    Display zoom controls on the map.\n**kwargs\n    Additional keyword arguments are passed to Leaflets Map class:\n    https://leafletjs.com/reference.html#map\nReturns\n-------\nFolium Map Object\nExamples\n--------\n>>> m = folium.Map(location=[45.523, -122.675], width=750, height=500)\n>>> m = folium.Map(location=[45.523, -122.675], tiles=\"cartodb positron\")\n>>> m = folium.Map(\n...     location=[45.523, -122.675],\n...     zoom_start=2,\n...     tiles=\"https://api.mapbox.com/v4/mapbox.streets/{z}/{x}/{y}.png?access_token=mytoken\",\n...     attr=\"Mapbox attribution\",\n... )\nFile:           ~/anaconda3/envs/py37/lib/python3.7/site-packages/folium/folium.py\nType:           type\nSubclasses:     \n\n\n\n\n- location과 scale을 조정하는 방법\n\n35.8475, 127.1305 # 전북대 자연대 본관\n35.8468, 127.1294 # 전북대 분수대\n\n\nfolium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305],\n          zoom_start=20)\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nfolium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305], #자연대본관이 센터\n          zoom_start=15)\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- tiles 옵션을 주어서 지도의 외형을 변경하여 보자.\n\ntiles=“OpenStreetMap”\ntiles=“Stamen Terrain”, tiles=“Stamen Toner”, tiles=“Stamen Watercolor”\ntiles=\"CartoDB positron\", tiles=“CartoDB dark_matter”\n\n\nfolium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305],\n          zoom_start=15,\n          tiles=\"Stamen Terrain\")\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_12(1121).html#folium.marker",
    "href": "posts/DV_12(1121).html#folium.marker",
    "title": "DV 12주차",
    "section": "folium.Marker()",
    "text": "folium.Marker()\n- 마커생성\n\njbnu = folium.Marker(\n    location = [35.8475, 127.1305]\n)\n\nfolium.Marker 는 클래스\n\nm = folium.Map(scrollWheelZoom=False,\n          location = [35.8475, 127.1305],\n          zoom_start=14,\n          tiles=\"CartoDB positron\")\n\nfolium.Map 도 클래스\n\njbnu.add_to(m)\n\n<folium.map.Marker at 0x7f3e244f9510>\n\n\n\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nhome = folium.Marker(\n    location = [35.8368, 127.1118] # 서신동\n)\n\n\nhome.add_to(m)\n\n<folium.map.Marker at 0x7f3e244b1ed0>\n\n\n\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n마커에 팝업내용 추가\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    popup = \"JBNU\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"HOME\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 아이콘 변경\n- folium.Marker()에서 icon=folium.Icon(color=‘red’,icon=‘university’,prefix=‘fa’) 와 같은 식으로 옵션을 추가\n\nicon=‘university’ 대신에 `street-view’,‘tree’,‘plane’,‘bell’ 등을 추가할 수 있음.\n아이콘들은 여기 참고. ’glyphicon glyphicon-” 부분을 제외한 문자열을 넣으면 된다.\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = \"JBNU\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"HOME\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(1)\n- “JBNU” 대신에 \"<h2> JBNU </h2><br>\"\n- “HOME” 대신에 \"<h5> HOME </h5><br>\"\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = \"<h2> JBNU </h2><br>\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(2)\n\n데이터프레임을 HTML로 바꾸어서 넣기\n\n\n_df=pd.DataFrame({'year':[2019,2020,2021,2022],'students':[35,30,33,26]})\n_df\n\n\n\n\n\n  \n    \n      \n      year\n      students\n    \n  \n  \n    \n      0\n      2019\n      35\n    \n    \n      1\n      2020\n      30\n    \n    \n      2\n      2021\n      33\n    \n    \n      3\n      2022\n      26\n    \n  \n\n\n\n\n\n_df.to_html()\n\n\n\n\n\n\n\n\n\n\n\n\nyear\n\n\n\nstudents\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\n2019\n\n\n\n35\n\n\n\n\n\n\n\n1\n\n\n\n2020\n\n\n\n30\n\n\n\n\n\n\n\n2\n\n\n\n2021\n\n\n\n33\n\n\n\n\n\n\n\n3\n\n\n\n2022\n\n\n\n26\n\n\n\n\n\n\n\n\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _df.to_html()\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 서신동\n    popup = \"<h5> HOME </h5><br>\" + _df.to_html(),\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(3)\n\n데이터프레임을 HTML로 바꾸어서 넣어보자.\n팝업시 크기를 조절할 수 있게 해보자. (folium.IFrame, folium.Popup 이용)\n\n\n_iframe = folium.IFrame('<h2> JBNU </h2><br>'+_df.to_html(),width=150,height=200)\n_popup = folium.Popup(_iframe)\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _popup\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n마커의 팝업내용 HTML넣기(4)\n\n논리구조상 HTML 오브젝트를 아무거나 넣을 수 있음 \\(\\to\\) 그림도 넣을 수 있을까?\n그림파일을 HTML로 바꾸어서 넣어보자.\n\n\nimport matplotlib.pyplot as plt\n\n\n_df.plot.line(x='year',y='students')\nfig = plt.gcf()\n\n\n\n\n\nfig.savefig?\n\n\nSignature: fig.savefig(fname, *, transparent=None, **kwargs)\nDocstring:\nSave the current figure.\nCall signature::\n  savefig(fname, *, dpi='figure', format=None, metadata=None,\n          bbox_inches=None, pad_inches=0.1,\n          facecolor='auto', edgecolor='auto',\n          backend=None, **kwargs\n         )\nThe available output formats depend on the backend being used.\nParameters\n----------\nfname : str or path-like or binary file-like\n    A path, or a Python file-like object, or\n    possibly some backend-dependent object such as\n    `matplotlib.backends.backend_pdf.PdfPages`.\n    If *format* is set, it determines the output format, and the file\n    is saved as *fname*.  Note that *fname* is used verbatim, and there\n    is no attempt to make the extension, if any, of *fname* match\n    *format*, and no extension is appended.\n    If *format* is not set, then the format is inferred from the\n    extension of *fname*, if there is one.  If *format* is not\n    set and *fname* has no extension, then the file is saved with\n    :rc:`savefig.format` and the appropriate extension is appended to\n    *fname*.\nOther Parameters\n----------------\ndpi : float or 'figure', default: :rc:`savefig.dpi`\n    The resolution in dots per inch.  If 'figure', use the figure's\n    dpi value.\nformat : str\n    The file format, e.g. 'png', 'pdf', 'svg', ... The behavior when\n    this is unset is documented under *fname*.\nmetadata : dict, optional\n    Key/value pairs to store in the image metadata. The supported keys\n    and defaults depend on the image format and backend:\n    - 'png' with Agg backend: See the parameter ``metadata`` of\n      `~.FigureCanvasAgg.print_png`.\n    - 'pdf' with pdf backend: See the parameter ``metadata`` of\n      `~.backend_pdf.PdfPages`.\n    - 'svg' with svg backend: See the parameter ``metadata`` of\n      `~.FigureCanvasSVG.print_svg`.\n    - 'eps' and 'ps' with PS backend: Only 'Creator' is supported.\nbbox_inches : str or `.Bbox`, default: :rc:`savefig.bbox`\n    Bounding box in inches: only the given portion of the figure is\n    saved.  If 'tight', try to figure out the tight bbox of the figure.\npad_inches : float, default: :rc:`savefig.pad_inches`\n    Amount of padding around the figure when bbox_inches is 'tight'.\nfacecolor : color or 'auto', default: :rc:`savefig.facecolor`\n    The facecolor of the figure.  If 'auto', use the current figure\n    facecolor.\nedgecolor : color or 'auto', default: :rc:`savefig.edgecolor`\n    The edgecolor of the figure.  If 'auto', use the current figure\n    edgecolor.\nbackend : str, optional\n    Use a non-default backend to render the file, e.g. to render a\n    png file with the \"cairo\" backend rather than the default \"agg\",\n    or a pdf file with the \"pgf\" backend rather than the default\n    \"pdf\".  Note that the default backend is normally sufficient.  See\n    :ref:`the-builtin-backends` for a list of valid backends for each\n    file format.  Custom backends can be referenced as \"module://...\".\norientation : {'landscape', 'portrait'}\n    Currently only supported by the postscript backend.\npapertype : str\n    One of 'letter', 'legal', 'executive', 'ledger', 'a0' through\n    'a10', 'b0' through 'b10'. Only supported for postscript\n    output.\ntransparent : bool\n    If *True*, the Axes patches will all be transparent; the\n    Figure patch will also be transparent unless *facecolor*\n    and/or *edgecolor* are specified via kwargs.\n    If *False* has no effect and the color of the Axes and\n    Figure patches are unchanged (unless the Figure patch\n    is specified via the *facecolor* and/or *edgecolor* keyword\n    arguments in which case those colors are used).\n    The transparency of these patches will be restored to their\n    original values upon exit of this function.\n    This is useful, for example, for displaying\n    a plot on top of a colored background on a web page.\nbbox_extra_artists : list of `~matplotlib.artist.Artist`, optional\n    A list of extra artists that will be considered when the\n    tight bbox is calculated.\npil_kwargs : dict, optional\n    Additional keyword arguments that are passed to\n    `PIL.Image.Image.save` when saving the figure.\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/figure.py\nType:      method\n\n\n\n\n\nfig.savefig('test.png')\n\n\n저장한 그림파일을 HTML로 바꾸기 위해서 base64 가져오기\n\n\nimport base64\n\n\n_encoded = base64.b64encode(open('test.png','rb').read())\n_myhtml = '<img src=\"data:image/png;base64,{}\">'.format\n_iframe = folium.IFrame(_myhtml(_encoded.decode('UTF-8')),width=400,height=300)\n_popup = folium.Popup(_iframe)\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _popup\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_12(1121).html#folium.circlemarker",
    "href": "posts/DV_12(1121).html#folium.circlemarker",
    "title": "DV 12주차",
    "section": "folium.CircleMarker()",
    "text": "folium.CircleMarker()\n- 서클마커 생성\n\nfolium.CircleMarker?\n\n\nInit signature:\nfolium.CircleMarker(\n    location=None,\n    radius=10,\n    popup=None,\n    tooltip=None,\n    **kwargs,\n)\nDocstring:     \nA circle of a fixed size with radius specified in pixels.\nSee :func:`folium.vector_layers.path_options` for the `Path` options.\nParameters\n----------\nlocation: tuple[float, float]\n    Latitude and Longitude pair (Northing, Easting)\npopup: string or folium.Popup, default None\n    Input text or visualization for object displayed when clicking.\ntooltip: str or folium.Tooltip, default None\n    Display a text when hovering over the object.\nradius: float, default 10\n    Radius of the circle marker, in pixels.\n**kwargs\n    Other valid (possibly inherited) options. See:\n    https://leafletjs.com/reference.html#circlemarker\nFile:           ~/anaconda3/envs/py37/lib/python3.7/site-packages/folium/vector_layers.py\nType:           type\nSubclasses:     \n\n\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\"\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n서클마커의 색상 및 크기 변경\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\",\n    radius = 20,\n    color='red'\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n서클마커 테두리 삭제 및 fill\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\",\n    radius = 20,\n    color=None,\n    fill=True,\n    fill_color='blue'\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_12(1121).html#folium.plugins.heatmap",
    "href": "posts/DV_12(1121).html#folium.plugins.heatmap",
    "title": "DV 12주차",
    "section": "folium.plugins.HeatMap()",
    "text": "folium.plugins.HeatMap()\n- Heatmap은 폴리움에서 데이터 시각화를 하기에 적합한 기본도구임\nhetmap : 변수가 nx3(or2)의 형태로 저장되어야함. 위치정보, 색깔\n\ndata = np.random.multivariate_normal(mean=[28,77],cov=[[5,0],[0,5]],size=30)\ndata\n\narray([[26.90395013, 76.67048321],\n       [25.8497742 , 78.11586853],\n       [25.9457691 , 76.38304552],\n       [26.92593912, 77.28038385],\n       [25.5991387 , 73.78185956],\n       [27.3230456 , 81.43696204],\n       [29.148638  , 77.10700642],\n       [30.67602261, 77.54824301],\n       [28.54287701, 75.90813103],\n       [27.58172922, 74.17403175],\n       [30.49801026, 75.01214148],\n       [29.13382765, 79.22643318],\n       [28.01915992, 77.16029599],\n       [26.77686428, 72.68952163],\n       [26.75485743, 73.9484101 ],\n       [23.98161607, 70.57320764],\n       [28.34373122, 76.12772879],\n       [27.59842471, 79.05475651],\n       [30.44317469, 74.30593407],\n       [30.37148679, 77.59831078],\n       [30.85907885, 79.21582417],\n       [27.09252368, 78.40493264],\n       [32.42220863, 76.50265661],\n       [25.28967556, 79.93875523],\n       [25.23525815, 75.94602496],\n       [29.14062166, 76.81364822],\n       [26.4371104 , 78.74836501],\n       [24.8546951 , 76.4959588 ],\n       [29.65245395, 78.08582716],\n       [24.8009876 , 79.0652865 ]])\n\n\n\nfolium.plugins.HeatMap?\n\n\nInit signature:\nfolium.plugins.HeatMap(\n    data,\n    name=None,\n    min_opacity=0.5,\n    max_zoom=18,\n    radius=25,\n    blur=15,\n    gradient=None,\n    overlay=True,\n    control=True,\n    show=True,\n    **kwargs,\n)\nDocstring:     \nCreate a Heatmap layer\nParameters\n----------\ndata : list of points of the form [lat, lng] or [lat, lng, weight]\n    The points you want to plot.\n    You can also provide a numpy.array of shape (n,2) or (n,3).\nname : string, default None\n    The name of the Layer, as it will appear in LayerControls.\nmin_opacity  : default 1.\n    The minimum opacity the heat will start at.\nmax_zoom : default 18\n    Zoom level where the points reach maximum intensity (as intensity\n    scales with zoom), equals maxZoom of the map by default\nradius : int, default 25\n    Radius of each \"point\" of the heatmap\nblur : int, default 15\n    Amount of blur\ngradient : dict, default None\n    Color gradient config. e.g. {0.4: 'blue', 0.65: 'lime', 1: 'red'}\noverlay : bool, default True\n    Adds the layer as an optional overlay (True) or the base layer (False).\ncontrol : bool, default True\n    Whether the Layer will be included in LayerControls.\nshow: bool, default True\n    Whether the layer will be shown on opening (only for overlays).\nFile:           ~/anaconda3/envs/py37/lib/python3.7/site-packages/folium/plugins/heat_map.py\nType:           type\nSubclasses:     \n\n\n\n\n\nfolium.plugins.HeatMap(data)\n\n<folium.plugins.heat_map.HeatMap at 0x7f3e15a553d0>\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMap(data).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMap(data,\n    radius=11\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_12(1121).html#folium.plugins.heatmapwithtime",
    "href": "posts/DV_12(1121).html#folium.plugins.heatmapwithtime",
    "title": "DV 12주차",
    "section": "folium.plugins.HeatMapWithTime()",
    "text": "folium.plugins.HeatMapWithTime()\n\ndata1 = np.random.multivariate_normal(mean=[28,77],cov=[[5,0],[0,5]],size=20)\ndata2 = np.random.multivariate_normal(mean=[25,80],cov=[[5,0],[0,5]],size=20)\ndata3 = np.random.multivariate_normal(mean=[31,70],cov=[[5,0],[0,5]],size=20)\ndata = np.array([data1,data2,data3])\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMapWithTime(\n    data.tolist(),\n    index=['t1','t2','t3'], # time_index \n    radius=15,\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_12(1121).html#예제-earthquakes",
    "href": "posts/DV_12(1121).html#예제-earthquakes",
    "title": "DV 12주차",
    "section": "예제: earthquakes",
    "text": "예제: earthquakes\n\nStep1: Pandas 정리\n\ndf=pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n    \n  \n\n23412 rows × 4 columns\n\n\n\n\ndf.Date\n\n0        01/02/1965\n1        01/04/1965\n2        01/05/1965\n3        01/08/1965\n4        01/09/1965\n            ...    \n23407    12/28/2016\n23408    12/28/2016\n23409    12/28/2016\n23410    12/29/2016\n23411    12/30/2016\nName: Date, Length: 23412, dtype: object\n\n\n\n' 01/02/1965'.split('/')[-1]\n\n'1965'\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n      1965\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n      1965\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n      1965\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n      1965\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n      1965\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n      2016\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n      2016\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n      2016\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n      2016\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n      2016\n    \n  \n\n23412 rows × 5 columns\n\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date))).Year.unique()\n\narray(['1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972',\n       '1973', '1974', '1975', '1975-02-23T02:58:41.000Z', '1976', '1977',\n       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985',\n       '1985-04-28T02:53:41.530Z', '1986', '1987', '1988', '1989', '1990',\n       '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998',\n       '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006',\n       '2007', '2008', '2009', '2010', '2011', '2011-03-13T02:23:34.520Z',\n       '2012', '2013', '2014', '2015', '2016'], dtype=object)\n\n\n\n'1975-02-23T02:58:41.000Z'.split('-')[0]\n\n'1975'\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\\\n.assign(Year = lambda df: list(map(lambda x: x.split('-')[0], df.Year)))\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n      Year\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n      1965\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n      1965\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n      1965\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n      1965\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n      1965\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n      2016\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n      2016\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n      2016\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n      2016\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n      2016\n    \n  \n\n23412 rows × 5 columns\n\n\n\n\ndf.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\\\n.assign(Year = lambda df: list(map(lambda x: x.split('-')[0], df.Year))).Year.unique()\n\narray(['1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972',\n       '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980',\n       '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988',\n       '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996',\n       '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012',\n       '2013', '2014', '2015', '2016'], dtype=object)\n\n\n\nlst =[ \n    df.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\\\n    .assign(Year = lambda df: list(map(lambda x: x.split('-')[0] ,df.Year)))\\\n    .groupby('Year')\\\n    .pipe(list)[_year][1]\\\n    .loc[:,['Latitude','Longitude']]\\\n    .pipe(np.array).tolist()\n    \n    for _year in range(2016-1965+1) \n]\n\n\n\nStep2: folium\n\nm=folium.Map(scrollWheelZoom=False)\nfolium.plugins.HeatMapWithTime(\n    lst,\n    radius=5,\n    index=list(range(1965,2017)) \n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/DV_12(1121).html#세계지도-그리기",
    "href": "posts/DV_12(1121).html#세계지도-그리기",
    "title": "DV 12주차",
    "section": "세계지도 그리기",
    "text": "세계지도 그리기\n\npx.scatter_geo()\n\n\n                                                \n\n\n\npx.scatter_geo(projection='natural earth') #동그랗게"
  },
  {
    "objectID": "posts/DV_12(1121).html#세계지도-버블",
    "href": "posts/DV_12(1121).html#세계지도-버블",
    "title": "DV 12주차",
    "section": "세계지도 + 버블",
    "text": "세계지도 + 버블\n- 예시1\n\ndf = pd.DataFrame({'lat':[37,0], 'lon':[127,0], 'size':[100,5]})\ndf\n\n\n\n\n\n  \n    \n      \n      lat\n      lon\n      size\n    \n  \n  \n    \n      0\n      37\n      127\n      100\n    \n    \n      1\n      0\n      0\n      5\n    \n  \n\n\n\n\n\npx.scatter_geo(\n    data_frame=df,\n    lat = 'lat',\n    lon = 'lon',\n    size = 'size'\n)\n\n\n                                                \n\n\n- 예시2\n\ndf= pd.DataFrame({'code':['KOR','JPN'], 'size':[100,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      code\n      size\n    \n  \n  \n    \n      0\n      KOR\n      100\n    \n    \n      1\n      JPN\n      30\n    \n  \n\n\n\n\n\npx.scatter_geo(\n    data_frame = df,\n    locations = 'code',\n    size = 'size'\n)\n\n\n                                                \n\n\n\nGapminder data 시각화\n- Gapminder data: 국가별 기대수명, 1인당 GDP, 인구에 대한 데이터\n\n특징: 연도별로 정리가 되어있다.\n\n\ndf=px.data.gapminder()\ndf\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n      iso_alpha\n      iso_num\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n      AFG\n      4\n    \n    \n      1\n      Afghanistan\n      Asia\n      1957\n      30.332\n      9240934\n      820.853030\n      AFG\n      4\n    \n    \n      2\n      Afghanistan\n      Asia\n      1962\n      31.997\n      10267083\n      853.100710\n      AFG\n      4\n    \n    \n      3\n      Afghanistan\n      Asia\n      1967\n      34.020\n      11537966\n      836.197138\n      AFG\n      4\n    \n    \n      4\n      Afghanistan\n      Asia\n      1972\n      36.088\n      13079460\n      739.981106\n      AFG\n      4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1699\n      Zimbabwe\n      Africa\n      1987\n      62.351\n      9216418\n      706.157306\n      ZWE\n      716\n    \n    \n      1700\n      Zimbabwe\n      Africa\n      1992\n      60.377\n      10704340\n      693.420786\n      ZWE\n      716\n    \n    \n      1701\n      Zimbabwe\n      Africa\n      1997\n      46.809\n      11404948\n      792.449960\n      ZWE\n      716\n    \n    \n      1702\n      Zimbabwe\n      Africa\n      2002\n      39.989\n      11926563\n      672.038623\n      ZWE\n      716\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n      ZWE\n      716\n    \n  \n\n1704 rows × 8 columns\n\n\n\n\ndf.query('year==2007')\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n      iso_alpha\n      iso_num\n    \n  \n  \n    \n      11\n      Afghanistan\n      Asia\n      2007\n      43.828\n      31889923\n      974.580338\n      AFG\n      4\n    \n    \n      23\n      Albania\n      Europe\n      2007\n      76.423\n      3600523\n      5937.029526\n      ALB\n      8\n    \n    \n      35\n      Algeria\n      Africa\n      2007\n      72.301\n      33333216\n      6223.367465\n      DZA\n      12\n    \n    \n      47\n      Angola\n      Africa\n      2007\n      42.731\n      12420476\n      4797.231267\n      AGO\n      24\n    \n    \n      59\n      Argentina\n      Americas\n      2007\n      75.320\n      40301927\n      12779.379640\n      ARG\n      32\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1655\n      Vietnam\n      Asia\n      2007\n      74.249\n      85262356\n      2441.576404\n      VNM\n      704\n    \n    \n      1667\n      West Bank and Gaza\n      Asia\n      2007\n      73.422\n      4018332\n      3025.349798\n      PSE\n      275\n    \n    \n      1679\n      Yemen, Rep.\n      Asia\n      2007\n      62.698\n      22211743\n      2280.769906\n      YEM\n      887\n    \n    \n      1691\n      Zambia\n      Africa\n      2007\n      42.384\n      11746035\n      1271.211593\n      ZMB\n      894\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n      ZWE\n      716\n    \n  \n\n142 rows × 8 columns\n\n\n\n\npx.scatter_geo(\n    data_frame = df,\n    locations = 'iso_alpha',  \n    size = 'pop'\n)\n\n\n                                                \n\n\n\npx.scatter_geo(\n    data_frame = df.query('year==2007'),\n    locations = 'iso_alpha',  \n    size = 'pop',\n    color = 'continent' # 국가\n)\n\n\n                                                \n\n\n\nx,y 좌표 잡기\n크기\ncolor\n시간\n\n….."
  },
  {
    "objectID": "posts/DV_3(0921).html",
    "href": "posts/DV_3(0921).html",
    "title": "DV 3주차(2)",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nfrom IPython.display import HTML"
  },
  {
    "objectID": "posts/DV_3(0921).html#산점도-응용예제1---표본상관계수",
    "href": "posts/DV_3(0921).html#산점도-응용예제1---표본상관계수",
    "title": "DV 3주차(2)",
    "section": "산점도 응용예제1 - 표본상관계수",
    "text": "산점도 응용예제1 - 표본상관계수\n\n예제소개\n- 아래와 같은 자료를 수집하였다고 하자.\n\n몸무게 = [44,48,49,58,62,68,69,70,76,79]\n키 = [159,160,162,165,167,162,165,175,165,172]\n\n\nx=[44,48,49,58,62,68,69,70,76,79]\ny=[159,160,162,165,167,162,165,175,165,172]\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립)\n키와 몸무게는 관계가 있어 보인다. (정비례)\n\n- 얼만큼 정비례인가?\n\n이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다.\n상관계수는 산점도에서 가장 중요한 개념 중 하나\n\n\n\n상관계수의 정의\n- (표본) 상관계수\n\\[r=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) }{\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\sum_{i=1}^{n}(y_i-\\bar{y})^2 }}=\\sum_{i=1}^{n}\\tilde{x}_i\\tilde{y}_i \\]\n\n단, \\(\\tilde{x}_i=\\frac{(x_i-\\bar{x})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}}\\), \\(\\tilde{y}_i=\\frac{(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\)\n\n- \\(\\tilde{x}_i\\)와 \\(\\tilde{y}_i\\)를 계산하기 위해서 \\(a=\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}, b=\\sqrt{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}\\)를 계산하자.\n(방법1)\n\nfig, ax = plt.subplots(1,3, figsize=(12,4))\nax[0].plot(x,y,'o')\nax[1].plot(np.array(x) - np.mean(x), np.array(y)-np.mean(y), 'o')\n\n\n\n\n\nxx= (np.array(x) - np.mean(x)) / np.sqrt(np.sum((x-np.mean(x))**2))\nyy= (np.array(y) - np.mean(y)) / np.sqrt(np.sum((y-np.mean(y))**2))\n\n\nax[2].plot(xx,yy,'o')\n\n\nfig\n\n\n\n\n첫번째 그림에서 두번쨰 그림 갈때 0근처로 감\n두번째 그림에서 세번째 그림은 퍼져있는 정도(분산)이 큰 차이가 없음(1근처로 왔다갔다..)\n(방법2)\n- 사실 \\(a,b\\)는 아래와 같이 계산할 수 있다.\n\\(a=\\sqrt{n}\\times{\\tt np.std(x)}\\)\n\\(b=\\sqrt{n}\\times{\\tt np.std(y)}\\)\n\nn=len(x)\nnp.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y)\n\n(36.58004920718397, 15.21840990379744)\n\n\n\n\\({\\tt np.std(x)}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\)\n\\({\\tt np.std(y)}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\bar{y})^2}\\)\n\n\nnote: \\({\\tt np.std(x,ddof=1)}=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\)\n\n\n# xx= (x-np.mean(x))/a\n# yy= (y-np.mean(y))/b\n# ax3.plot(xx,yy,'o')\n\n\n\n상관계수의 의미\n질문: r의 값이 양수인가? 음수인가?\n양수 일 것 같다..\n- plotly 사용하여 \\((\\tilde{x}_i,\\tilde{y}_i)\\)를 그려보자.\n\nfig=px.scatter(x=xx, y=yy)\nHTML(fig.to_html(include_plotlyjs='cdn',include_mathjax=False))\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\\(\\tilde{x}_i\\), \\(\\tilde{y}_i\\) 를 곱한값이 양수인것과 음수인것을 체크해보자.\n양수인쪽이 많은지 음수인쪽이 많은지 생각해보자.\n\\(r=\\sum_{i=1}^{n}\\tilde{x}_i \\tilde{y}_i\\) 의 부호는?\n\n\n\n그림을 보고 상관계수의 부호를 알아내는 방법\n- \\((x_i,y_i)\\)의 산점도를 보고 \\((\\tilde{x}_i, \\tilde{y}_i)\\) 의 산점도를 상상 \\(\\to\\) 1,3 분면에 점들이 많으면 양수, 2,4 분면에 점들이 많으면 음수\n\n\n그림을 보고 상관계수의 절대값을 알아내는 방법\n- 예시\n\nx=np.arange(0,10,0.1)\ny1=x+np.random.normal(loc=0,scale=1.0,size=len(x)) # 평균0,분산1인 오차항 더하기\ny2=x+np.random.normal(loc=0,scale=7.0,size=len(x)) # 평균0, 분산7인 오차항 더하기\n\n\nplt.plot(x,y1,'o')\nplt.plot(x,y2,'x')\n\n\n\n\n\ndef tilde(x):\n    n=len(x)\n    return (np.array(x) - np.mean(x)) / np.sqrt(np.sum((np.array(x) - np.mean(x))**2))\n\n\nxx = tilde(x)\nyy1 = tilde(y1)\nyy2 = tilde(y2)\n\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(x,y1,'o');ax[0].plot(x,y2,'x')\nax[1].plot(xx,yy1,'o');ax[1].plot(xx,yy2,'x')"
  },
  {
    "objectID": "posts/DV_3(0921).html#산점도-응용예제2-앤스콤의-4분할",
    "href": "posts/DV_3(0921).html#산점도-응용예제2-앤스콤의-4분할",
    "title": "DV 3주차(2)",
    "section": "산점도 응용예제2 – 앤스콤의 4분할",
    "text": "산점도 응용예제2 – 앤스콤의 4분할\n- Anscombe’s quartet: 교과서에 나오는 그림임.\n- 교훈1: 데이터를 분석하기 전에 항상 시각화를 하라.\n\nx = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\ny1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\ny2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\ny3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\nx4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\ny4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n\n\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\nax1.plot(x,y1,'o') \nax2.plot(x,y2,'o') \nax3.plot(x,y3,'o')  \nax4.plot(x4,y4,'o') \n\n\n\n\n\n_xx = tilde(x)\n_yy1 = tilde(y1)\n\n\nnp.sum(_xx*_yy1) # 상관계수 계싼\n\n0.8164205163448399\n\n\n\nnp.corrcoef([x,y1]) # 상관계수 계산\n\narray([[1.        , 0.81642052],\n       [0.81642052, 1.        ]])\n\n\n\nnp.corrcoef([x,y2])\n\narray([[1.        , 0.81623651],\n       [0.81623651, 1.        ]])\n\n\n\nnp.corrcoef([x,y1,y2,y3])\n\narray([[1.        , 0.81642052, 0.81623651, 0.81628674],\n       [0.81642052, 1.        , 0.7500054 , 0.46871668],\n       [0.81623651, 0.7500054 , 1.        , 0.58791933],\n       [0.81628674, 0.46871668, 0.58791933, 1.        ]])\n\n\n\nnp.corrcoef([x4,y4])\n\narray([[1.        , 0.81652144],\n       [0.81652144, 1.        ]])\n\n\n\n앤스콤의 4분할중 1,2,3 번째 그림의 상관계수는 0.81642052, 0.81623651, 0.81628674 이라는 의미\n즉 corr(x,y1)=0.81642052, corr(x,y2)=0.81623651, corr(x,y3)=0.81628674 임\n\n* 참고로 np.corrcoef([x,y1,y2,y3])의 계산결과는 정확하게\n\\[\\begin{bmatrix} corr(x,x) & corr(x,y1) & corr(x,y2) & corr(x,y3) \\\\ corr(y1,x) & corr(y1,y1) & corr(y1,y2) & corr(y1,y3) \\\\ corr(y2,x) & corr(y2,y1) & corr(y2,y2) & corr(y2,y3) \\\\ corr(y3,x) & corr(y3,y1) & corr(y3,y2) & corr(y3,y3)\\end{bmatrix}\\]\n를 의미한다.\n- 앤스콤플랏의 4개의 그림은 모두 같은 상관계수를 가진다. \\(\\to\\) 하지만 4개의 그림은 느낌이 전혀 다르다.\n- 같은 표본상관계수를 가진다고 하여 같은 관계성을 가지는 것은 아니다. 표본상관계수는 x,y의 비례정도를 측정하는데 그 값이 1에 가깝다고 하여 꼭 정비례의 관계가 있음을 의미하는게 아니다. \\((x_i,y_i)\\)의 산점도가 선형성을 보일때만 “표본상관계수가 1이므로 정비례의 관계에 있다” 라는 논리전개가 성립한다.\n\n앤스콤의 1번째 플랏: 산점도가 선형 \\(\\to\\) 표본상관계수가 0.816 = 정비례의 관계가 0.816 정도\n앤스콤의 2번째 플랏: 산점도가 선형이 아님 \\(\\to\\) 표본상관계수가 크게 의미없음\n앤스콤의 3번째 플랏: 산점도가 선형인듯 보이나 하나의 이상치가 있음 \\(\\to\\) 하나의 이상치가 표본상관계수의 값을 무너뜨릴 수 있으므로 표본상관계수값을 신뢰할 수 없음.\n앤스콤의 4번째 플랏: 산점도를 그려보니 이상한그림 \\(\\to\\) 표존상관계수를 계산할수는 있음. 그런데 그게 무슨 의미가 있을지?\n\n- 앤스콤의 3번째 플랏: 하나의 이상치가 상관계수를 무너뜨리는 경우 시각화"
  },
  {
    "objectID": "posts/DV_3(0921).html#산점도-응용예제3-무상관은-관계가-없다는-뜻",
    "href": "posts/DV_3(0921).html#산점도-응용예제3-무상관은-관계가-없다는-뜻",
    "title": "DV 3주차(2)",
    "section": "산점도 응용예제3 – 무상관은 관계가 없다는 뜻?",
    "text": "산점도 응용예제3 – 무상관은 관계가 없다는 뜻?\n\nnp.random.seed(43052)\nx=np.linspace(-1,1,100,endpoint=True)\ny=x**2+np.random.normal(scale=0.1,size=100)\n\n\nplt.plot(x,y,'o')\nplt.title('y=x**2')\n\nText(0.5, 1.0, 'y=x**2')\n\n\n\n\n\n\nnp.corrcoef(x,y)\n\narray([[1.        , 0.00688718],\n       [0.00688718, 1.        ]])\n\n\n- 표본상관계수의 값이 0에 가까운 것은 두 변수의 직선관계가 약한것을 의미한 것이지 두 변수 사이에 아무런 함수관계가 없다는 것을 의미하는 것은 아니다."
  },
  {
    "objectID": "posts/DV_5(1005).html",
    "href": "posts/DV_5(1005).html",
    "title": "DV 5주차(1)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "posts/DV_5(1005).html#sns-aray",
    "href": "posts/DV_5(1005).html#sns-aray",
    "title": "DV 5주차(1)",
    "section": "sns: aray",
    "text": "sns: aray\n\nsns.scatterplot(data=None, x=x1, y=y1)\nsns.scatterplot(data=None, x=x2, y=y2)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/DV_5(1005).html#sns-wide-df",
    "href": "posts/DV_5(1005).html#sns-wide-df",
    "title": "DV 5주차(1)",
    "section": "sns: wide df",
    "text": "sns: wide df\n\npd.DataFrame({'x':x1,'y':y1})\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.053500\n      -1.258803\n    \n    \n      1\n      -0.517300\n      -0.273907\n    \n    \n      2\n      -0.938688\n      0.582421\n    \n    \n      3\n      1.017930\n      -0.223879\n    \n    \n      4\n      0.827941\n      0.519745\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      995\n      1.317776\n      -0.898103\n    \n    \n      996\n      -0.054884\n      0.290131\n    \n    \n      997\n      -0.082623\n      0.971652\n    \n    \n      998\n      -0.796771\n      -0.140001\n    \n    \n      999\n      0.030602\n      0.435023\n    \n  \n\n1000 rows × 2 columns\n\n\n\n\n               \nsns.scatterplot(data=pd.DataFrame({'x':x1,'y':y1}),x='x',y='y')\nsns.scatterplot(data=pd.DataFrame({'x':x2,'y':y2}),x='x',y='y')\n# #sns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:xlabel='x', ylabel='y'>"
  },
  {
    "objectID": "posts/DV_5(1005).html#sns-long-df",
    "href": "posts/DV_5(1005).html#sns-long-df",
    "title": "DV 5주차(1)",
    "section": "sns: long df",
    "text": "sns: long df\n\nx=np.concatenate([x1,x2])\n# np.array(list(x1) + list(x2))\n# x1.tolist() + x2.tolist()\n# 다 같은 코드이지만 cocaternate쓰는 방식이 제일 편하다\n\ny=np.concatenate([y1,y2])\n\ncat=['x1']*len(x1) + ['x2']*len(x2)\n\n\ndf2=pd.DataFrame({'x':x, 'y':y, 'cat':cat})\ndf2\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      cat\n    \n  \n  \n    \n      0\n      0.082929\n      1.218634\n      x1\n    \n    \n      1\n      -0.019451\n      -1.352701\n      x1\n    \n    \n      2\n      -1.253126\n      1.246169\n      x1\n    \n    \n      3\n      -0.343648\n      0.078081\n      x1\n    \n    \n      4\n      0.479097\n      -1.039999\n      x1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      2.503038\n      2.350603\n      x2\n    \n    \n      1996\n      1.940601\n      2.356207\n      x2\n    \n    \n      1997\n      3.213965\n      2.769489\n      x2\n    \n    \n      1998\n      1.203818\n      -0.276493\n      x2\n    \n    \n      1999\n      1.378763\n      1.914046\n      x2\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df2, x='x', y='y', hue='cat')\n\n<AxesSubplot:xlabel='x', ylabel='y'>"
  },
  {
    "objectID": "posts/DV_5(1005).html#예제1",
    "href": "posts/DV_5(1005).html#예제1",
    "title": "DV 5주차(1)",
    "section": "예제1",
    "text": "예제1\n\nfig, ax = plt.subplots()\nax.plot([1,2,4,3])\n\n\n\n\n\nax\n\n<AxesSubplot:>\n\n\n\nfig, mypltax = plt.subplots()\n\n\n\n\n\nsns.scatterplot(data=df2, x='x', y='y', hue='cat', ax=mypltax)\n# ax라는 변수를 넣자\n\n<AxesSubplot:xlabel='x', ylabel='y'>\n\n\n\nfig  # 오 sns에 ax넣으니 fig에 sns가 들어옴\n\n\n\n\n\nseaborn에서 배우지 않은 내용을 matplotlib이용해서 사용가능함\n\n\nfig, mypltax = plt.subplots()\nsns.scatterplot(data=df2, x='x', y='y', hue='cat', ax=mypltax)\nmypltax.set_title('coco babo')\nfig.suptitle('coco ddong')\n\nText(0.5, 0.98, 'coco ddong')\n\n\n\n\n\n\nfig, ax = plt.subplots(1,3, figsize=(12,4))\nax[0].plot([1,2,4,3], '--o')\nsns.scatterplot(x=x1, y=y1, ax=ax[1])\nsns.scatterplot(x=x1, y=y1, ax=ax[2]) # 겹쳐그리자\nsns.scatterplot(x=x2, y=y2, ax=ax[-1]) # 겹쳐그리자\nax[2].plot([1,2,4,3], '--m', lw=5)"
  },
  {
    "objectID": "posts/DV_5(1005).html#예제2",
    "href": "posts/DV_5(1005).html#예제2",
    "title": "DV 5주차(1)",
    "section": "예제2",
    "text": "예제2\n\nimport cv2\n\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg \nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg',0) # 채널이 1개인 흑백이미지\n!rm Unequalized_Hawkes_Bay_NZ.jpg \n\n--2023-02-25 16:17:39--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   553KB/s    in 0.2s    \n\n2023-02-25 16:17:40 (553 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg’ saved [110895/110895]\n\n\n\n\nplt.imshow(img,vmin=0,vmax=255,cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7f61e88d36d0>\n\n\n\n\n\n\nimg2 = cv2.equalizeHist(img)\n\n\nimg.shape\n\n(683, 1024)\n\n\n\nimg.reshape(683*1024,1) # 컬럼벡터\nimg.reshape(683*1024) #길이가 1\n\narray([127, 145, 149, ..., 146, 145, 144], dtype=uint8)\n\n\n\nfig, ax = plt.subplots(2,2, figsize=(10,5))\nax[0,0].imshow(img,vmin=0,vmax=255,cmap='gray')\n#ax[0,1].hist(img.reshape(-1))\nsns.histplot(img.reshape(-1),ax=ax[0,1], bins=15, lw=0, kde=True, color='C1')\nax[1,0].imshow(img2,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img2.reshape(-1),ax=ax[1,1], bins=15, lw=0, kde=True, color='C1')\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n\nax[0,1]의 x축을 ax[1,1]의 x축과 맞춰서 비교해보고 싶다.\n\n\nfig, ax = plt.subplots(2,2, figsize=(10,5))\nax[0,0].imshow(img,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img.reshape(-1),ax=ax[0,1], bins=15, lw=0, kde=True, color='C1')\nax[0,1].set_xlim(0,255)\nax[1,0].imshow(img2,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img2.reshape(-1),ax=ax[1,1], bins=15, lw=0, kde=True, color='C1')\n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/DV_5(1005).html#축-간격조정",
    "href": "posts/DV_5(1005).html#축-간격조정",
    "title": "DV 5주차(1)",
    "section": "축 간격조정",
    "text": "축 간격조정\n\nimport matplotlib as mpl\n\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(3)) # 큰 눈금간격을 3으로\nax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) # 작은 눈금간격을 1로"
  },
  {
    "objectID": "posts/DV_5(1005).html#축-삭제",
    "href": "posts/DV_5(1005).html#축-삭제",
    "title": "DV 5주차(1)",
    "section": "축 삭제",
    "text": "축 삭제\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.NullLocator()) # x축 눈금삭제\nax.yaxis.set_major_locator(mpl.ticker.NullLocator()) # y축 눈금삭제"
  },
  {
    "objectID": "posts/DV_5(1005).html#축-범위조정",
    "href": "posts/DV_5(1005).html#축-범위조정",
    "title": "DV 5주차(1)",
    "section": "축 범위조정",
    "text": "축 범위조정\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.set_ylim(-1,2) \nax.set_xlim(-5,35)\n#plt.ylim(-1,2)   위 ax와 같은 코드\n#plt.xlim(-5,35)\n\n(-5.0, 35.0)"
  },
  {
    "objectID": "posts/DV_5(1005).html#gcf-gca",
    "href": "posts/DV_5(1005).html#gcf-gca",
    "title": "DV 5주차(1)",
    "section": "gcf, gca",
    "text": "gcf, gca\n\nplt.plot([1,2,3,2])\nfig=plt.gcf()\n\n# gcf: get current figure\n\n\n\n\n\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')\n\n\n\nfig\n\n\n\n\n\nax = fig.gca()\n\n# gca: get current axes\n\n\nax.set_title('title') \nfig"
  },
  {
    "objectID": "posts/DV_11(1114).html",
    "href": "posts/DV_11(1114).html",
    "title": "DV 11주차(1)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/DV_11(1114).html#data1-야후-파이낸스",
    "href": "posts/DV_11(1114).html#data1-야후-파이낸스",
    "title": "DV 11주차(1)",
    "section": "data1: 야후 파이낸스",
    "text": "data1: 야후 파이낸스\n- yahoo finance: https://finance.yahoo.com/\n\nyf.pdr_override()\n\n\nsymbols = ['AMZN','AAPL','GOOG','MSFT','NFLX','NVDA','TSLA']\nstart = '2020-01-01'\nend = '2022-10-30'\ndf = pdr.get_data_yahoo(symbols,start,end)['Adj Close']\n\n[*********************100%***********************]  7 of 7 completed\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      AAPL\n      AMZN\n      GOOG\n      MSFT\n      NFLX\n      NVDA\n      TSLA\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2020-01-02\n      73.449379\n      94.900497\n      68.368500\n      155.761826\n      329.809998\n      59.770554\n      28.684000\n    \n    \n      2020-01-03\n      72.735313\n      93.748497\n      68.032997\n      153.822311\n      325.899994\n      58.813866\n      29.534000\n    \n    \n      2020-01-06\n      73.314880\n      95.143997\n      69.710503\n      154.219925\n      335.829987\n      59.060509\n      30.102667\n    \n    \n      2020-01-07\n      72.970078\n      95.343002\n      69.667000\n      152.813766\n      330.750000\n      59.775528\n      31.270666\n    \n    \n      2020-01-08\n      74.143898\n      94.598503\n      70.216003\n      155.247818\n      339.260010\n      59.887650\n      32.809334\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2022-10-24\n      148.975021\n      119.820000\n      102.970001\n      245.939163\n      282.450012\n      125.957771\n      211.250000\n    \n    \n      2022-10-25\n      151.855850\n      120.599998\n      104.930000\n      249.331085\n      291.019989\n      132.576080\n      222.419998\n    \n    \n      2022-10-26\n      148.875351\n      115.660004\n      94.820000\n      230.093628\n      298.619995\n      128.927017\n      224.639999\n    \n    \n      2022-10-27\n      144.339813\n      110.959999\n      92.599998\n      225.547836\n      296.940002\n      131.726288\n      225.089996\n    \n    \n      2022-10-28\n      155.245056\n      103.410004\n      96.580002\n      234.619492\n      295.720001\n      138.304611\n      228.520004\n    \n  \n\n713 rows × 7 columns\n\n\n\n\ndf.columns\n\nIndex(['AAPL', 'AMZN', 'GOOG', 'MSFT', 'NFLX', 'NVDA', 'TSLA'], dtype='object')"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-1개의-y를-그리기",
    "href": "posts/DV_11(1114).html#matplotlib-1개의-y를-그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 1개의 y를 그리기",
    "text": "matplotlib: 1개의 y를 그리기\n- 예시1: 1개의 y를 그리기\n\ndf.reset_index()\n\n\n\n\n\n  \n    \n      \n      Date\n      AAPL\n      AMZN\n      GOOG\n      MSFT\n      NFLX\n      NVDA\n      TSLA\n    \n  \n  \n    \n      0\n      2020-01-02\n      73.449379\n      94.900497\n      68.368500\n      155.761826\n      329.809998\n      59.770554\n      28.684000\n    \n    \n      1\n      2020-01-03\n      72.735313\n      93.748497\n      68.032997\n      153.822311\n      325.899994\n      58.813866\n      29.534000\n    \n    \n      2\n      2020-01-06\n      73.314880\n      95.143997\n      69.710503\n      154.219925\n      335.829987\n      59.060509\n      30.102667\n    \n    \n      3\n      2020-01-07\n      72.970078\n      95.343002\n      69.667000\n      152.813766\n      330.750000\n      59.775528\n      31.270666\n    \n    \n      4\n      2020-01-08\n      74.143898\n      94.598503\n      70.216003\n      155.247818\n      339.260010\n      59.887650\n      32.809334\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      708\n      2022-10-24\n      148.975021\n      119.820000\n      102.970001\n      245.939163\n      282.450012\n      125.957771\n      211.250000\n    \n    \n      709\n      2022-10-25\n      151.855850\n      120.599998\n      104.930000\n      249.331085\n      291.019989\n      132.576080\n      222.419998\n    \n    \n      710\n      2022-10-26\n      148.875351\n      115.660004\n      94.820000\n      230.093628\n      298.619995\n      128.927017\n      224.639999\n    \n    \n      711\n      2022-10-27\n      144.339813\n      110.959999\n      92.599998\n      225.547836\n      296.940002\n      131.726288\n      225.089996\n    \n    \n      712\n      2022-10-28\n      155.245056\n      103.410004\n      96.580002\n      234.619492\n      295.720001\n      138.304611\n      228.520004\n    \n  \n\n713 rows × 8 columns\n\n\n\n\ndf.reset_index().melt(id_vars='Date') # tidy data\n\n\n\n\n\n  \n    \n      \n      Date\n      variable\n      value\n    \n  \n  \n    \n      0\n      2020-01-02\n      AAPL\n      73.449379\n    \n    \n      1\n      2020-01-03\n      AAPL\n      72.735313\n    \n    \n      2\n      2020-01-06\n      AAPL\n      73.314880\n    \n    \n      3\n      2020-01-07\n      AAPL\n      72.970078\n    \n    \n      4\n      2020-01-08\n      AAPL\n      74.143898\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4986\n      2022-10-24\n      TSLA\n      211.250000\n    \n    \n      4987\n      2022-10-25\n      TSLA\n      222.419998\n    \n    \n      4988\n      2022-10-26\n      TSLA\n      224.639999\n    \n    \n      4989\n      2022-10-27\n      TSLA\n      225.089996\n    \n    \n      4990\n      2022-10-28\n      TSLA\n      228.520004\n    \n  \n\n4991 rows × 3 columns\n\n\n\n\ndf.reset_index().plot(x='Date', y='AMZN')\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n- 예시2\n\ndf.reset_index().plot(x='Date',y='AMZN', kind='line')\n# 위의 코드는 kind가 생략된 것과 같다\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n- 예시3\n\ndf.reset_index().plot.line(x='Date',y='AMZN')\n# kind=line 대신에 plot.line\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-2개의-y를-겹쳐서-그리기",
    "href": "posts/DV_11(1114).html#matplotlib-2개의-y를-겹쳐서-그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 2개의 y를 겹쳐서 그리기",
    "text": "matplotlib: 2개의 y를 겹쳐서 그리기\n- 2개의 y를 겹쳐 그리기\n\ndf.reset_index().plot(x='Date', y=['AMZN','AAPL'])\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-모든-y를-겹쳐서-그리기",
    "href": "posts/DV_11(1114).html#matplotlib-모든-y를-겹쳐서-그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 모든 y를 겹쳐서 그리기",
    "text": "matplotlib: 모든 y를 겹쳐서 그리기\n- 모든 y를 겹쳐서 그리기\n\ndf.reset_index().plot(x='Date')\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-그림크기조정",
    "href": "posts/DV_11(1114).html#matplotlib-그림크기조정",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 그림크기조정",
    "text": "matplotlib: 그림크기조정\n\ndf.reset_index().plot(x='Date',figsize=(8,8))\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-서브플랏",
    "href": "posts/DV_11(1114).html#matplotlib-서브플랏",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 서브플랏",
    "text": "matplotlib: 서브플랏\n- 예시1: 기본 서브플랏\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(10,10))\n\n# 겹처서 말구 나눠서 그려짐! 신기하군 \n\narray([<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>], dtype=object)\n\n\n\n\n\n- 예시2: 레이아웃 조정\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(15,15),layout=(4,2))\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-폰트조정",
    "href": "posts/DV_11(1114).html#matplotlib-폰트조정",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 폰트조정",
    "text": "matplotlib: 폰트조정\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(15,15),layout=(4,2),fontsize=15)\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-레전드삭제",
    "href": "posts/DV_11(1114).html#matplotlib-레전드삭제",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 레전드삭제",
    "text": "matplotlib: 레전드삭제\n\ndf.reset_index().plot.line(x='Date',subplots=True, layout=(4,2), legend=False)\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-모든y를-겹쳐서-그리기",
    "href": "posts/DV_11(1114).html#plotly-모든y를-겹쳐서-그리기",
    "title": "DV 11주차(1)",
    "section": "plotly 모든y를 겹쳐서 그리기",
    "text": "plotly 모든y를 겹쳐서 그리기\n- 방법1\n\ndf.reset_index().set_index('Date').stack().reset_index()\n\n\n\n\n\n  \n    \n      \n      Date\n      level_1\n      0\n    \n  \n  \n    \n      0\n      2020-01-02\n      AAPL\n      73.449379\n    \n    \n      1\n      2020-01-02\n      AMZN\n      94.900497\n    \n    \n      2\n      2020-01-02\n      GOOG\n      68.368500\n    \n    \n      3\n      2020-01-02\n      MSFT\n      155.761826\n    \n    \n      4\n      2020-01-02\n      NFLX\n      329.809998\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4986\n      2022-10-28\n      GOOG\n      96.580002\n    \n    \n      4987\n      2022-10-28\n      MSFT\n      234.619492\n    \n    \n      4988\n      2022-10-28\n      NFLX\n      295.720001\n    \n    \n      4989\n      2022-10-28\n      NVDA\n      138.304611\n    \n    \n      4990\n      2022-10-28\n      TSLA\n      228.520004\n    \n  \n\n4991 rows × 3 columns\n\n\n\n- 방법2\n\ndf.reset_index().melt(id_vars='Date').plot.line(backend='plotly',x='Date',y='value',color='variable')"
  },
  {
    "objectID": "posts/DV_11(1114).html#data2-핸드폰점유율",
    "href": "posts/DV_11(1114).html#data2-핸드폰점유율",
    "title": "DV 11주차(1)",
    "section": "data2: 핸드폰점유율",
    "text": "data2: 핸드폰점유율\n\ndf = pd.read_csv('https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      31.49\n      22.09\n      10.02\n      7.79\n      4.10\n      3.15\n      2.41\n      2.40\n      9.51\n      0.54\n      2.35\n      0.95\n      0.96\n      0.70\n      0.84\n      0.74\n    \n    \n      1\n      2019-11\n      31.36\n      22.90\n      10.18\n      8.16\n      4.42\n      3.41\n      2.40\n      2.40\n      9.10\n      0.78\n      0.66\n      0.97\n      0.97\n      0.73\n      0.83\n      0.75\n    \n    \n      2\n      2019-12\n      31.37\n      24.79\n      9.95\n      7.73\n      4.23\n      3.19\n      2.50\n      2.54\n      8.13\n      0.84\n      0.75\n      0.90\n      0.87\n      0.74\n      0.77\n      0.70\n    \n    \n      3\n      2020-01\n      31.29\n      24.76\n      10.61\n      8.10\n      4.25\n      3.02\n      2.42\n      2.40\n      7.55\n      0.88\n      0.69\n      0.88\n      0.86\n      0.79\n      0.80\n      0.69\n    \n    \n      4\n      2020-02\n      30.91\n      25.89\n      10.98\n      7.80\n      4.31\n      2.89\n      2.36\n      2.34\n      7.06\n      0.89\n      0.70\n      0.81\n      0.77\n      0.78\n      0.80\n      0.69\n    \n    \n      5\n      2020-03\n      30.80\n      27.03\n      10.70\n      7.70\n      4.30\n      2.87\n      2.35\n      2.28\n      6.63\n      0.93\n      0.73\n      0.72\n      0.74\n      0.78\n      0.76\n      0.66\n    \n    \n      6\n      2020-04\n      30.41\n      28.79\n      10.28\n      7.60\n      4.20\n      2.75\n      2.51\n      2.28\n      5.84\n      0.90\n      0.75\n      0.69\n      0.71\n      0.80\n      0.76\n      0.70\n    \n    \n      7\n      2020-05\n      30.18\n      26.72\n      10.39\n      8.36\n      4.70\n      3.12\n      2.46\n      2.19\n      6.31\n      1.04\n      0.70\n      0.73\n      0.77\n      0.81\n      0.78\n      0.76\n    \n    \n      8\n      2020-06\n      31.06\n      25.26\n      10.69\n      8.55\n      4.65\n      3.18\n      2.57\n      2.11\n      6.39\n      1.04\n      0.68\n      0.74\n      0.75\n      0.77\n      0.78\n      0.75\n    \n    \n      9\n      2020-07\n      30.95\n      24.82\n      10.75\n      8.94\n      4.69\n      3.46\n      2.45\n      2.03\n      6.41\n      1.13\n      0.65\n      0.76\n      0.74\n      0.76\n      0.75\n      0.72\n    \n    \n      10\n      2020-08\n      31.04\n      25.15\n      10.73\n      8.90\n      4.69\n      3.38\n      2.39\n      1.96\n      6.31\n      1.18\n      0.63\n      0.74\n      0.72\n      0.75\n      0.73\n      0.70\n    \n    \n      11\n      2020-09\n      30.57\n      24.98\n      10.58\n      9.49\n      4.94\n      3.50\n      2.27\n      1.88\n      6.12\n      1.45\n      0.63\n      0.74\n      0.67\n      0.81\n      0.69\n      0.67\n    \n    \n      12\n      2020-10\n      30.25\n      26.53\n      10.44\n      9.67\n      4.83\n      2.54\n      2.21\n      1.79\n      6.04\n      1.55\n      0.63\n      0.69\n      0.65\n      0.85\n      0.67\n      0.64"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기",
    "href": "posts/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 2개의 y를 겹쳐그리기",
    "text": "matplotlib: 2개의 y를 겹쳐그리기\n- 예시1\n\ndf.plot.bar(x='Date', y=['Samsung', 'Apple'])\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n- 예시2: width옵션으로 폭조정\n\ndf.plot.bar(x='Date', y=['Samsung', 'Apple'], width=0.8)\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기-xy-플립",
    "href": "posts/DV_11(1114).html#matplotlib-2개의-y를-겹쳐그리기-xy-플립",
    "title": "DV 11주차(1)",
    "section": "matplotlib: 2개의 y를 겹쳐그리기 + x,y 플립",
    "text": "matplotlib: 2개의 y를 겹쳐그리기 + x,y 플립\n- 예시: barh를 이용하여 플립\n\ndf.plot.barh(x='Date', y=['Samsung', 'Apple'], width=0.8)\n\n<AxesSubplot:ylabel='Date'>"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-모든y를-stacked-bar로-나타내기",
    "href": "posts/DV_11(1114).html#plotly-모든y를-stacked-bar로-나타내기",
    "title": "DV 11주차(1)",
    "section": "plotly: 모든y를 stacked bar로 나타내기",
    "text": "plotly: 모든y를 stacked bar로 나타내기\n\ndf.melt(id_vars='Date').plot.bar(backend='plotly',x='Date',y='value',color='variable')"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기",
    "href": "posts/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기",
    "title": "DV 11주차(1)",
    "section": "plotly: 3개의 y를 겹쳐그리기",
    "text": "plotly: 3개의 y를 겹쳐그리기\n\ndf.melt(id_vars='Date')\\\n.query('variable==\"Samsung\" or variable==\"Apple\" or variable == \"Huawei\"')\\\n.plot.bar(backend='plotly', x='Date', y='value', color='variable')\n\n\n                                                \n\n\n- barmode=‘group’\n\ndf.melt(id_vars='Date')\\\n.query('variable==\"Samsung\" or variable==\"Apple\" or variable == \"Huawei\"')\\\n.plot.bar(backend='plotly', x='Date', y='value', color='variable', barmode='group')"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기-text",
    "href": "posts/DV_11(1114).html#plotly-3개의-y를-겹쳐그리기-text",
    "title": "DV 11주차(1)",
    "section": "plotly: 3개의 y를 겹쳐그리기 + text",
    "text": "plotly: 3개의 y를 겹쳐그리기 + text\n\ndf.melt(id_vars='Date')\\\n.query('variable==\"Samsung\" or variable==\"Apple\" or variable == \"Huawei\"')\\\n.plot.bar(backend='plotly', x='Date', y='value', color='variable', barmode='group', text='value', height=600)"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_col",
    "href": "posts/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_col",
    "title": "DV 11주차(1)",
    "section": "plotly: 면분할로 subplot그리기 (facet_col)",
    "text": "plotly: 면분할로 subplot그리기 (facet_col)\n\ndf.melt(id_vars='Date').query(' variable==\"Samsung\" or variable==\"Apple\"')\\\n.plot.bar(backend='plotly',x='Date',y='value',color='variable',barmode='group',facet_col='variable')"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_row",
    "href": "posts/DV_11(1114).html#plotly-면분할로-subplot그리기-facet_row",
    "title": "DV 11주차(1)",
    "section": "plotly: 면분할로 subplot그리기 (facet_row)",
    "text": "plotly: 면분할로 subplot그리기 (facet_row)\n\ndf.melt(id_vars='Date').query(' variable==\"Samsung\" or variable==\"Apple\"')\\\n.plot.bar(backend='plotly',x='Date',y='value',color='variable',barmode='group',facet_row='variable')"
  },
  {
    "objectID": "posts/DV_11(1114).html#data3-팁",
    "href": "posts/DV_11(1114).html#data3-팁",
    "title": "DV 11주차(1)",
    "section": "data3: 팁",
    "text": "data3: 팁\n\nimport plotly.express as px \ndf = px.data.tips() \ndf\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n    \n  \n\n244 rows × 7 columns"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-팁의-박스플랏",
    "href": "posts/DV_11(1114).html#plotly-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 팁의 박스플랏",
    "text": "plotly: 팁의 박스플랏\n\ndf.plot.box(backend='plotly',y='tip', width=500, height=500)"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-시간에-따른-팁의-박스플랏",
    "href": "posts/DV_11(1114).html#plotly-시간에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간에 따른 팁의 박스플랏",
    "text": "plotly: 시간에 따른 팁의 박스플랏\n\ndf.plot.box(backend='plotly',x='time', y='tip', width=500, height=500)"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-시간과-성별에-따른-팁의-박스플랏",
    "href": "posts/DV_11(1114).html#plotly-시간과-성별에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간과 성별에 따른 팁의 박스플랏",
    "text": "plotly: 시간과 성별에 따른 팁의 박스플랏\n- 예시1: y=‘tip’, x=‘time’, color=‘sex’\n\ndf.plot.box(backend='plotly',x='time', y='tip', color='sex', width=500, height=500)\n\n\n                                                \n\n\n- 예시2: y=‘tip’, x=‘time’, color=‘sex’, points=‘all’\n\ndf.plot.box(backend='plotly',x='time', y='tip', color='sex', points='all',width=500, height=500)\n\n\n                                                \n\n\n\n저녁이 손님이 더 많다"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-시간성별요일에-따른-팁의-박스플랏",
    "href": "posts/DV_11(1114).html#plotly-시간성별요일에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간,성별,요일에 따른 팁의 박스플랏",
    "text": "plotly: 시간,성별,요일에 따른 팁의 박스플랏\n- 예시1: y=‘tip’, x=‘time’, color=‘sex’, facet_col=‘day’\n\ndf.plot.box(backend='plotly',x='time', y='tip', color='sex', facet_col='day', width=500, height=500)\n\n\n                                                \n\n\n- 예시2: y=‘tip’, color=‘sex’, facet_col=‘time’, facet_row=‘day’\n\ndf.plot.box(backend='plotly',facet_col='time', facet_row='day',y='tip',color='sex',points='all',height=1000)"
  },
  {
    "objectID": "posts/DV_11(1114).html#plotly-시간성별요일흡연에-따른-팁의-박스플랏",
    "href": "posts/DV_11(1114).html#plotly-시간성별요일흡연에-따른-팁의-박스플랏",
    "title": "DV 11주차(1)",
    "section": "plotly: 시간,성별,요일,흡연에 따른 팁의 박스플랏",
    "text": "plotly: 시간,성별,요일,흡연에 따른 팁의 박스플랏\n\ndf.plot.box(backend='plotly',facet_col='time', facet_row='day',x='smoker',y='tip',color='sex',points='all',height=1000)"
  },
  {
    "objectID": "posts/DV_11(1114).html#data4-인사자료",
    "href": "posts/DV_11(1114).html#data4-인사자료",
    "title": "DV 11주차(1)",
    "section": "data4: 인사자료",
    "text": "data4: 인사자료\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/HRDataset_v14.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Employee_Name\n      EmpID\n      MarriedID\n      MaritalStatusID\n      GenderID\n      EmpStatusID\n      DeptID\n      PerfScoreID\n      FromDiversityJobFairID\n      Salary\n      ...\n      ManagerName\n      ManagerID\n      RecruitmentSource\n      PerformanceScore\n      EngagementSurvey\n      EmpSatisfaction\n      SpecialProjectsCount\n      LastPerformanceReview_Date\n      DaysLateLast30\n      Absences\n    \n  \n  \n    \n      0\n      Adinolfi, Wilson  K\n      10026\n      0\n      0\n      1\n      1\n      5\n      4\n      0\n      62506\n      ...\n      Michael Albert\n      22.0\n      LinkedIn\n      Exceeds\n      4.60\n      5\n      0\n      1/17/2019\n      0\n      1\n    \n    \n      1\n      Ait Sidi, Karthikeyan\n      10084\n      1\n      1\n      1\n      5\n      3\n      3\n      0\n      104437\n      ...\n      Simon Roup\n      4.0\n      Indeed\n      Fully Meets\n      4.96\n      3\n      6\n      2/24/2016\n      0\n      17\n    \n    \n      2\n      Akinkuolie, Sarah\n      10196\n      1\n      1\n      0\n      5\n      5\n      3\n      0\n      64955\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      3.02\n      3\n      0\n      5/15/2012\n      0\n      3\n    \n    \n      3\n      Alagbe,Trina\n      10088\n      1\n      1\n      0\n      1\n      5\n      3\n      0\n      64991\n      ...\n      Elijiah Gray\n      16.0\n      Indeed\n      Fully Meets\n      4.84\n      5\n      0\n      1/3/2019\n      0\n      15\n    \n    \n      4\n      Anderson, Carol\n      10069\n      0\n      2\n      0\n      5\n      5\n      3\n      0\n      50825\n      ...\n      Webster Butler\n      39.0\n      Google Search\n      Fully Meets\n      5.00\n      4\n      0\n      2/1/2016\n      0\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      306\n      Woodson, Jason\n      10135\n      0\n      0\n      1\n      1\n      5\n      3\n      0\n      65893\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      4.07\n      4\n      0\n      2/28/2019\n      0\n      13\n    \n    \n      307\n      Ybarra, Catherine\n      10301\n      0\n      0\n      0\n      5\n      5\n      1\n      0\n      48513\n      ...\n      Brannon Miller\n      12.0\n      Google Search\n      PIP\n      3.20\n      2\n      0\n      9/2/2015\n      5\n      4\n    \n    \n      308\n      Zamora, Jennifer\n      10010\n      0\n      0\n      0\n      1\n      3\n      4\n      0\n      220450\n      ...\n      Janet King\n      2.0\n      Employee Referral\n      Exceeds\n      4.60\n      5\n      6\n      2/21/2019\n      0\n      16\n    \n    \n      309\n      Zhou, Julia\n      10043\n      0\n      0\n      0\n      1\n      3\n      3\n      0\n      89292\n      ...\n      Simon Roup\n      4.0\n      Employee Referral\n      Fully Meets\n      5.00\n      3\n      5\n      2/1/2019\n      0\n      11\n    \n    \n      310\n      Zima, Colleen\n      10271\n      0\n      4\n      0\n      1\n      5\n      3\n      0\n      45046\n      ...\n      David Stanley\n      14.0\n      LinkedIn\n      Fully Meets\n      4.50\n      5\n      0\n      1/30/2019\n      0\n      2\n    \n  \n\n311 rows × 36 columns"
  },
  {
    "objectID": "posts/DV_11(1114).html#인종별-급여비교-단순-groupby",
    "href": "posts/DV_11(1114).html#인종별-급여비교-단순-groupby",
    "title": "DV 11주차(1)",
    "section": "인종별 급여비교 (단순 groupby)",
    "text": "인종별 급여비교 (단순 groupby)\n\ndf.groupby('RaceDesc').agg({'Salary':[np.mean,\"count\"]})\n\n\n\n\n\n  \n    \n      \n      Salary\n    \n    \n      \n      mean\n      count\n    \n    \n      RaceDesc\n      \n      \n    \n  \n  \n    \n      American Indian or Alaska Native\n      65806.000000\n      3\n    \n    \n      Asian\n      68521.206897\n      29\n    \n    \n      Black or African American\n      74431.025000\n      80\n    \n    \n      Hispanic\n      83667.000000\n      1\n    \n    \n      Two or more races\n      59998.181818\n      11\n    \n    \n      White\n      67287.545455\n      187\n    \n  \n\n\n\n\n평균을 히스토그램 그려봣을때 약간 정규분포를 띄어야 의미가 있다"
  },
  {
    "objectID": "posts/DV_11(1114).html#급여의-시각화",
    "href": "posts/DV_11(1114).html#급여의-시각화",
    "title": "DV 11주차(1)",
    "section": "급여의 시각화",
    "text": "급여의 시각화\n- 예시1\n\ndf.query('RaceDesc == \"Black or African American\" or RaceDesc == \"White\"')\\\n.plot.hist(backend='plotly', x='Salary', color='RaceDesc', facet_col='RaceDesc')\n\n\n                                                \n\n\n- 예시2: 비율로 계싼\n\ndf.query('RaceDesc == \"Black or African American\" or RaceDesc == \"White\"')\\\n.plot.hist(backend='plotly',x='Salary',color='RaceDesc',facet_col='RaceDesc',histnorm='probability')"
  },
  {
    "objectID": "posts/DV_10(1109).html",
    "href": "posts/DV_10(1109).html",
    "title": "DV 10주차(2)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom plotnine import *"
  },
  {
    "objectID": "posts/DV_10(1109).html#시각화1-전체합격률",
    "href": "posts/DV_10(1109).html#시각화1-전체합격률",
    "title": "DV 10주차(2)",
    "section": "시각화1: 전체합격률",
    "text": "시각화1: 전체합격률\n- df1\n\n(df.query('gender==\"female\" and result==\"fail\"')['count']).sum()\n\n1063\n\n\n\ndf.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n    \n    \n      1\n      female\n      pass\n      772\n    \n    \n      2\n      male\n      fail\n      1291\n    \n    \n      3\n      male\n      pass\n      1400\n    \n  \n\n\n\n\n- df11\n\ndf.groupby('gender').agg({'count':np.sum}).reset_index()\n\n\n\n\n\n  \n    \n      \n      gender\n      count\n    \n  \n  \n    \n      0\n      female\n      1835\n    \n    \n      1\n      male\n      2691\n    \n  \n\n\n\n\n\ndf1과 df2를 합치자\n\n- merge: 두개의 데이터프레임을 합친다.\n\n_df1=df.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\n_df2=df.groupby('gender').agg({'count':np.sum}).reset_index()\npd.merge(_df1,_df2)\n\n# _df1과 _df2의 count변수명이 다르기 때문에 아래와 같이 아무것도 안나옴\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n    \n  \n  \n  \n\n\n\n\n\ndf.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n    \n  \n  \n    \n      0\n      female\n      1835\n    \n    \n      1\n      male\n      2691\n    \n  \n\n\n\n\n- merge 방법 1\n\n_df1=df.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\n_df2=df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\npd.merge(_df1,_df2)\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n    \n  \n\n\n\n\n- merge 방법2\n\ndf.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n    \n  \n\n\n\n\n- 비율계산\n\ndf.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n      0.579292\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n      0.420708\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n      0.479747\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n      0.520253\n    \n  \n\n\n\n\n- 시각화\n\ndata1=df.groupby(['gender', 'result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data1.query('result == \"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\n\n\n\n\n<ggplot: (8761232133521)>\n\n\n- 결론: 남자의 합격률이 더 높다. \\(\\to\\) 성차별?"
  },
  {
    "objectID": "posts/DV_10(1109).html#시각화2-학과별-합격률",
    "href": "posts/DV_10(1109).html#시각화2-학과별-합격률",
    "title": "DV 10주차(2)",
    "section": "시각화2: 학과별 합격률",
    "text": "시각화2: 학과별 합격률\n- df2\n\ndf.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      department\n      gender\n      count2\n    \n  \n  \n    \n      0\n      A\n      female\n      108\n    \n    \n      1\n      A\n      male\n      825\n    \n    \n      2\n      B\n      female\n      25\n    \n    \n      3\n      B\n      male\n      560\n    \n    \n      4\n      C\n      female\n      593\n    \n    \n      5\n      C\n      male\n      325\n    \n    \n      6\n      D\n      female\n      375\n    \n    \n      7\n      D\n      male\n      417\n    \n    \n      8\n      E\n      female\n      393\n    \n    \n      9\n      E\n      male\n      191\n    \n    \n      10\n      F\n      female\n      341\n    \n    \n      11\n      F\n      male\n      373\n    \n  \n\n\n\n\n- merge\n\ndf.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\\\n.merge(df)\n\n\n\n\n\n  \n    \n      \n      department\n      gender\n      count2\n      result\n      count\n    \n  \n  \n    \n      0\n      A\n      female\n      108\n      fail\n      19\n    \n    \n      1\n      A\n      female\n      108\n      pass\n      89\n    \n    \n      2\n      A\n      male\n      825\n      fail\n      314\n    \n    \n      3\n      A\n      male\n      825\n      pass\n      511\n    \n    \n      4\n      B\n      female\n      25\n      fail\n      7\n    \n    \n      5\n      B\n      female\n      25\n      pass\n      18\n    \n    \n      6\n      B\n      male\n      560\n      fail\n      208\n    \n    \n      7\n      B\n      male\n      560\n      pass\n      352\n    \n    \n      8\n      C\n      female\n      593\n      fail\n      391\n    \n    \n      9\n      C\n      female\n      593\n      pass\n      202\n    \n    \n      10\n      C\n      male\n      325\n      fail\n      204\n    \n    \n      11\n      C\n      male\n      325\n      pass\n      121\n    \n    \n      12\n      D\n      female\n      375\n      fail\n      244\n    \n    \n      13\n      D\n      female\n      375\n      pass\n      131\n    \n    \n      14\n      D\n      male\n      417\n      fail\n      279\n    \n    \n      15\n      D\n      male\n      417\n      pass\n      138\n    \n    \n      16\n      E\n      female\n      393\n      fail\n      299\n    \n    \n      17\n      E\n      female\n      393\n      pass\n      94\n    \n    \n      18\n      E\n      male\n      191\n      fail\n      137\n    \n    \n      19\n      E\n      male\n      191\n      pass\n      54\n    \n    \n      20\n      F\n      female\n      341\n      fail\n      103\n    \n    \n      21\n      F\n      female\n      341\n      pass\n      238\n    \n    \n      22\n      F\n      male\n      373\n      fail\n      149\n    \n    \n      23\n      F\n      male\n      373\n      pass\n      224\n    \n  \n\n\n\n\n\n위와 같은 거긴 한데 count 뒤로 보내려고 아래와 같이 작성\n\n\ndata2=df.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate=count/count2')\ndata2\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n      108\n      0.175926\n    \n    \n      1\n      A\n      pass\n      female\n      89\n      108\n      0.824074\n    \n    \n      2\n      A\n      fail\n      male\n      314\n      825\n      0.380606\n    \n    \n      3\n      A\n      pass\n      male\n      511\n      825\n      0.619394\n    \n    \n      4\n      B\n      fail\n      female\n      7\n      25\n      0.280000\n    \n    \n      5\n      B\n      pass\n      female\n      18\n      25\n      0.720000\n    \n    \n      6\n      B\n      fail\n      male\n      208\n      560\n      0.371429\n    \n    \n      7\n      B\n      pass\n      male\n      352\n      560\n      0.628571\n    \n    \n      8\n      C\n      fail\n      female\n      391\n      593\n      0.659359\n    \n    \n      9\n      C\n      pass\n      female\n      202\n      593\n      0.340641\n    \n    \n      10\n      C\n      fail\n      male\n      204\n      325\n      0.627692\n    \n    \n      11\n      C\n      pass\n      male\n      121\n      325\n      0.372308\n    \n    \n      12\n      D\n      fail\n      female\n      244\n      375\n      0.650667\n    \n    \n      13\n      D\n      pass\n      female\n      131\n      375\n      0.349333\n    \n    \n      14\n      D\n      fail\n      male\n      279\n      417\n      0.669065\n    \n    \n      15\n      D\n      pass\n      male\n      138\n      417\n      0.330935\n    \n    \n      16\n      E\n      fail\n      female\n      299\n      393\n      0.760814\n    \n    \n      17\n      E\n      pass\n      female\n      94\n      393\n      0.239186\n    \n    \n      18\n      E\n      fail\n      male\n      137\n      191\n      0.717277\n    \n    \n      19\n      E\n      pass\n      male\n      54\n      191\n      0.282723\n    \n    \n      20\n      F\n      fail\n      female\n      103\n      341\n      0.302053\n    \n    \n      21\n      F\n      pass\n      female\n      238\n      341\n      0.697947\n    \n    \n      22\n      F\n      fail\n      male\n      149\n      373\n      0.399464\n    \n    \n      23\n      F\n      pass\n      male\n      224\n      373\n      0.600536\n    \n  \n\n\n\n\n- 시각화\n\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\\\n+facet_wrap('department')\n\n\n\n\n<ggplot: (8761230954277)>\n\n\n\n학과별로 살펴보니 A,B,D,F는 여성 합격률이 더 높다.\n\n- 교재설명: 여성의 합격률이 낮은 학과(인기있는 학과)에만 많이 지원하였기 때문\n\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='department',fill='gender',y='count'),\\\nposition='dodge')\n\n\n\n\n<ggplot: (8761230699317)>\n\n\n\n살펴보니 합격률이 높은 A,B학과의 경우 상대적으로 남성이 많이 지원하였음. 합격률이 낮은 C,D학과는 상대적으로 여성이 많이 지원함. D,F의 지원수는 비슷"
  },
  {
    "objectID": "posts/DV_10(1109).html#시각화1-남녀합격률-시각화",
    "href": "posts/DV_10(1109).html#시각화1-남녀합격률-시각화",
    "title": "DV 10주차(2)",
    "section": "시각화1: 남녀합격률 시각화",
    "text": "시각화1: 남녀합격률 시각화\n\ndf.groupby(['gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n    \n  \n  \n    \n      0\n      female\n      1001\n    \n    \n      1\n      male\n      1002\n    \n  \n\n\n\n\n\ndatahw=df.groupby(['gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\\\n.merge(df).eval('rate = count/count2')\ndatahw\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n      department\n      result\n      count\n      rate\n    \n  \n  \n    \n      0\n      female\n      1001\n      A\n      fail\n      0\n      0.000000\n    \n    \n      1\n      female\n      1001\n      A\n      pass\n      1\n      0.000999\n    \n    \n      2\n      female\n      1001\n      B\n      fail\n      400\n      0.399600\n    \n    \n      3\n      female\n      1001\n      B\n      pass\n      600\n      0.599401\n    \n    \n      4\n      male\n      1002\n      A\n      fail\n      100\n      0.099800\n    \n    \n      5\n      male\n      1002\n      A\n      pass\n      900\n      0.898204\n    \n    \n      6\n      male\n      1002\n      B\n      fail\n      1\n      0.000998\n    \n    \n      7\n      male\n      1002\n      B\n      pass\n      1\n      0.000998\n    \n  \n\n\n\n\n\nggplot(datahw.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\n\n\n\n\n<ggplot: (8761230608089)>"
  },
  {
    "objectID": "posts/DV_10(1109).html#시각화2-학과별-남녀합격률-시각화",
    "href": "posts/DV_10(1109).html#시각화2-학과별-남녀합격률-시각화",
    "title": "DV 10주차(2)",
    "section": "시각화2: 학과별 남녀합격률 시각화",
    "text": "시각화2: 학과별 남녀합격률 시각화\n\ndatahw2=df.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(datahw2.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\\\n+facet_wrap('department')\n\n\n\n\n<ggplot: (8761230576213)>\n\n\n\nA학과: 쓰면 거의 붙는 학과\nB학과: 쓰면 반정도 붙는 학과"
  },
  {
    "objectID": "posts/DV_10(1109).html#시각화3-학과별-지원자-수-시각화",
    "href": "posts/DV_10(1109).html#시각화3-학과별-지원자-수-시각화",
    "title": "DV 10주차(2)",
    "section": "시각화3: 학과별 지원자 수 시각화",
    "text": "시각화3: 학과별 지원자 수 시각화\n\ndatahw3=df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\nggplot(datahw3)+geom_col(aes(x='gender',fill='gender',y='count2'))+facet_wrap('department')\n\n\n\n\n<ggplot: (8761230548765)>\n\n\n\n여학생은 쓰면 붙는 A학과에는 거의 지원안함, 대신에 쓰면 반정도 붙는 B학과에 대부분 지원함"
  },
  {
    "objectID": "posts/DV_13(1130).html",
    "href": "posts/DV_13(1130).html",
    "title": "DV 13주차(2)",
    "section": "",
    "text": "import pandas as pd \nimport json \nimport requests \nimport plotly.express as px"
  },
  {
    "objectID": "posts/DV_13(1130).html#data",
    "href": "posts/DV_13(1130).html#data",
    "title": "DV 13주차(2)",
    "section": "DATA",
    "text": "DATA\n\ndf = px.data.election()\ngeojson = px.data.election_geojson()\n\n\n두 개의 데이터\n두 데이터를 연결하는 매개체\n지역구에 대응하는 숫자가 들어있는 칼럼이름(df)\nkey가 저장된 위치(geojson, df)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      district\n      Coderre\n      Bergeron\n      Joly\n      total\n      winner\n      result\n      district_id\n    \n  \n  \n    \n      0\n      101-Bois-de-Liesse\n      2481\n      1829\n      3024\n      7334\n      Joly\n      plurality\n      101\n    \n    \n      1\n      102-Cap-Saint-Jacques\n      2525\n      1163\n      2675\n      6363\n      Joly\n      plurality\n      102\n    \n    \n      2\n      11-Sault-au-Récollet\n      3348\n      2770\n      2532\n      8650\n      Coderre\n      plurality\n      11\n    \n    \n      3\n      111-Mile-End\n      1734\n      4782\n      2514\n      9030\n      Bergeron\n      majority\n      111\n    \n    \n      4\n      112-DeLorimier\n      1770\n      5933\n      3044\n      10747\n      Bergeron\n      majority\n      112\n    \n  \n\n\n\n\n\ngeojson.keys()\n\ndict_keys(['type', 'features'])\n\n\n\ngeojson['features'][0].keys()\n\ndict_keys(['type', 'geometry', 'properties', 'id'])\n\n\n\ngeojson['features'][0]['properties']\n\n{'district': '11-Sault-au-Récollet'}"
  },
  {
    "objectID": "posts/DV_13(1130).html#시각화-예시1",
    "href": "posts/DV_13(1130).html#시각화-예시1",
    "title": "DV 13주차(2)",
    "section": "시각화 예시1",
    "text": "시각화 예시1\n\npx.choropleth_mapbox(\n    data_frame= df, \n    geojson=geojson, \n    color=\"Bergeron\",\n    locations=\"district\", \n    featureidkey=\"properties.district\",\n    center={\"lat\": 45.5517, \"lon\": -73.7073},\n    mapbox_style=\"carto-positron\",\n    zoom=9\n)\n\n\n                                                \n\n\n\nfig=px.choropleth_mapbox(\n    data_frame= df, \n    geojson=geojson, \n    color=\"Bergeron\",\n    locations=\"district\", \n    featureidkey=\"properties.district\",\n    center={\"lat\": 45.5517, \"lon\": -73.7073},\n    mapbox_style=\"carto-positron\",\n    zoom=9\n)\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}) # 마진 없애주기"
  },
  {
    "objectID": "posts/DV_13(1130).html#시각화-예시2",
    "href": "posts/DV_13(1130).html#시각화-예시2",
    "title": "DV 13주차(2)",
    "section": "시각화 예시2",
    "text": "시각화 예시2\n\nfig = px.choropleth_mapbox(data_frame= df, \n                           geojson=geojson, \n                           color=\"Bergeron\",\n                           locations=\"district_id\", \n                           featureidkey=\"id\",\n                           center={\"lat\": 45.5517, \"lon\": -73.7073},\n                           mapbox_style=\"carto-positron\",\n                           zoom=9)\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})"
  },
  {
    "objectID": "posts/DV_07(1017).html",
    "href": "posts/DV_07(1017).html",
    "title": "DV 7주차(1)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/DV_07(1017).html#정리",
    "href": "posts/DV_07(1017).html#정리",
    "title": "DV 7주차(1)",
    "section": "정리",
    "text": "정리\n\n\n\n\n.\n[]\n.iloc\n.loc\ncommnets\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\n\nrow/bool,list\nX\nO\nO\nO\n\n\n\nrow/bool,ser\nX\nO\nX\nO\n\n\n\nrow/bool,map\nX\nX\nO\nO\n\n\n\ncol/bool,list\nX\nX\nO\nO\n\n\n\ncol/bool,ser\nX\nX\nX\nX\n쓸일이없음\n\n\ncol/bool,map\nX\nX\nO\nO"
  },
  {
    "objectID": "posts/DV_07(1017).html#데이터",
    "href": "posts/DV_07(1017).html#데이터",
    "title": "DV 7주차(1)",
    "section": "데이터",
    "text": "데이터\n\n책 : https://github.com/PacktPublishing/Pandas-Cookbook\n\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      ...\n      num_user_for_reviews\n      language\n      country\n      content_rating\n      budget\n      title_year\n      actor_2_facebook_likes\n      imdb_score\n      aspect_ratio\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      ...\n      3054.0\n      English\n      USA\n      PG-13\n      237000000.0\n      2009.0\n      936.0\n      7.9\n      1.78\n      33000\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      ...\n      1238.0\n      English\n      USA\n      PG-13\n      300000000.0\n      2007.0\n      5000.0\n      7.1\n      2.35\n      0\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      ...\n      994.0\n      English\n      UK\n      PG-13\n      245000000.0\n      2015.0\n      393.0\n      6.8\n      2.35\n      85000\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      ...\n      2701.0\n      English\n      USA\n      PG-13\n      250000000.0\n      2012.0\n      23000.0\n      8.5\n      2.35\n      164000\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      12.0\n      7.1\n      NaN\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      ...\n      6.0\n      English\n      Canada\n      NaN\n      NaN\n      2013.0\n      470.0\n      7.7\n      NaN\n      84\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      ...\n      359.0\n      English\n      USA\n      TV-14\n      NaN\n      NaN\n      593.0\n      7.5\n      16.00\n      32000\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      ...\n      3.0\n      English\n      USA\n      NaN\n      1400.0\n      2013.0\n      0.0\n      6.3\n      NaN\n      16\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      ...\n      9.0\n      English\n      USA\n      PG-13\n      NaN\n      2012.0\n      719.0\n      6.3\n      2.35\n      660\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      ...\n      84.0\n      English\n      USA\n      PG\n      1100.0\n      2004.0\n      23.0\n      6.6\n      1.85\n      456\n    \n  \n\n4916 rows × 28 columns\n\n\n\n- columns 이름 확인\n\ndf.columns, df.keys()\n\n(Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n        'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n        'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n        'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n        'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n        'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n        'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n        'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n       dtype='object'),\n Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n        'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n        'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n        'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n        'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n        'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n        'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n        'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n       dtype='object'))"
  },
  {
    "objectID": "posts/DV_07(1017).html#기본인덱싱-df인덱싱공부-1단계-내용",
    "href": "posts/DV_07(1017).html#기본인덱싱-df인덱싱공부-1단계-내용",
    "title": "DV 7주차(1)",
    "section": "기본인덱싱 (df인덱싱공부 1단계 내용)",
    "text": "기본인덱싱 (df인덱싱공부 1단계 내용)\n\ndf.loc[:,['color', 'director_name', 'num_critic_for_reviews']]   # 대괄호 쳐주면 df로 나옴\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n    \n  \n\n4916 rows × 3 columns\n\n\n\n\ndf.loc[:,'color':  'title_year','aspect_ratio'] # 슬라이싱 하고 한 개의 리스트 더 봅으려고 하면 안됨\n\nIndexingError: Too many indexers\n\n\ncolor = 0\ntitle_year = 10\naspect_ratio = 16 번째 인덱스라면\n\nlist(range(11))+[16]\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16]\n\n\n\n근데 저게 몇번째인지 어떻게 세 ?\npd.Series 이용\n\n\npd.Series(df.columns)\n\n0                         color\n1                 director_name\n2        num_critic_for_reviews\n3                      duration\n4       director_facebook_likes\n5        actor_3_facebook_likes\n6                  actor_2_name\n7        actor_1_facebook_likes\n8                         gross\n9                        genres\n10                 actor_1_name\n11                  movie_title\n12              num_voted_users\n13    cast_total_facebook_likes\n14                 actor_3_name\n15         facenumber_in_poster\n16                plot_keywords\n17              movie_imdb_link\n18         num_user_for_reviews\n19                     language\n20                      country\n21               content_rating\n22                       budget\n23                   title_year\n24       actor_2_facebook_likes\n25                   imdb_score\n26                 aspect_ratio\n27         movie_facebook_likes\ndtype: object\n\n\n\ndf.iloc[:,list(range(13))+[26]] \n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n      aspect_ratio\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n      1.78\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n      2.35\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      Christoph Waltz\n      Spectre\n      275868\n      2.35\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      Tom Hardy\n      The Dark Knight Rises\n      1144337\n      2.35\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      Doug Walker\n      Star Wars: Episode VII - The Force Awakens\n      8\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      Eric Mabius\n      Signed Sealed Delivered\n      629\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      Natalie Zea\n      The Following\n      73839\n      16.00\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      Eva Boehnke\n      A Plague So Pleasant\n      38\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      Alan Ruck\n      Shanghai Calling\n      1255\n      2.35\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      John August\n      My Date with Drew\n      4285\n      1.85\n    \n  \n\n4916 rows × 14 columns"
  },
  {
    "objectID": "posts/DV_07(1017).html#actor라는-단어가-포함된-column-선택",
    "href": "posts/DV_07(1017).html#actor라는-단어가-포함된-column-선택",
    "title": "DV 7주차(1)",
    "section": "actor라는 단어가 포함된 column 선택",
    "text": "actor라는 단어가 포함된 column 선택\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n- 방법1\n\n'actor' in 'actor_1_facebook_likes'\n\nTrue\n\n\n\n'ator' in 'actor_1_facebook_likes'\n\nFalse\n\n\n\n_df = pd.DataFrame({'x':[1,2,3],'y':[2,3,4], 'z':[3,4,5]})\n_df.loc[:,[True,False,True]]\n# 요론식으로 해서 찾아보자\n\n\n\n\n\n  \n    \n      \n      x\n      z\n    \n  \n  \n    \n      0\n      1\n      3\n    \n    \n      1\n      2\n      4\n    \n    \n      2\n      3\n      5\n    \n  \n\n\n\n\n\ndf.loc[:,list(map(lambda x: 'actor' in x, df.columns))]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법3\n\ndf.iloc[:,list(map(lambda x: 'actor' in x, df.columns))]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법4\n\ndf.iloc[:,map(lambda x: 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns"
  },
  {
    "objectID": "posts/DV_07(1017).html#s로-끝나는-column선택",
    "href": "posts/DV_07(1017).html#s로-끝나는-column선택",
    "title": "DV 7주차(1)",
    "section": "s로 끝나는 column선택",
    "text": "s로 끝나는 column선택\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\n_str = 'actor_1_facebook_likes'\n_str[-1] == 's'\n\nTrue\n\n\n\nlist(map(lambda x: x[-1] == 's', df.columns))\n\n[False,\n False,\n True,\n False,\n True,\n True,\n False,\n True,\n True,\n True,\n False,\n False,\n True,\n True,\n False,\n False,\n True,\n False,\n True,\n False,\n False,\n False,\n False,\n False,\n True,\n False,\n False,\n True]\n\n\n- 방법1\n\ndf.loc[:,list(map(lambda x: x[-1] == 's', df.columns))]  # list 뺴도 됨\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns\n\n\n\n- 방법2\n\ndf.iloc[:,map(lambda x: x[-1] == 's', df.columns)]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns"
  },
  {
    "objectID": "posts/DV_07(1017).html#c-혹은-d로-시작하는-column-선택",
    "href": "posts/DV_07(1017).html#c-혹은-d로-시작하는-column-선택",
    "title": "DV 7주차(1)",
    "section": "c 혹은 d로 시작하는 column 선택",
    "text": "c 혹은 d로 시작하는 column 선택\n- 방법1\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\ndf.loc[:,map(lambda x: (x[0] == 'c') or (x[0] == 'd'), df.columns)]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns\n\n\n\n- 방법2\n\ndf.iloc[:,map(lambda x: (x[0] == 'c') or (x[0] == 'd'), df.columns)]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns"
  },
  {
    "objectID": "posts/DV_07(1017).html#방법1-concat-복잡..",
    "href": "posts/DV_07(1017).html#방법1-concat-복잡..",
    "title": "DV 7주차(1)",
    "section": "방법1: concat (복잡..)",
    "text": "방법1: concat (복잡..)\n\n_df = pd.DataFrame({'c':[3,4,5]})\n_df\n\n\n\n\n\n  \n    \n      \n      c\n    \n  \n  \n    \n      0\n      3\n    \n    \n      1\n      4\n    \n    \n      2\n      5\n    \n  \n\n\n\n\n\npd.concat([df,_df],axis=1)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5"
  },
  {
    "objectID": "posts/DV_07(1017).html#방법2-4가지-컨셉에-따른-할당",
    "href": "posts/DV_07(1017).html#방법2-4가지-컨셉에-따른-할당",
    "title": "DV 7주차(1)",
    "section": "방법2: 4가지 컨셉에 따른 할당",
    "text": "방법2: 4가지 컨셉에 따른 할당\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n컨셉1: 불가능\n\ndf.c = [3,4,5]\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n\n컨셉2: 가능\n(예시1)\n\ndct = {'a':[1,2,3],'b':[2,3,4]}\ndf = pd.DataFrame(dct)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndct['c'] = [3,4,5]\ndct\n\n{'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [3, 4, 5]}\n\n\n\ndf['c'] = [3,4,5]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) - 굳이 사용할 필요는 없음\n\ndct = {'a':[1,2,3],'b':[2,3,4]}\ndf = pd.DataFrame(dct)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf[['a','b']]\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf[['c','d']] = np.array([[1,2,3],[3,4,5]]).T\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      1\n      3\n    \n    \n      1\n      2\n      3\n      2\n      4\n    \n    \n      2\n      3\n      4\n      3\n      5\n    \n  \n\n\n\n\n(예시3)\n\ndct = {'a':[1,2,3],'b':[2,3,4]}\ndf = pd.DataFrame(dct)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c'] = [3,4,5]\ndf['d'] = [4,5,6]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(위와 동일하게..)\n\n(df['c'],df['d']) = ([3,4,5], [4,5,6])\ndf \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n\n컨셉3: 불가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.iloc[:,2] = [3,4,5] \ndf\n\nIndexError: iloc cannot enlarge its target object\n\n\n\n\n컨셉4: 가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'] = [3,4,5]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) - 굳이 쓰진 말자\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,['c','d']] = np.array([[3,4,5],[4,5,6]]).T # 이거 솔직히 되는지 몰랐어요.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'],df.loc[:,'d'] = [3,4,5],[4,5,6] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/DV_07(1017).html#방법3-.assign으로-할당-star",
    "href": "posts/DV_07(1017).html#방법3-.assign으로-할당-star",
    "title": "DV 7주차(1)",
    "section": "방법3: .assign으로 할당 (\\(\\star\\))",
    "text": "방법3: .assign으로 할당 (\\(\\star\\))\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n(예시1)\n\ndf.assign(c=[3,4,5])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2)\n\ndf.assign(c=[3,4,5],d=[4,5,6])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf.assign(c=[3,4,5]).assign(g=[4,2,2])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      g\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      2\n    \n    \n      2\n      3\n      4\n      5\n      2\n    \n  \n\n\n\n\n\ndf  # assign은 위에 할당 해도 기본 df가 남아잇누\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4"
  },
  {
    "objectID": "posts/DV_07(1017).html#방법4-.eval을-이용",
    "href": "posts/DV_07(1017).html#방법4-.eval을-이용",
    "title": "DV 7주차(1)",
    "section": "방법4: .eval을 이용",
    "text": "방법4: .eval을 이용\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]').eval('d=[4,5,6]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/DV_07(1017).html#연습해보기",
    "href": "posts/DV_07(1017).html#연습해보기",
    "title": "DV 7주차(1)",
    "section": "연습해보기",
    "text": "연습해보기\n\n데이터\n\ndf=pd.DataFrame({'x':np.random.randn(1000),'y':np.random.randn(1000)})\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n    \n    \n      1\n      -0.620359\n      -0.310537\n    \n    \n      2\n      -0.247889\n      0.133445\n    \n    \n      3\n      0.499346\n      -1.361192\n    \n    \n      4\n      0.436258\n      -0.225653\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n    \n    \n      996\n      1.279831\n      -0.435540\n    \n    \n      997\n      -0.497101\n      -0.551975\n    \n    \n      998\n      0.457574\n      -0.647124\n    \n    \n      999\n      1.284832\n      -0.149123\n    \n  \n\n1000 rows × 2 columns\n\n\n\n\n\n# 새로운열 r을 생성하고 \\(r=\\sqrt{x^2 + y^2}\\)를 계산\n- 방법1: 브로드캐스팅\n\ndf.assign(r=np.sqrt(df.x**2 + df.y**2))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n      1.840630\n    \n    \n      1\n      -0.620359\n      -0.310537\n      0.693742\n    \n    \n      2\n      -0.247889\n      0.133445\n      0.281525\n    \n    \n      3\n      0.499346\n      -1.361192\n      1.449893\n    \n    \n      4\n      0.436258\n      -0.225653\n      0.491163\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n      1.969498\n    \n    \n      996\n      1.279831\n      -0.435540\n      1.351911\n    \n    \n      997\n      -0.497101\n      -0.551975\n      0.742823\n    \n    \n      998\n      0.457574\n      -0.647124\n      0.792555\n    \n    \n      999\n      1.284832\n      -0.149123\n      1.293457\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법2: lambda + map을 이용한 개별원소 계산\n\ndf.assign(r=list(map(lambda x,y: np.sqrt(x**2+y**2), df.x, df.y)))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n      1.840630\n    \n    \n      1\n      -0.620359\n      -0.310537\n      0.693742\n    \n    \n      2\n      -0.247889\n      0.133445\n      0.281525\n    \n    \n      3\n      0.499346\n      -1.361192\n      1.449893\n    \n    \n      4\n      0.436258\n      -0.225653\n      0.491163\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n      1.969498\n    \n    \n      996\n      1.279831\n      -0.435540\n      1.351911\n    \n    \n      997\n      -0.497101\n      -0.551975\n      0.742823\n    \n    \n      998\n      0.457574\n      -0.647124\n      0.792555\n    \n    \n      999\n      1.284832\n      -0.149123\n      1.293457\n    \n  \n\n1000 rows × 3 columns\n\n\n\n위의 코드에서 list를 지우게 되면 에러가 난다.\n- 방법3: eval\n\ndf.eval('r=sqrt(x**2+y**2)')\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.103943\n      -1.837693\n      1.840630\n    \n    \n      1\n      -0.620359\n      -0.310537\n      0.693742\n    \n    \n      2\n      -0.247889\n      0.133445\n      0.281525\n    \n    \n      3\n      0.499346\n      -1.361192\n      1.449893\n    \n    \n      4\n      0.436258\n      -0.225653\n      0.491163\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      1.956551\n      -0.225453\n      1.969498\n    \n    \n      996\n      1.279831\n      -0.435540\n      1.351911\n    \n    \n      997\n      -0.497101\n      -0.551975\n      0.742823\n    \n    \n      998\n      0.457574\n      -0.647124\n      0.792555\n    \n    \n      999\n      1.284832\n      -0.149123\n      1.293457\n    \n  \n\n1000 rows × 3 columns\n\n\n\n위의 코드에서 r=np.sqrt(~) 사용하면 안된다."
  },
  {
    "objectID": "posts/DV_07(1017).html#toy-exam",
    "href": "posts/DV_07(1017).html#toy-exam",
    "title": "DV 7주차(1)",
    "section": "toy exam",
    "text": "toy exam\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1) \ntemp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7, \n                25.4, 26.8, 28.9, 35.1, 32.2, 34.6])\neps= np.random.normal(size=12,scale=5)\nicecream= 20 + temp * 2 + eps\n\n\nplt.plot(temp,icecream,'.')\n\n\n\n\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\] - 좌변은 소아마비임을 나타내는 어떠한 반응수치라고 생각하자.\n\nnp.random.seed(2) \neps = np.random.normal(size=12,scale=5) \ndisease = 30+ temp* 0.5 + eps\n\n\nplt.plot(temp, disease, '.')\n\n\n\n\n\nplt.plot(icecream,disease,'.')\n\n\n\n\n\n양의 상관관계에 있다.\n\n- 아이스크림 중 어떠한 물질이 소아마비를 일으키는것이 분명하므로 (인과성이 분명해보이니까) 아래와 같은 모형을 세우자. <– 여기서부터 틀렸음\n\\[{\\tt disease}_i =\\beta_0 +\\beta_1 {\\tt icecream}_i +\\epsilon_i,\\quad \\textbf{for} ~~ i=1,2,\\dots, 12\\]\n- 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 추정하면 우리는 아이스크림과 소아마비의 관계를 알 수 있다. <– 틀린주장\n\n틀린 모형\n도데체 우리가 뭘 잘못했는가?\n\n- 두 변수 사이에 상관관계가 있어도 실제 원인은 다른 변수에 숨겨져 있는 경우가 많다.\n(ex1)\n\n온도 \\(\\to\\) 익사\n온도 \\(\\to\\) 아이스크림\n아이스크림과 익사자도 양의 상관관계에 있을것이다.\n아이스크림을 먹이면 물에 빠져 죽는다 \\(\\to\\) 틀린주장\n사실 기온이 숨겨진 원인이다. 기온이 증가하면 아이스크림 판매량도 증가하고 폭염때문에 익사사고율도 높아지는 구조이다.\n\n(ex2)\n\n인구수 \\(\\to\\) 교회\n인구수 \\(\\to\\) 범죄건수\n지역별 교회와 범죄건수를 살펴보면 상관관계가 높게 나올것임\n교회를 지으면 범죄건수도 증가한다? \\(\\to\\) 틀린주장\n사실 인구가 숨겨진 요인임\n\n- ex2, ex1에 대하여 바른 분석을 하려면?\n\nex2: 인구가 비슷한 도시끼리 묶어서 비교해보면 교회와 범죄의 건수는 양의 상관관계에 있지 않을것임\nex1: 온도가 비슷한 그룹끼리 묶어보자.\n\n- 올바른 분석: 온도가 비슷한 그룹끼리 묶어서 그려보자. \\(\\to\\) 상관계수가 줄어들 것이다.\n\nplt.plot(icecream[:6],disease[:6],'.')\n\n\n\n\n\nplt.plot(icecream[6:],disease[6:],'.')\n\n\n\n\n\n진짜로 선형관계가 약해졌다.."
  },
  {
    "objectID": "posts/DV_1(0910).html",
    "href": "posts/DV_1(0910).html",
    "title": "DV 1주차",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "posts/DV_1(0910).html#boxplot",
    "href": "posts/DV_1(0910).html#boxplot",
    "title": "DV 1주차",
    "section": "boxplot",
    "text": "boxplot\n\nmotivating example\n(예제1) 전북고등학교: 평균은 좋은 측정값인가?\n\n전북고등학교에서 통계학을 수업하는 A선생님과 B선생님의 있다. A선생님에게서 수업을 들을 학생들의 평균은 79.1이고 B선생님에게서 수업을 들은 학생들의 평균은 78.3이다.\n\n\ny1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들\ny2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 \n\n\nnp.mean(y1), np.mean(y2)\n\n(79.1, 78.3)\n\n\n- 의사결정: A선생님에게 배운 학생들의 실력이 평균적으로 더 좋을 것이다.\n- 평균은 A반(=A선생님에게 통계학을 배운 반)이 더 높다. 그런데 98점을 받은 학생이 A반에 포함되어서 A반이 전체평균이 높게 나온것이고 나머지 학생들은 전체적으로 B반 학생들이 더 시험을 잘 보았다고 해석할 수 있다.\n- 교훈: 단순한 평균 비교보다 학생들이 받은 점수의 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다.\n\n\nmatplotlib으로 boxplot 그리기\n- A반 학생들의 박스플랏 그리기\n\nplt.boxplot(y1)\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f635fdf5f50>,\n  <matplotlib.lines.Line2D at 0x7f6360351c50>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f635e60c2d0>,\n  <matplotlib.lines.Line2D at 0x7f635e60c610>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f635fd87c10>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f635e60c990>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f635e60cc90>],\n 'means': []}\n\n\n\n\n\n- B반 학생들의 박스플랏 그리기\n\nplt.boxplot(y2)\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f635e5ba410>,\n  <matplotlib.lines.Line2D at 0x7f635e5ba750>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f635e5baa90>,\n  <matplotlib.lines.Line2D at 0x7f635e5badd0>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f635e5ba110>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f635e60f190>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f635e60f4d0>],\n 'means': []}\n\n\n\n\n\n- A반 학생들의 점수와 B반 학생들의 점수를 나란히 박스플랏으로 그리자.\n\nplt.boxplot([y1,y2]) #리스트로 만들어주면 나란히 가능\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f635ec47290>,\n  <matplotlib.lines.Line2D at 0x7f635ec475d0>,\n  <matplotlib.lines.Line2D at 0x7f635ec4fa10>,\n  <matplotlib.lines.Line2D at 0x7f635ec4fd10>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f635ec47910>,\n  <matplotlib.lines.Line2D at 0x7f635ec47c50>,\n  <matplotlib.lines.Line2D at 0x7f635ec67090>,\n  <matplotlib.lines.Line2D at 0x7f635ec673d0>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f635ec48f50>,\n  <matplotlib.lines.Line2D at 0x7f635ec4f6d0>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f635ec4f050>,\n  <matplotlib.lines.Line2D at 0x7f635ec67710>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f635ec4f350>,\n  <matplotlib.lines.Line2D at 0x7f635ec67a50>],\n 'means': []}\n\n\n\n\n\n\n\nboxplot이란?\n- ref: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Statistics/boxplot/box_plot.ipynb\n\nnp.random.seed(916170)\n\n# connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs\nmu, sigma = 0, 1 # mean and standard deviation\ns = np.random.normal(mu, sigma, 1000)\n\nfig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5))\n\n# rectangular box plot\nbplot = axes.boxplot(s,\n                vert=False,\n                patch_artist=True, \n                showfliers=True, # This would show outliers (the remaining .7% of the data)\n                positions = [0],\n                boxprops = dict(linestyle='--', linewidth=2, color='Black', facecolor = 'red', alpha = .4),\n                medianprops = dict(linestyle='-', linewidth=2, color='Yellow'),\n                whiskerprops = dict(linestyle='-', linewidth=2, color='Blue', alpha = .4),\n                capprops = dict(linestyle='-', linewidth=2, color='Black'),\n                flierprops = dict(marker='o', markerfacecolor='green', markersize=10,\n                  linestyle='none', alpha = .4),\n                widths = .3,\n                zorder = 1)   \n\naxes.set_xlim(-4, 4)\nplt.xticks(fontsize = 14)\n\naxes.set_yticks([])\naxes.annotate(r'',\n            xy=(-.73, .205), xycoords='data',\n            xytext=(.66, .205), textcoords='data',\n            arrowprops=dict(arrowstyle=\"|-|\",\n                            connectionstyle=\"arc3\")\n            );\n\naxes.text(0, .25, \"Interquartile Range \\n(IQR)\",  horizontalalignment='center', fontsize=18)\naxes.text(0, -.21, r\"Median\", horizontalalignment='center', fontsize=16);\naxes.text(2.65, -.15, \"\\\"Maximum\\\"\", horizontalalignment='center', fontsize=18);\naxes.text(-2.65, -.15, \"\\\"Minimum\\\"\", horizontalalignment='center', fontsize=18);\naxes.text(-.68, -.24, r\"Q1\", horizontalalignment='center', fontsize=18);\naxes.text(-2.65, -.21, r\"(Q1 - 1.5*IQR)\", horizontalalignment='center', fontsize=16);\naxes.text(.6745, -.24, r\"Q3\", horizontalalignment='center', fontsize=18);\naxes.text(.6745, -.30, r\"(75th Percentile)\", horizontalalignment='center', fontsize=12);\naxes.text(-.68, -.30, r\"(25th Percentile)\", horizontalalignment='center', fontsize=12);\naxes.text(2.65, -.21, r\"(Q3 + 1.5*IQR)\", horizontalalignment='center', fontsize=16);\n\naxes.annotate('Outliers', xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18,\n            arrowprops={'arrowstyle': '->', 'color': 'black', 'lw': 2},\n            va='center');\n\naxes.annotate('Outliers', xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18,\n            arrowprops={'arrowstyle': '->', 'color': 'black', 'lw': 2},\n            va='center');\n\n\n\n\n\n\nplotly로 boxplot 그리기\n- 로컬에서 하기 위해서는 아래를 설치 (코랩은 ㄴ)\n\n!conda env list \n\n# conda environments:\n#\nbase                     /home/koinup4/anaconda3\npy37                  *  /home/koinup4/anaconda3/envs/py37\npy39                     /home/koinup4/anaconda3/envs/py39\n\n\n\n\n!pip install plotly \n!pip install ipywidgets\n!pip install jupyter-dash\n!pip install dash \n!pip install pandas \n\nCollecting plotly\n  Downloading plotly-5.13.0-py2.py3-none-any.whl (15.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.2/15.2 MB 93.1 MB/s eta 0:00:0000:0100:01\nCollecting tenacity>=6.2.0\n  Downloading tenacity-8.2.1-py3-none-any.whl (24 kB)\nInstalling collected packages: tenacity, plotly\nSuccessfully installed plotly-5.13.0 tenacity-8.2.1\nCollecting ipywidgets\n  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 kB 5.8 MB/s eta 0:00:00\nRequirement already satisfied: ipykernel>=4.5.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipywidgets) (5.5.5)\nCollecting jupyterlab-widgets~=3.0\n  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 384.3/384.3 kB 35.3 MB/s eta 0:00:00\nRequirement already satisfied: traitlets>=4.3.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipywidgets) (5.8.1)\nCollecting widgetsnbextension~=4.0\n  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 75.0 MB/s eta 0:00:00\nRequirement already satisfied: ipython>=6.1.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipywidgets) (7.33.0)\nRequirement already satisfied: jupyter-client in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\nRequirement already satisfied: tornado>=4.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\nRequirement already satisfied: backcall in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: jedi>=0.16 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\nRequirement already satisfied: matplotlib-inline in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\nRequirement already satisfied: pexpect>4.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied: pickleshare in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\nRequirement already satisfied: pygments in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\nRequirement already satisfied: decorator in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: setuptools>=18.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (65.6.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.6)\nRequirement already satisfied: jupyter-core>=4.6.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (4.11.1)\nRequirement already satisfied: pyzmq>=13 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (19.0.2)\nRequirement already satisfied: python-dateutil>=2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\nRequirement already satisfied: entrypoints in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: nest-asyncio>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.5.6)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\nInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\nSuccessfully installed ipywidgets-8.0.4 jupyterlab-widgets-3.0.5 widgetsnbextension-4.0.5\nCollecting jupyter-dash\n  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\nCollecting retrying\n  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\nCollecting dash\n  Downloading dash-2.8.1-py3-none-any.whl (9.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 80.9 MB/s eta 0:00:00:00:010:01\nCollecting ansi2html\n  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\nCollecting flask\n  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 kB 19.6 MB/s eta 0:00:00\nRequirement already satisfied: ipykernel in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (5.5.5)\nRequirement already satisfied: nest-asyncio in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (1.5.6)\nRequirement already satisfied: ipython in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (7.33.0)\nRequirement already satisfied: requests in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-dash) (2.28.2)\nRequirement already satisfied: importlib-metadata in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ansi2html->jupyter-dash) (4.11.4)\nRequirement already satisfied: plotly>=5.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash->jupyter-dash) (5.13.0)\nCollecting dash-table==5.0.0\n  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\nCollecting dash-html-components==2.0.0\n  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\nCollecting dash-core-components==2.0.0\n  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\nRequirement already satisfied: Jinja2>=3.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from flask->jupyter-dash) (3.1.2)\nCollecting click>=8.0\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 13.5 MB/s eta 0:00:00\nCollecting Werkzeug>=2.2.2\n  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.6/233.6 kB 44.7 MB/s eta 0:00:00\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nRequirement already satisfied: tornado>=4.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (6.1)\nRequirement already satisfied: jupyter-client in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (7.0.6)\nRequirement already satisfied: traitlets>=4.1.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (5.8.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (3.0.36)\nRequirement already satisfied: matplotlib-inline in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.1.6)\nRequirement already satisfied: pexpect>4.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (4.8.0)\nRequirement already satisfied: pygments in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (2.14.0)\nRequirement already satisfied: jedi>=0.16 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.18.2)\nRequirement already satisfied: decorator in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (5.1.1)\nRequirement already satisfied: pickleshare in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.7.5)\nRequirement already satisfied: setuptools>=18.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (65.6.3)\nRequirement already satisfied: backcall in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from requests->jupyter-dash) (3.4)\nRequirement already satisfied: six>=1.7.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from retrying->jupyter-dash) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata->ansi2html->jupyter-dash) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata->ansi2html->jupyter-dash) (4.4.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Jinja2>=3.0->flask->jupyter-dash) (2.1.1)\nRequirement already satisfied: ptyprocess>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\nRequirement already satisfied: tenacity>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotly>=5.0.0->dash->jupyter-dash) (8.2.1)\nRequirement already satisfied: wcwidth in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.6)\nRequirement already satisfied: entrypoints in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (0.4)\nRequirement already satisfied: pyzmq>=13 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (19.0.2)\nRequirement already satisfied: python-dateutil>=2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\nRequirement already satisfied: jupyter-core>=4.6.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (4.11.1)\nInstalling collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, itsdangerous, click, ansi2html, flask, dash, jupyter-dash\nSuccessfully installed Werkzeug-2.2.3 ansi2html-1.8.0 click-8.1.3 dash-2.8.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-2.2.3 itsdangerous-2.1.2 jupyter-dash-0.4.2 retrying-1.3.4\nRequirement already satisfied: dash in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (2.8.1)\nRequirement already satisfied: dash-table==5.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (5.0.0)\nRequirement already satisfied: dash-html-components==2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (2.0.0)\nRequirement already satisfied: Flask>=1.0.4 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (2.2.3)\nRequirement already satisfied: plotly>=5.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (5.13.0)\nRequirement already satisfied: dash-core-components==2.0.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from dash) (2.0.0)\nRequirement already satisfied: Werkzeug>=2.2.2 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (2.2.3)\nRequirement already satisfied: itsdangerous>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (2.1.2)\nRequirement already satisfied: Jinja2>=3.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (3.1.2)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (4.11.4)\nRequirement already satisfied: click>=8.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Flask>=1.0.4->dash) (8.1.3)\nRequirement already satisfied: tenacity>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotly>=5.0.0->dash) (8.2.1)\nRequirement already satisfied: zipp>=0.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash) (4.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from Jinja2>=3.0->Flask>=1.0.4->dash) (2.1.1)\nRequirement already satisfied: pandas in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (1.3.5)\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (2022.7.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: numpy>=1.17.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas) (1.21.6)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n\n\n\nimport plotly.express as px\nimport pandas as pd\nfrom IPython.display import HTML\n\n\n['A']*len(y1)  # y1숫자만큼 A반복\n\n['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n\n\n\n['A']*len(y1) + ['B']*len(y2)\n\n['A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'A',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B',\n 'B']\n\n\n\ndf=pd.DataFrame({'score':y1+y2, 'class':['A']*len(y1) + ['B']*len(y2)})\ndf\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      75\n      A\n    \n    \n      1\n      75\n      A\n    \n    \n      2\n      76\n      A\n    \n    \n      3\n      76\n      A\n    \n    \n      4\n      77\n      A\n    \n    \n      5\n      77\n      A\n    \n    \n      6\n      79\n      A\n    \n    \n      7\n      79\n      A\n    \n    \n      8\n      79\n      A\n    \n    \n      9\n      98\n      A\n    \n    \n      10\n      76\n      B\n    \n    \n      11\n      76\n      B\n    \n    \n      12\n      77\n      B\n    \n    \n      13\n      77\n      B\n    \n    \n      14\n      78\n      B\n    \n    \n      15\n      78\n      B\n    \n    \n      16\n      80\n      B\n    \n    \n      17\n      80\n      B\n    \n    \n      18\n      80\n      B\n    \n    \n      19\n      81\n      B\n    \n  \n\n\n\n\n\nfig=px.box(df,x='class',y='score')\nfig\n\n\n                                                \n\n\n왜 안나오누..\n\nHTML(fig.to_html(include_plotlyjs='cdn', include_mathjax=False))"
  },
  {
    "objectID": "posts/DV_1(0910).html#histogram",
    "href": "posts/DV_1(0910).html#histogram",
    "title": "DV 1주차",
    "section": "histogram",
    "text": "histogram\n\nmotivating example\n- 전북고예제에서의 소망: 그냥 A반 B반 중에 어떤 반이 공부를 더 잘하냐? - 보통 이러한 질문은 중심경향값 중 하나를 골라서 비교하면 되었다. - 중심경향값이란 데이터 분포의 중심을 보여준 값으로 자료 전체를 대표할 수 있는 값을 말함. 평균, 중앙값 등이 대표적인 중심경향값이다.\n- 전북고 예제에서는 “A반 B반 중에서 어떤 반이 공부를 더 잘하냐?” 라는 질문의 대답으로 단순평균비교로는 의미가 없었다. 오히려 결과론적으로 보면 중앙값이 더 타당해 보인다.\n- 그런데 사실 생각해보면 중앙값을 기준으로 B반이 공부를 더 잘했다고 주장하는 것도 애매하다. 무튼 가장 공부잘한 학생은 A반에 있으니까!? (한명뿐이니까 빼고 가도 되지않나여? 이지만 2명 3명 점점 늘어난다 생각해보면 합리적인 기준을 제시할 수 있을까?)\n- 사실 “A반 B반 중에 누가 더 공부를 잘하냐?” 라는 질문은 굉장히 대답하기 곤란한 질문이다. 왜냐하면 - 이슈1: 단순 평균비교로 이러한 질문에 답을 하기 어렵다. - 이슈2: 박스플랏으로 전체분포를 파악해도 어떠한 반이 더 공부를 잘한다는 기준을 잡는 것이 애매하다.\n그런데 특수한 경우에는 “A반 B반 중에 누가 더 공부를 잘하냐?” 라는 질문에 대한 대답을 깔끔하게 할 수 있다.\n(예제2) 정규분포 전북고등학교: 평균은 좋은 측정값인가?\n- A반과 B반의 통계학 성적이 아래와 같다고 하자.\n\nnp.random.seed(43052)\ny1 = np.random.randn(10000)         # 평균 0 분산 1\ny2 = np.random.randn(10000) + 0.5   # 평균 0.5 분산 1\n\n\nnp.mean(y1), np.mean(y2)\n\n(-0.011790879905079434, 0.4979147460611458)\n\n\n\nnp.mean(y2) - np.mean(y1)\n\n0.5097056259662253\n\n\ny2의 값이 y1의 값보다 전체적으로 0.51 정도 높다고 볼수 있다.?\n\nplt.boxplot([y1,y2])\n\n{'whiskers': [<matplotlib.lines.Line2D at 0x7f638623b0d0>,\n  <matplotlib.lines.Line2D at 0x7f63861c40d0>,\n  <matplotlib.lines.Line2D at 0x7f63861cf510>,\n  <matplotlib.lines.Line2D at 0x7f63861cf810>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f63861c4410>,\n  <matplotlib.lines.Line2D at 0x7f63861c4750>,\n  <matplotlib.lines.Line2D at 0x7f63861cfb50>,\n  <matplotlib.lines.Line2D at 0x7f63861cfe90>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f638623b9d0>,\n  <matplotlib.lines.Line2D at 0x7f63861cf1d0>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f63861c4ad0>,\n  <matplotlib.lines.Line2D at 0x7f63861dc210>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f63861c4e10>,\n  <matplotlib.lines.Line2D at 0x7f63861dc550>],\n 'means': []}\n\n\n\n\n\n\n분포의 모양이 거의 비슷, 왼쪽그림을 컨트롤+C 하여 오른쪽에 붙인다음 0.5정도 y축으로 올린느낌이다!\n\n- 이러한 상황에서는 “B반의 성적 \\(\\approx\\) A반의 성적 + 0.5” 라고 주장해도 큰 무리가 없어보인다. 따라서 이 경우에는 “A반 B반 중에 어떤 반이 더 공부를 잘하냐?” 라는 질문에 대다하여 “B반이 평균적으로 0.51정도 공부를 잘한다”고 말할 수 있다.\n- 결론: 정규분포 분포가정을 한다면 이슈 1, 2에 대한 무넺를 한번에 해결 가능함\n- 정규분포 가정은 어떻게 할 수 있나? (=데이터를 보고 어떻게 정규분포라고 알 수 있는가?) : 데이터의 히스토그램을 그려서 종 모양이 되는지 확인해본다. (아직 초보단계라서 이것밖에 모를 수 있다.)\n\n\nhistogram이란?\n- 히스토그램: X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림\n\n\nmatplotlib으로 histogram 그리기\n- 히스토그램의 예시1\n\ny=[10,11,12,15,16,20,21,22,23,24,25]\n\n\nplt.hist(y)\n\n(array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]),\n array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nplt.hist(y,bins=10)  # bins 빈도 10개\n\n(array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]),\n array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 히스토그램 예시2\n\nplt.hist(y,bins=2) # 빈도 2개\n# 범위 10~17.5에 5개, 17.5~25까지는 6개가 있음\n\n(array([5., 6.]),\n array([10. , 17.5, 25. ]),\n <BarContainer object of 2 artists>)\n\n\n\n\n\n- 히스토그램 예시3\n\nplt.hist(y,bins=3)\n\n(array([3., 2., 6.]),\n array([10., 15., 20., 25.]),\n <BarContainer object of 3 artists>)\n\n\n\n\n\n\n가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다.\nrange / bins = 15 / 3 = 5 이므로 각 구간의 간격은 5이다.\n구간은 [10,15), [15,20), [20,25] 로 나눈다.\n각 구간에 포함된 자료의 수는 3, 2, 6이다.\n\n- 히스토그램 예시4\n\nplt.hist(y,bins=7)\n\n(array([3., 0., 2., 0., 1., 2., 3.]),\n array([10.        , 12.14285714, 14.28571429, 16.42857143, 18.57142857,\n        20.71428571, 22.85714286, 25.        ]),\n <BarContainer object of 7 artists>)\n\n\n\n\n\n\n가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다.\nrange / bins = 15 / 7 = 2.142857142857143 이므로 각 구간의 간격은 2.142857142857143이다.\n구간은 [10,12.14285714), [12.14285714,14.28571429,), [22.85714286,25] 로 나눈다.\n각 구간에 포함된 자료의 수는 3,0,2,0,1,2,3 이다.\n\n\n_a = 15/7\n_a\n\n2.142857142857143\n\n\n- 히스토그램 예시5\n\n# np.random.seed(43052)\n# y1 = np.random.randn(10000)\n# y2 = np.random.randn(10000) + 0.5 \nplt.hist([y1,y2],bins=50);\n\n\n\n\n\n\nseaborn으로 histogram 그리기\n\n!pip install seaborn\nimport seaborn as sns\n\nCollecting seaborn\n  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 293.3/293.3 kB 13.8 MB/s eta 0:00:00\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (3.5.3)\nRequirement already satisfied: typing_extensions in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (4.4.0)\nRequirement already satisfied: pandas>=0.25 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (1.3.5)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from seaborn) (1.21.6)\nRequirement already satisfied: pillow>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\nRequirement already satisfied: cycler>=0.10 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\nRequirement already satisfied: python-dateutil>=2.7 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=0.25->seaborn) (2022.7.1)\nRequirement already satisfied: six>=1.5 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\nInstalling collected packages: seaborn\nSuccessfully installed seaborn-0.12.2\n\n\n\ny1, y2\n\n(array([ 0.38342049,  1.0841745 ,  1.14277825, ...,  1.03232398,\n        -0.18988252, -0.03578389]),\n array([ 1.96391024,  0.31095591, -0.65422978, ..., -0.50052895,\n         1.26755071,  1.00486301]))\n\n\n\ndf=pd.DataFrame({'score': np.concatenate([y1,y2]), 'class':['A']*len(y1) + ['B']*len(y2)})\ndf\n#list(y1)+list(y2)   위의 score를 이렇게도 쓸수있다.\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      0.383420\n      A\n    \n    \n      1\n      1.084175\n      A\n    \n    \n      2\n      1.142778\n      A\n    \n    \n      3\n      0.307894\n      A\n    \n    \n      4\n      0.237787\n      A\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      19995\n      0.493276\n      B\n    \n    \n      19996\n      0.619512\n      B\n    \n    \n      19997\n      -0.500529\n      B\n    \n    \n      19998\n      1.267551\n      B\n    \n    \n      19999\n      1.004863\n      B\n    \n  \n\n20000 rows × 2 columns\n\n\n\n\nsns.histplot(df, x='score', hue='class')\n\n<AxesSubplot:xlabel='score', ylabel='Count'>\n\n\n\n\n\n\n\nplotnine으로 histogram 그리기\n\n!pip install plotnine\n\nCollecting plotnine\n  Downloading plotnine-0.8.0-py3-none-any.whl (4.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 19.9 MB/s eta 0:00:0000:0100:01\nRequirement already satisfied: matplotlib>=3.1.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotnine) (3.5.3)\nRequirement already satisfied: numpy>=1.19.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotnine) (1.21.6)\nCollecting scipy>=1.5.0\n  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.1/38.1 MB 60.6 MB/s eta 0:00:0000:0100:01\nCollecting mizani>=0.7.3\n  Downloading mizani-0.7.3-py3-none-any.whl (63 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 11.2 MB/s eta 0:00:00\nCollecting descartes>=1.1.0\n  Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\nCollecting patsy>=0.5.1\n  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 kB 38.6 MB/s eta 0:00:00\nCollecting statsmodels>=0.12.1\n  Downloading statsmodels-0.13.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 96.2 MB/s eta 0:00:00ta 0:00:01\nRequirement already satisfied: pandas>=1.1.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from plotnine) (1.3.5)\nRequirement already satisfied: cycler>=0.10 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (4.38.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (1.4.4)\nRequirement already satisfied: python-dateutil>=2.7 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (2.8.2)\nRequirement already satisfied: pillow>=6.2.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (9.4.0)\nRequirement already satisfied: packaging>=20.0 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine) (23.0)\nCollecting palettable\n  Downloading palettable-3.3.0-py2.py3-none-any.whl (111 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 111.8/111.8 kB 14.4 MB/s eta 0:00:00\nRequirement already satisfied: pytz>=2017.3 in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=1.1.0->plotnine) (2022.7.1)\nRequirement already satisfied: six in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from patsy>=0.5.1->plotnine) (1.16.0)\nRequirement already satisfied: typing-extensions in /home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->plotnine) (4.4.0)\nInstalling collected packages: palettable, scipy, patsy, statsmodels, mizani, descartes, plotnine\nSuccessfully installed descartes-1.1.0 mizani-0.7.3 palettable-3.3.0 patsy-0.5.3 plotnine-0.8.0 scipy-1.7.3 statsmodels-0.13.5\n\n\n\nfrom plotnine import *\n\n\nggplot(df) + geom_histogram(aes(x='score', fill='class'), position='identity', alpha=0.5)\n# position: 겹쳐있게 보이게 함.\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 84'. Pick better value with 'binwidth'.\n\n\n\n\n\n<ggplot: (8754036207793)>\n\n\n\nggplot(df) + geom_histogram(aes(x='score', fill='class'), alpha=0.5)\n# 파란색을 그리고 빨간색을 그 위에 그림\n# 비교를 위해서 관찰만 할것 이렇게 그리진 말자\n\n/home/koinup4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 84'. Pick better value with 'binwidth'.\n\n\n\n\n\n<ggplot: (8754019989885)>\n\n\n\n\nplotly로 histogram 그리기\n\nimport plotly.figure_factory as ff\n\nhist_data = [y1, y2]\n\ngroup_labels = ['A', 'B']\n\n# Create distplot with curve_type set to 'normal'\nff.create_distplot(hist_data, group_labels,bin_size=.2, show_rug=False)"
  },
  {
    "objectID": "posts/DV_11(1116).html",
    "href": "posts/DV_11(1116).html",
    "title": "DV 11주차(2)",
    "section": "",
    "text": "import pandas as pd \nimport numpy as np"
  },
  {
    "objectID": "posts/DV_11(1116).html#데이터읽기-pd.read_html",
    "href": "posts/DV_11(1116).html#데이터읽기-pd.read_html",
    "title": "DV 11주차(2)",
    "section": "데이터읽기 // pd.read_html()",
    "text": "데이터읽기 // pd.read_html()\n- 대한민국의 저출산문제\n\nref: https://ko.wikipedia.org/wiki/대한민국의_저출산\n\n- 위의 url에서 3,5번째 테이블을 읽고싶다.\n\n3번째 테이블: 시도별 출산율\n5번째 테이블: 시도별 출생아 수\n\n\n_dflst=pd.read_html('https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%A0%80%EC%B6%9C%EC%82%B0')\n_df1 = _dflst[2]\n_df2 = _dflst[4]\n\n\n_df1 # 시도별 출산율\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      2005\n      2006[7]\n      2007\n      2008[8]\n      2009[9]\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n  \n  \n    \n      0\n      서울\n      0.92\n      0.97\n      1.06\n      1.01\n      0.96\n      1.02\n      1.01\n      1.06\n      0.97\n      0.98\n      1.00\n      0.94\n      0.84\n      0.76\n      0.72\n      0.64\n      0.63\n    \n    \n      1\n      부산\n      0.88\n      0.91\n      1.02\n      0.98\n      0.94\n      1.05\n      1.08\n      1.14\n      1.05\n      1.09\n      1.14\n      1.10\n      0.98\n      0.90\n      0.83\n      0.75\n      0.73\n    \n    \n      2\n      대구\n      0.99\n      1.00\n      1.13\n      1.07\n      1.03\n      1.11\n      1.15\n      1.22\n      1.13\n      1.17\n      1.22\n      1.19\n      1.07\n      0.99\n      0.93\n      0.81\n      0.78\n    \n    \n      3\n      인천\n      1.07\n      1.11\n      1.25\n      1.19\n      1.14\n      1.21\n      1.23\n      1.30\n      1.20\n      1.21\n      1.22\n      1.14\n      1.01\n      1.01\n      0.94\n      0.83\n      0.78\n    \n    \n      4\n      광주\n      1.10\n      1.14\n      1.26\n      1.20\n      1.14\n      1.22\n      1.23\n      1.30\n      1.17\n      1.20\n      1.21\n      1.17\n      1.05\n      0.97\n      0.91\n      0.81\n      0.90\n    \n    \n      5\n      대전\n      1.10\n      1.15\n      1.27\n      1.22\n      1.16\n      1.21\n      1.26\n      1.32\n      1.23\n      1.25\n      1.28\n      1.19\n      1.08\n      0.95\n      0.88\n      0.81\n      0.81\n    \n    \n      6\n      울산\n      1.18\n      1.24\n      1.40\n      1.34\n      1.31\n      1.37\n      1.39\n      1.48\n      1.39\n      1.44\n      1.49\n      1.42\n      1.26\n      1.13\n      1.08\n      0.99\n      0.94\n    \n    \n      7\n      세종\n      -\n      -\n      -\n      -\n      -\n      -\n      -\n      1.60\n      1.44\n      1.35\n      1.89\n      1.82\n      1.67\n      1.57\n      1.47\n      1.28\n      1.28\n    \n    \n      8\n      경기\n      1.17\n      1.23\n      1.35\n      1.29\n      1.23\n      1.31\n      1.31\n      1.36\n      1.23\n      1.24\n      1.27\n      1.19\n      1.07\n      1.00\n      0.94\n      0.88\n      0.85\n    \n    \n      9\n      강원\n      1.18\n      1.19\n      1.35\n      1.25\n      1.25\n      1.31\n      1.34\n      1.37\n      1.25\n      1.25\n      1.31\n      1.24\n      1.12\n      1.07\n      1.08\n      1.04\n      0.98\n    \n    \n      10\n      충북\n      1.19\n      1.22\n      1.39\n      1.32\n      1.32\n      1.40\n      1.43\n      1.49\n      1.37\n      1.36\n      1.41\n      1.36\n      1.24\n      1.17\n      1.05\n      0.98\n      0.95\n    \n    \n      11\n      충남\n      1.26\n      1.35\n      1.50\n      1.44\n      1.41\n      1.48\n      1.50\n      1.57\n      1.44\n      1.42\n      1.48\n      1.40\n      1.28\n      1.19\n      1.11\n      1.03\n      0.96\n    \n    \n      12\n      전북\n      1.17\n      1.20\n      1.37\n      1.31\n      1.28\n      1.37\n      1.41\n      1.44\n      1.32\n      1.33\n      1.35\n      1.25\n      1.15\n      1.04\n      0.97\n      0.91\n      0.85\n    \n    \n      13\n      전남\n      1.28\n      1.33\n      1.53\n      1.45\n      1.45\n      1.54\n      1.57\n      1.64\n      1.52\n      1.50\n      1.55\n      1.47\n      1.33\n      1.24\n      1.23\n      1.15\n      1.02\n    \n    \n      14\n      경북\n      1.17\n      1.20\n      1.36\n      1.31\n      1.27\n      1.38\n      1.43\n      1.49\n      1.38\n      1.41\n      1.46\n      1.40\n      1.26\n      1.17\n      1.09\n      1.00\n      0.97\n    \n    \n      15\n      경남\n      1.18\n      1.25\n      1.43\n      1.37\n      1.32\n      1.41\n      1.45\n      1.50\n      1.37\n      1.41\n      1.44\n      1.36\n      1.23\n      1.12\n      1.05\n      0.95\n      0.90\n    \n    \n      16\n      제주\n      1.30\n      1.36\n      1.48\n      1.39\n      1.38\n      1.46\n      1.49\n      1.60\n      1.43\n      1.48\n      1.48\n      1.43\n      1.31\n      1.22\n      1.15\n      1.02\n      0.95\n    \n    \n      17\n      전국\n      1.08\n      1.13\n      1.25\n      1.19\n      1.15\n      1.23\n      1.24\n      1.30\n      1.19\n      1.21\n      1.24\n      1.17\n      1.05\n      0.98\n      0.92\n      0.84\n      0.81\n    \n  \n\n\n\n\n\n_df2 # 시도별 출생아수\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n  \n  \n    \n      0\n      서울\n      93266\n      91526\n      93914.000\n      84066.000\n      83711.000\n      83005\n      75.536\n      65389\n      58074\n      53.673\n      47400\n      45531\n    \n    \n      1\n      부산\n      27415\n      27759\n      28673.000\n      25831.000\n      26190.000\n      26645\n      24906.000\n      21480\n      19152\n      17049.000\n      15100\n      14446\n    \n    \n      2\n      대구\n      20557\n      20758\n      21472.000\n      19340.000\n      19361.000\n      19438\n      18298.000\n      15946\n      14400\n      13233.000\n      11200\n      10661\n    \n    \n      3\n      인천\n      25752\n      20758\n      21472.000\n      25560.000\n      25786.000\n      25491\n      23609.000\n      20445\n      20087\n      18522.000\n      16000\n      14947\n    \n    \n      4\n      광주\n      13979\n      13916\n      14392.000\n      12729.000\n      12729.000\n      12441\n      11580.000\n      10120\n      9105\n      8364.000\n      7300\n      7956\n    \n    \n      5\n      대전\n      14314\n      14808\n      15279.000\n      14099.000\n      13962.000\n      13774\n      12436.000\n      10851\n      9337\n      8410.000\n      7500\n      7414\n    \n    \n      6\n      울산\n      11432\n      11542\n      12160.000\n      11330.000\n      11556.000\n      11732\n      10910.000\n      9381\n      8149\n      7539.000\n      6600\n      6127\n    \n    \n      7\n      세종\n      -\n      -\n      1054.000\n      1111.000\n      1344.000\n      2708\n      3297.000\n      3504\n      3703\n      3819.000\n      3500\n      3570\n    \n    \n      8\n      경기\n      121753\n      122027\n      124746.000\n      112129.000\n      112.169\n      113495\n      105643.000\n      94088\n      83198\n      83.198\n      77800\n      76139\n    \n    \n      9\n      강원\n      12477\n      12408\n      12426.000\n      10980.000\n      10662.000\n      10929\n      10058.000\n      9958\n      8351\n      8283.000\n      7800\n      7357\n    \n    \n      10\n      충북\n      14670\n      14804\n      15139.000\n      13658.000\n      13366.000\n      13563\n      12742.000\n      11394\n      10586\n      9333.000\n      8600\n      8190\n    \n    \n      11\n      충남\n      20.242\n      20.398\n      20.448\n      18.628\n      18200.000\n      18604\n      17302.000\n      15670\n      14380\n      13228.000\n      11900\n      10984\n    \n    \n      12\n      전북\n      16100\n      16175\n      16238.000\n      14555.000\n      14231.000\n      14087\n      12698.000\n      11348\n      10001\n      8971.000\n      8200\n      7745\n    \n    \n      13\n      전남\n      16654\n      16612\n      16990.000\n      15401.000\n      14817.000\n      15061\n      13980.000\n      12354\n      11238\n      10832.000\n      9700\n      8430\n    \n    \n      14\n      경북\n      23700\n      24250\n      24635.000\n      22206.000\n      22062.000\n      22310\n      20616.000\n      17957\n      16079\n      14472.000\n      12900\n      12045\n    \n    \n      15\n      경남\n      32203\n      32536\n      33211.000\n      29504.000\n      29763.000\n      29537\n      27138.000\n      23849\n      21224\n      19250.000\n      16800\n      15562\n    \n    \n      16\n      제주\n      5657\n      5628\n      5992.000\n      5328.000\n      5526.000\n      5600\n      5494.000\n      5037\n      4781\n      4500.000\n      4000\n      3728\n    \n    \n      17\n      전국\n      470171\n      471265\n      484550.000\n      436455.000\n      435435.000\n      438420\n      406243.000\n      357771\n      326822\n      302676.000\n      272400\n      260562\n    \n  \n\n\n\n\n\n데이터정리\n\n전국 행 삭제\n지역/연도[6]에 있는 2006[7] 이런 것 정리\nnan값 표시\n\n\n_df1.drop(17)\\\n.melt(id_vars='지역/연도[6]').variable.unique()\n\narray(['2005', '2006[7]', '2007', '2008[8]', '2009[9]', '2010', '2011',\n       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019',\n       '2020', '2021'], dtype=object)\n\n\n\ndf1 = _df1.drop(17)\\\n.melt(id_vars='지역/연도[6]')\\\n.assign(variable = lambda df: list(map(lambda x:x[:4], df.variable)))\ndf1\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      variable\n      value\n    \n  \n  \n    \n      0\n      서울\n      2005\n      0.92\n    \n    \n      1\n      부산\n      2005\n      0.88\n    \n    \n      2\n      대구\n      2005\n      0.99\n    \n    \n      3\n      인천\n      2005\n      1.07\n    \n    \n      4\n      광주\n      2005\n      1.10\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      284\n      전북\n      2021\n      0.85\n    \n    \n      285\n      전남\n      2021\n      1.02\n    \n    \n      286\n      경북\n      2021\n      0.97\n    \n    \n      287\n      경남\n      2021\n      0.9\n    \n    \n      288\n      제주\n      2021\n      0.95\n    \n  \n\n289 rows × 3 columns\n\n\n\n\ndf1.value.unique()\n\narray(['0.92', '0.88', '0.99', '1.07', '1.10', '1.18', '-', '1.17',\n       '1.19', '1.26', '1.28', '1.30', '0.97', '0.91', '1.00', '1.11',\n       '1.14', '1.15', '1.24', '1.23', '1.22', '1.35', '1.20', '1.33',\n       '1.25', '1.36', '1.06', '1.02', '1.13', '1.27', '1.40', '1.39',\n       '1.50', '1.37', '1.53', '1.43', '1.48', '1.01', '0.98', '1.34',\n       '1.29', '1.32', '1.44', '1.31', '1.45', '0.96', '0.94', '1.03',\n       '1.16', '1.41', '1.38', '1.05', '1.21', '1.54', '1.46', '1.08',\n       '1.57', '1.49', 1.06, 1.14, 1.22, 1.3, 1.32, 1.48, 1.6, 1.36, 1.37,\n       1.49, 1.57, 1.44, 1.64, 1.5, 0.97, 1.05, 1.13, 1.2, 1.17, 1.23,\n       1.39, 1.25, 1.52, 1.38, 1.43, 0.98, 1.09, 1.21, 1.35, 1.24, 1.42,\n       1.33, 1.41, 1.0, 1.28, 1.89, 1.27, 1.31, 1.55, 1.46, 0.94, 1.1,\n       1.19, 1.82, 1.4, 1.47, 0.84, 1.07, 1.01, 1.08, 1.26, 1.67, 1.12,\n       1.15, 0.76, 0.9, 0.99, 0.95, 1.04, 0.72, 0.83, 0.93, 0.91, 0.88,\n       1.11, 0.64, 0.75, 0.81, 1.03, 1.02, 0.63, 0.73, 0.78, 0.85, 0.96],\n      dtype=object)\n\n\n문자열, 숫자.. 다 섞여있음\n\ndf1 = df1.assign(value=lambda df: list(map(lambda x: None if x=='-' else float(x), df.value)))\n\n\ndf1=df1.set_axis(['지역','연도','출산율'],axis=1)\ndf1\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출산율\n    \n  \n  \n    \n      0\n      서울\n      2005\n      0.92\n    \n    \n      1\n      부산\n      2005\n      0.88\n    \n    \n      2\n      대구\n      2005\n      0.99\n    \n    \n      3\n      인천\n      2005\n      1.07\n    \n    \n      4\n      광주\n      2005\n      1.10\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      284\n      전북\n      2021\n      0.85\n    \n    \n      285\n      전남\n      2021\n      1.02\n    \n    \n      286\n      경북\n      2021\n      0.97\n    \n    \n      287\n      경남\n      2021\n      0.90\n    \n    \n      288\n      제주\n      2021\n      0.95\n    \n  \n\n289 rows × 3 columns\n\n\n\n\ndf2 = _df2.drop(17)\\\n.melt(id_vars='지역/연도[6]')\\\n.assign(value = lambda df: list(map(lambda x: None if x=='-' else float(x), df.value)))\\\n.set_axis(['지역','연도','출생아수'],axis=1)\ndf2\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns"
  },
  {
    "objectID": "posts/DV_11(1116).html#시각화i-전국-출생아수-시각화",
    "href": "posts/DV_11(1116).html#시각화i-전국-출생아수-시각화",
    "title": "DV 11주차(2)",
    "section": "시각화I: 전국 출생아수 시각화",
    "text": "시각화I: 전국 출생아수 시각화\n\ndf2.groupby(['연도']).agg({'출생아수':np.sum}).reset_index().plot(x='연도',y='출생아수',backend='plotly')\n\n\n                                                \n\n\n\n일괄적으로 감소하는 느낌은 없음"
  },
  {
    "objectID": "posts/DV_11(1116).html#시각화ii-시도별-출생아수-시각화",
    "href": "posts/DV_11(1116).html#시각화ii-시도별-출생아수-시각화",
    "title": "DV 11주차(2)",
    "section": "시각화II: 시도별 출생아수 시각화",
    "text": "시각화II: 시도별 출생아수 시각화\n- 시각화예시1\n\ndf2.plot.line(backend='plotly', x='연도', y='출생아수', color='지역')\n\n\n                                                \n\n\n\n서울과 경기가 특이하네..\n\n- 시각화예시2: plot.area\n\ndf2.plot.area(backend='plotly',x='연도',y='출생아수',color='지역')\n\n\n                                                \n\n\n\nareaplot의 최상단의 선: 전국출생아수 시각화와 같음 (일괄적으로 감소하는 느낌은 별로 없음. 그 이유는 서울과 경기지역 때문임)\nareaplot의 장점: 전국출생아수를 연도별로 시각화 하는 느낌 + 각 연도를 도시별로 분해하여 해석하는 느낌"
  },
  {
    "objectID": "posts/DV_11(1116).html#시각화iii-시도별-출산율-시각화",
    "href": "posts/DV_11(1116).html#시각화iii-시도별-출산율-시각화",
    "title": "DV 11주차(2)",
    "section": "시각화III: 시도별 출산율 시각화",
    "text": "시각화III: 시도별 출산율 시각화\n\ndf1.plot.line(backend='plotly', x='연도', y='출산율', color='지역')\n\n\n                                                \n\n\n\n상식과 일치하는 정상적인 플랏 ( 출산율이 2021 이후로 꺽이는 느낌이 든다.)\n여기서는 서울/경기가 정상인듯 보인다.\n\n\n출산율의 경우 합계 출산율이 크게 의미가 없으므로 areaplot는 생략"
  },
  {
    "objectID": "posts/DV_11(1116).html#해석",
    "href": "posts/DV_11(1116).html#해석",
    "title": "DV 11주차(2)",
    "section": "해석",
    "text": "해석\n- 이상한점: 서울/경기지역에서 특정연도의 출생아수가 매우 낮으나 서울/경기지역의 출산’율’은 모든 년도에서 고른값을 가짐\n- 해석: 데이터가 이상?? / 원본 데이터를 확인하니 오타가 있음.. 컴마를 온점으로 찍음 ㅠ"
  },
  {
    "objectID": "posts/DV_11(1116).html#데이터의-수정-1-df2-상태에서-수정",
    "href": "posts/DV_11(1116).html#데이터의-수정-1-df2-상태에서-수정",
    "title": "DV 11주차(2)",
    "section": "데이터의 수정 (1): df2 상태에서 수정",
    "text": "데이터의 수정 (1): df2 상태에서 수정\n\ndf2.sort_values(\"출생아수\")[:10]\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      62\n      충남\n      2013\n      18.628\n    \n    \n      11\n      충남\n      2010\n      20.242\n    \n    \n      28\n      충남\n      2011\n      20.398\n    \n    \n      45\n      충남\n      2012\n      20.448\n    \n    \n      153\n      서울\n      2019\n      53.673\n    \n    \n      102\n      서울\n      2016\n      75.536\n    \n    \n      161\n      경기\n      2019\n      83.198\n    \n    \n      76\n      경기\n      2014\n      112.169\n    \n    \n      41\n      세종\n      2012\n      1054.000\n    \n    \n      58\n      세종\n      2013\n      1111.000\n    \n  \n\n\n\n\n- 오타로 예상되는 서울/경기/충남 이외의 가장 작은 값은 2012년 세종시인데, 이 값이 1054로 1000보다 크다.\n\n출생아수 < 1000 이면 출생아수 * 1000을 수행하는 함수를 구현하자.\n\n\ndf2.assign(출생아수 = list(map(lambda x: x*1000 if x<1000 else x, df2.출생아수)))\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns\n\n\n\n- 수정 잘 됬는지 시각화\n\ndf2.assign(출생아수 = list(map(lambda x: x*1000 if x<1000 else x, df2.출생아수)))\\\n.plot.area(x='연도', y='출생아수', color='지역', backend='plotly')\n\n\n                                                \n\n\n\n전체출산율이 점점 낮아지고 있고 항목별로 살펴보아도 모든 도시의 출생아수가 점차 낮아지고 있음"
  },
  {
    "objectID": "posts/DV_11(1116).html#데이터의-수정-2-_df2-상태에서-수정",
    "href": "posts/DV_11(1116).html#데이터의-수정-2-_df2-상태에서-수정",
    "title": "DV 11주차(2)",
    "section": "데이터의 수정 (2): _df2 상태에서 수정",
    "text": "데이터의 수정 (2): _df2 상태에서 수정\n\napplymap\n- 예비학습\n\npd.DataFrame(np.arange(4).reshape(2,2)).applymap(lambda x:x**2+1)\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      5\n      10\n    \n  \n\n\n\n\n\n모든 element에 똑같이 함수를 적용하는 함수\n\n\n_df2.set_index('지역/연도[6]') # 임의로 인덱스를 빼자. 값에 applymap을 쓰기 위해서\n\n\n\n\n\n  \n    \n      \n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n    \n      지역/연도[6]\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      서울\n      93266\n      91526\n      93914.000\n      84066.000\n      83711.000\n      83005\n      75.536\n      65389\n      58074\n      53.673\n      47400\n      45531\n    \n    \n      부산\n      27415\n      27759\n      28673.000\n      25831.000\n      26190.000\n      26645\n      24906.000\n      21480\n      19152\n      17049.000\n      15100\n      14446\n    \n    \n      대구\n      20557\n      20758\n      21472.000\n      19340.000\n      19361.000\n      19438\n      18298.000\n      15946\n      14400\n      13233.000\n      11200\n      10661\n    \n    \n      인천\n      25752\n      20758\n      21472.000\n      25560.000\n      25786.000\n      25491\n      23609.000\n      20445\n      20087\n      18522.000\n      16000\n      14947\n    \n    \n      광주\n      13979\n      13916\n      14392.000\n      12729.000\n      12729.000\n      12441\n      11580.000\n      10120\n      9105\n      8364.000\n      7300\n      7956\n    \n    \n      대전\n      14314\n      14808\n      15279.000\n      14099.000\n      13962.000\n      13774\n      12436.000\n      10851\n      9337\n      8410.000\n      7500\n      7414\n    \n    \n      울산\n      11432\n      11542\n      12160.000\n      11330.000\n      11556.000\n      11732\n      10910.000\n      9381\n      8149\n      7539.000\n      6600\n      6127\n    \n    \n      세종\n      -\n      -\n      1054.000\n      1111.000\n      1344.000\n      2708\n      3297.000\n      3504\n      3703\n      3819.000\n      3500\n      3570\n    \n    \n      경기\n      121753\n      122027\n      124746.000\n      112129.000\n      112.169\n      113495\n      105643.000\n      94088\n      83198\n      83.198\n      77800\n      76139\n    \n    \n      강원\n      12477\n      12408\n      12426.000\n      10980.000\n      10662.000\n      10929\n      10058.000\n      9958\n      8351\n      8283.000\n      7800\n      7357\n    \n    \n      충북\n      14670\n      14804\n      15139.000\n      13658.000\n      13366.000\n      13563\n      12742.000\n      11394\n      10586\n      9333.000\n      8600\n      8190\n    \n    \n      충남\n      20.242\n      20.398\n      20.448\n      18.628\n      18200.000\n      18604\n      17302.000\n      15670\n      14380\n      13228.000\n      11900\n      10984\n    \n    \n      전북\n      16100\n      16175\n      16238.000\n      14555.000\n      14231.000\n      14087\n      12698.000\n      11348\n      10001\n      8971.000\n      8200\n      7745\n    \n    \n      전남\n      16654\n      16612\n      16990.000\n      15401.000\n      14817.000\n      15061\n      13980.000\n      12354\n      11238\n      10832.000\n      9700\n      8430\n    \n    \n      경북\n      23700\n      24250\n      24635.000\n      22206.000\n      22062.000\n      22310\n      20616.000\n      17957\n      16079\n      14472.000\n      12900\n      12045\n    \n    \n      경남\n      32203\n      32536\n      33211.000\n      29504.000\n      29763.000\n      29537\n      27138.000\n      23849\n      21224\n      19250.000\n      16800\n      15562\n    \n    \n      제주\n      5657\n      5628\n      5992.000\n      5328.000\n      5526.000\n      5600\n      5494.000\n      5037\n      4781\n      4500.000\n      4000\n      3728\n    \n    \n      전국\n      470171\n      471265\n      484550.000\n      436455.000\n      435435.000\n      438420\n      406243.000\n      357771\n      326822\n      302676.000\n      272400\n      260562\n    \n  \n\n\n\n\n- 방법1\n\n_df2.set_index('지역/연도[6]')\\\n.applymap(lambda x: None if x=='-' else float(x))\\\n.applymap(lambda x: x*1000 if x<1000 else x)\\\n.drop('전국')\\\n.stack().reset_index()\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      level_1\n      0\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      서울\n      2011\n      91526.0\n    \n    \n      2\n      서울\n      2012\n      93914.0\n    \n    \n      3\n      서울\n      2013\n      84066.0\n    \n    \n      4\n      서울\n      2014\n      83711.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      197\n      제주\n      2017\n      5037.0\n    \n    \n      198\n      제주\n      2018\n      4781.0\n    \n    \n      199\n      제주\n      2019\n      4500.0\n    \n    \n      200\n      제주\n      2020\n      4000.0\n    \n    \n      201\n      제주\n      2021\n      3728.0\n    \n  \n\n202 rows × 3 columns\n\n\n\n- 방법2\n\ndf2=_df2.set_index('지역/연도[6]')\\\n.applymap(lambda x: None if x=='-' else float(x))\\\n.applymap(lambda x: x*1000 if x<1000 else x)\\\n.drop('전국')\\\n.reset_index()\\\n.melt(id_vars='지역/연도[6]')\\\n.set_axis(['지역','연도','출생아수'],axis=1)\ndf2\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns\n\n\n\n\ndf2.plot.area(backend='plotly',x='연도',y='출생아수',color='지역')"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DV",
    "section": "",
    "text": "DV 13주차(2)\n\n\n\n\n\n\n\n지리정보시각화\n\n\nPLOTLY\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 13주차(1)\n\n\n\n\n\n\n\n지리정보시각화\n\n\nFOLIUM\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 12주차\n\n\n\n\n\n\n\n지리정보시각화\n\n\nFOLIUM\n\n\nFLOTLY\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 11주차(2)\n\n\n\n\n\n\n\n자료분석\n\n\nPANDAS BACKEND\n\n\nPLOTLY\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 11주차(1)\n\n\n\n\n\n\n\nPANDAS BACKEND\n\n\nPLOTLY\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 10주차(2)\n\n\n\n\n\n\n\n통계와 시각화\n\n\nPLOTNINE\n\n\n\n\n\n\n\n\n\n\n\nNov 9, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 10주차(1)\n\n\n\n\n\n\n\npandas\n\n\nPLOTNINE\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\n김보람\n\n\n\n\n\n\n  \n\n\n\n\nDV 9주차\n\n\n\n\n\n\n\n훌륭한 시각화\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 8주차\n\n\n\n\n\n\n\npandas\n\n\n자료 분석\n\n\nPLOTNINE\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 7주차(2)\n\n\n\n\n\n\n\n통계와 시각화\n\n\nPLOTNINE\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 7주차(1)\n\n\n\n\n\n\n\npandas\n\n\n통계와 시각화\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 6주차\n\n\n\n\n\n\n\npandas\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2022\n\n\n김보람\n\n\n\n\n\n\n  \n\n\n\n\nDV 5주차(2)\n\n\n\n\n\n\n\nPLOTNINE\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 5주차(1)\n\n\n\n\n\n\n\nSEABORN\n\n\nMATPLOTLIB\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 4주차(2)\n\n\n\n\n\n\n\nSEABORN\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 4주차(1)\n\n\n\n\n\n\n\nMATPLOTLIB\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 3주차(2)\n\n\n\n\n\n\n\nMATPLOTLIB\n\n\n통계와 시각화\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2022\n\n\n김보람\n\n\n\n\n\n\n  \n\n\n\n\nDV 3주차(1)\n\n\n\n\n\n\n\nMATPLOTLIB\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 2주차\n\n\n\n\n\n\n\n통계와 시각화\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\n김보람\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDV 1주차\n\n\n\n\n\n\n\nboxplot\n\n\nhistogram\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2022\n\n\n김보람\n\n\n\n\n\n\nNo matching items"
  }
]